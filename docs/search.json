[
  {
    "objectID": "greek.html",
    "href": "greek.html",
    "title": "Greek Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nΣυγκεντρωμένο υλικό για την R στα ελληνικά\n\n\n\n\n\n\n\nR\n\n\n\n\nΜία λίστα (που θα ανανεώνεται συνεχώς) με υλικό που υπάρχει διαθέσιμο στο διαδίκτυο (δωρεάν) σχετικά με την R\n\n\n\n\n\n\nOct 23, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello !",
    "section": "",
    "text": "I’m Stelios !\nCurrently, I am an undergraduate student of Statistics and Insurance Science at University of Piraeus.\nOn my website I will upload various posts closely related with R and Statistics.\nAlso you can have a look on my Shiny Apps."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nInstall LightGBM and CatBoost on Ubuntu 22.04\n\n\n\n\n\n\n\nLinux\n\n\nLightGBM\n\n\nCatBoost\n\n\nXGBoost\n\n\n\n\nInstall high performance algorithms (LightGBM, CatBoost & XGBoost) on your Linux device\n\n\n\n\n\n\nNov 13, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nGit Series (Part I - Configuration)\n\n\n\n\n\n\n\nGit\n\n\n\n\nAn article that brings together some configuration setttings of Git. A beginner’s approach to Git.\n\n\n\n\n\n\nNov 4, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nVerify your commits !\n\n\n\n\n\n\n\nGPG\n\n\nQuarto\n\n\n\n\nUsing GPG keys to add a signature to your GitHub commits\n\n\n\n\n\n\nOct 3, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nList of Quarto Websites\n\n\n\n\n\n\n\nQuarto\n\n\n\n\nA collection of websites built with Quarto. Includes links to websites and their respective repositories. Further additions are always welcome.\n\n\n\n\n\n\nAug 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nHello, World\n\n\n\n\n\n\n\nfirst article\n\n\n\n\nMy first article on my Quarto website.\n\n\n\n\n\n\nJul 27, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks.html",
    "href": "notebooks.html",
    "title": "ML Notebooks",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nAsylum applicants in Europe\n\n\n\n\n\n\n\nR\n\n\nEurostat\n\n\n\n\nCreate a Europe map based on the number of asylum applications per country.\n\n\n\n\n\n\nJan 8, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Cost of Housing in Kallithea\n\n\n\n\n\n\n\nR\n\n\nRegression\n\n\n\n\nBuild a regression model using various ML algorithms to predict cost to buy a house in Kallithea.\n\n\n\n\n\n\nDec 6, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Possible Interested Clients\n\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\n\n\nBuild a classification machine learning model (using LightGBM & XGBoost) in order to classify people based on their interest to have a term deposit or not.\n\n\n\n\n\n\nNov 24, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nForecasting Unemployment in Greece\n\n\n\n\n\n\n\nR\n\n\nTime Series\n\n\nARIMA\n\n\n\n\nMake a prediction about the future value of Greece’s unemployment using ARIMA model.\n\n\n\n\n\n\nOct 22, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nEDA on Greek Parliament\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nGreek Parliament\n\n\n\n\nLet’s explore the MPs that got elected the most over the years (1981-2019).\n\n\n\n\n\n\nOct 10, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2022-07-27-hello/27-07-2022-hello.html",
    "href": "blog/2022-07-27-hello/27-07-2022-hello.html",
    "title": "Hello, World",
    "section": "",
    "text": "Finally, I made my site using Quarto and hosted it via GitHub Pages.\nIt was a month ago, that I decided to start building my website. Initially, I was experimenting with other frameworks (e.g., Hugo with the help of blogdown, Distill), which were pretty good, but Quarto fulfilled my needs. The reasons for my decision are going to be discussed in a new article."
  },
  {
    "objectID": "blog/2022-07-27-hello/27-07-2022-hello.html#last-updated-on",
    "href": "blog/2022-07-27-hello/27-07-2022-hello.html#last-updated-on",
    "title": "Hello, World",
    "section": "Last updated on",
    "text": "Last updated on\n\n\n[1] \"2022-11-24\""
  },
  {
    "objectID": "blog/2022-07-27-hello/27-07-2022-hello.html#acknowledgments",
    "href": "blog/2022-07-27-hello/27-07-2022-hello.html#acknowledgments",
    "title": "Hello, World",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nImage by R. E. Beck from Pixabay"
  },
  {
    "objectID": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html",
    "href": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html",
    "title": "Verify your commits !",
    "section": "",
    "text": "It’s not a long time ago that I have started to use Git. I am constantly discovering new things. All this time I was reading articles, posts on Stackoverflow etc. One day I was watchsaw a Verified badge on someones’ repository commit history.\nThen the first questions arised.\n\n“What is that ?”  “Why I don’t have it ?”  “Do I need that ?”\n\n\n\n\n\n\n\nSSH vs GitHub for commit\n\n\n\nIn reality, when you have make a commit via your GitHub account your commit is indeed marked as verified but the majority of the users is working locally thus they have set SSH. Those are in need to set up GPG in order to sign their commits and push their changes."
  },
  {
    "objectID": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#what-if-i-do-not-verify",
    "href": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#what-if-i-do-not-verify",
    "title": "Verify your commits !",
    "section": "What if I do not verify",
    "text": "What if I do not verify\nTHe thing is that I realised\nA\nBut then"
  },
  {
    "objectID": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#create-pgp-key",
    "href": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#create-pgp-key",
    "title": "Verify your commits !",
    "section": "Create PGP key",
    "text": "Create PGP key\nGitHub has a wonderful explanation , so I won’t bother you to say the same things. You can see their guide here\nFor brevity, I will make a TL;DR version :"
  },
  {
    "objectID": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#signing-your-commits",
    "href": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#signing-your-commits",
    "title": "Verify your commits !",
    "section": "Signing your commits",
    "text": "Signing your commits\nAfter that you can continue your usual workflow with Git with just a little change. Now you have to sign your commits. To do that you have to set the option -S as follows :\ngit commit -S -m \"Edit something\"\nThen, you will be prompted to a new window in order to complete the password of your GPG key. And here it is, my first verified commit :\n\n\n\nVerified Commit on GitHub\n\n\nLet’s take a closer look :\n\n\n\nVerified Commit on GitHub\n\n\nBut there is more. On GitHub settings (Settings > SSH and GPG keys) there is also the option to warn others if a commit is not signed. If I enable it :\n\n\n\nSettings for unsigned commits\n\n\nthen it marks all my unsigned commits (before and after the change) as unverified, as a warning to others. I guess it’s good if someones’ intention is to use only signed commits.\n\n\n\nSettings for unsigned commits"
  },
  {
    "objectID": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#to-sum-up",
    "href": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#to-sum-up",
    "title": "Verify your commits !",
    "section": "To sum up",
    "text": "To sum up\nIn GitHub, Commit = Sign + Commit\nLocally,  - bash git commit -m \"...\" = Commit  - bash git commit -S -m \"...\" = Sign + Commit"
  },
  {
    "objectID": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#sources",
    "href": "blog/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#sources",
    "title": "Verify your commits !",
    "section": "Sources",
    "text": "Sources\n\nGithub Documentation Page for GPG keys\nAdding a GPG key to your GitHub account"
  },
  {
    "objectID": "blog/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html",
    "href": "blog/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html",
    "title": "List of Quarto Websites",
    "section": "",
    "text": "Given the increased popularity of Quarto, I took the initiative to make a list of some sites that are using this framework. That way, users of other popular frameworks (e.g., distill, blogdown) will have the chance to see the features of a Quarto site. Furthermore, existing Quarto users can take some inspiration from other web pages.\nUnfortunately, it is certain, that this list does not contain all the Quarto pages. Although, you are welcome to edit the page (to add yours) or comment on this article."
  },
  {
    "objectID": "blog/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#list-of-quarto-sites",
    "href": "blog/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#list-of-quarto-sites",
    "title": "List of Quarto Websites",
    "section": "List of Quarto Sites",
    "text": "List of Quarto Sites\nAn indicative list of websites using Quarto is as follows:\n\n\n\n\n\n\n\n\n   User\n\n   Website URL\n\n   GitHub  Repository\n\n\n\nandrewheiss\nnonprofitf22.classes.andrewheiss.com\nnonprofitf22.classes.andrewheiss.com\n\n\nbeatrizmilz\nbeamilz.com\nblog-en\n\n\nBioconductor\nbioconductor.github.io/biocblog/\nbiocblog\n\n\ndjnavarro\nblog.djnavarro.net/\nquarto-blog\n\n\njhelvy\n–\njhelvy_quarto\n\n\njoelnitta\njoelnitta.com\njoelnitta-home\n\n\nnjlyon0\nnjlyon0.github.io\nnjlyon0.github.io\n\n\nquarto-dev\nquarto.org\nquarto-web\n\n\nshamindras\nshamindras.com\nss_personal_distill_blog\n\n\nstesiam\nstesiam.github.io\nstesiam.github.io\n\n\nvbaliga\nvbaliga.github.io\nvbaliga.github.io"
  },
  {
    "objectID": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html",
    "href": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "",
    "text": "When someone starts with Machine Learning he usually starts to build some simple models as logistic regression, naive Bayes, linear regression etc. And those alone are already enough for most use cases, as their simplicity is productivity-friendly and comes up with adequate accuracy. However, in enterprise level, accuracy can be important for a lot of reasons. Gradient Boosting Machines are some algorithms which outperform the aforementioned methods and are not complex enough to use them. Of course, before we build the model with (e.g. tidymodels) we have to install them.\n\n\n\nError - Missing LightGBM install\n\n\nThus, on this article I gather all that information.\n\n\n\nInstallation Guides\nSource\n\n\n\n\nLightGBM\nLink\n\n\nCatBoost\nLink\n\n\nXGBoost\nLink"
  },
  {
    "objectID": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#lightgbm",
    "href": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#lightgbm",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "LightGBM",
    "text": "LightGBM\n\nOption 1. Install R Package\nIf you are reading this blog, the most possible scenario in that you are using R too. The most easy way to install the corresponding R package :\n\n\nR code\n\nstart_time_lightgbm <- Sys.time()\ninstall.packages(\"lightgbm\", repos = \"https://cran.r-project.org\")\nend_time_lightgbm <- Sys.time()\n\n\n\nOption 2. CMAKE\nThe LightGBM documentation are referring to this method of installation.\n\n\nTerminal\n\nsudo apt install cmake\n\n\n\nTerminal\n\ngit clone --recursive https://github.com/microsoft/LightGBM\ncd LightGBM\nmkdir build\ncd build\ncmake ..\nmake -j4"
  },
  {
    "objectID": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#catboost",
    "href": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#catboost",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "CatBoost",
    "text": "CatBoost\nTheir realeases.\n\n\nR code\n\ninstall.packages(\"devtools\")\n\nOn my occassion, when I tried to install devtools had an error status. According to my error status I had to add packages libharfbuzz-dev and libfribidi-dev. After that, my devtools installation completed without errors.\n\n\n\nR code\n\nstart_time_catboost <- Sys.time()\ndevtools::install_url(\"https://github.com/catboost/catboost/releases/download/v1.1.1/catboost-R-Linux-1.1.1.tgz\"[, INSTALL_opts = c(\"--no-multiarch\", \"--no-test-load\")])\nend_time_catboost <- Sys.time()"
  },
  {
    "objectID": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#xgboost",
    "href": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#xgboost",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "XGBoost",
    "text": "XGBoost\n\n\nR code\n\nstart_time_xgboost <- Sys.time()\ninstall.packages(\"xgboost\")\nend_time_xgboost <- Sys.time()"
  },
  {
    "objectID": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#summary",
    "href": "blog/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#summary",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "Summary",
    "text": "Summary\n\n\n\nML Model\nMethod\nInstallation time\n\n\n\n\nLightGBM\nR package\n7.79 min.\n\n\nCatBoost\nR package (w/o devtools)\n2.1 min.\n\n\nXGBoost\nR package\n6.16 min."
  },
  {
    "objectID": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html",
    "href": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html",
    "title": "Git Series (Part I - Configuration)",
    "section": "",
    "text": "A Version Control System (VCS) is a way to manage and track code changes. As we build an application, we add functions, change frontend features, fix bugs. We will need to edit the code many times. So we need a way to manage these changes. The tracking of every change to our code is the key point of VCS.\n\n\nWorkflow without Version Control\n\n\nSome popular Version Control Software are the following :\n\nGit\nApache Subversion (SVN)\nMercurial\nBazaar\n\nHaving seen what a VCS is, it would be interesting to see which one is the most widely used. In order to study which VCS is the most popular, I pulled data from Google Trends.\n\n\n\n\n\n\n\nCodetrends_vcs_tidy %>%\n  ggplot(aes(x= Month, y = counts)) +\n  geom_line(aes(color = VCS)) +\n  labs(title = \"Trends on Version Control Systems\",\n              subtitle = \"Compare trends of Git and SVN (Subversion) from 2004 to 2022\",\n              caption = \"Data source: Google Trends\") +\n  theme_classic()\n\n\n\n\nThe figure above makes clear the dominance of Git as a version control tool. Also, we notice that Subversion (SVN) was quite popular and a capable competitor of Git until 2010. After that period there is a continuous decline in SVN’s interest and the exact opposite for Git. Today, in 2022, the difference is chaotic between them.\n\n\nWhy should I use VCS ?\n\n\nEasy transition between versions\nMore productive, Time saver if a version produces error\nEnables cooperation with other developers (especially with a hosting service like GitHub).\n\n\nOk. There are some good points. But where is the catch ?\n\n\nWe are adding a new tool to our workflow (Git)\nKind of steep learning curve.\n\nWe have mentioned some of the most important programs for managing the code of an application. Of course, there are not a few times when we want to save the progress of our application somewhere else to enable developers communicate their code commits to each other. The solution is some code hosting services. The best known are GitHub, GitLab and Bitbucket. Finally, in case none of the options outlined earlier satisfy us, there is also the self-host solution. For example, if I had concerns about the terms of the above services, I could host Gitea on my own server or even to rent a cloud server. That way I would have my own “GitHub”, without depending on a third party service."
  },
  {
    "objectID": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#git-settings",
    "href": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#git-settings",
    "title": "Git Series (Part I - Configuration)",
    "section": "Git settings",
    "text": "Git settings\nSet up Name & Email\nSo, you decided to start Git without setting Name and Email?\nYou may think of it again. In case you try to commit without setting a Name and email. Git will not commit your changes, without prior setting those.\n\n\nTerminal\n\ngit config --global user.name \"YourName\"\ngit config --global user.email your_email\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are planning to host your repository on GitHub, you may want to hide your casual email. In that case GitHub offers a noreply email for this purpose. You can read more here.\n\n\nSet editor\n[Edit…]\n\n\nTerminal\n\ngit config --global core.editor \"editor_name\"\n\n\n\nEditor\nCommand\n\n\n\nAtom\nTitle\n\n\nVim\nText\n\n\nDefault branch name to main\nIn October of 2020, GitHub announced that will change the default name of initial branch from master to main. \n\nThe default branch name for new repositories is now main. GitHub.blog - October 1,2020\n\nTherefore, it would be good to make this change in our local environment as well, as follows :\n\n\nTerminal\n\ngit config --global init.defaultBranch main\n\nMerge method\nOne change that is not exactly necessary but helps me is to change the defaults regarding merge. Let’s say that I want to add a new feature in my application. Most of the times I will make a branch on which I will start developing my new feature. When I implement this function and I’m ready to merge my changes into the main code there are two situations.\n1. There are commits to main branch \nThe predefined action is to merge. The branch is visible. Our setting has not any effect on this case.\n2. There are no commits to main branch\nThe predefined action of Git is to take the feature branch and paste it on the top of main branch. By making the setting above I am telling Git to keep the branch and react like the first case. The branch is visible again.\nWith simple words, I am forcing Git to keep branch, regardless of changes to main branch.\n\n\nTerminal\n\ngit config --global merge.ff false\n\nAuto-sign your commits\nIn a previous article we saw how to sign our commits as well as the reasons for doing so. In short, we made a PGP key which we added to our GitHub account. From that moment to sign my commits I had to write git commit -S -m \"something\", instead of git commit -m \"something\". Of course, that method is a little bit problematic. It is a little bit longer, little different in comparison to what I am used to type and most importantly I may forget some times to sign it manually. The last one happened to me A LOT. Thankfully, there is a way to be carefree about that anymore. I can set git config in a way that my commits will be signed automatically.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do not have already a GPG key, you can have a look in this guide in order to generate one. Also, depending your hosting platform for your code, you can link your GPG with your account : \n\n\nGitHub and GPG keys \n\n\nBitBucket and GPG keys \n\nGitLab and GPG keys\n\n\n\n\n\nTerminal\n\ngpg --list-secret-keys --keyid-format LONG\ngit config user.signingkey key_id\ngit config commit.gpgsign true\n\nCheck your settings\nMaking the above settings, we can have a summary of those with the corresponding command:\n\n\nTerminal\n\ngit config --list\n\nHere is the output on my machine :\n\n\nOutput of git-config command\n\n\nThe image above sums up the settings of Git. Although, each user has different needs and for that reason it would be good in case you want to learn more about git config to see their documentation page."
  },
  {
    "objectID": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#to-sum-up",
    "href": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#to-sum-up",
    "title": "Git Series (Part I - Configuration)",
    "section": "To sum up",
    "text": "To sum up\nA summary of the commands we used to configure Git :\n\n\nTerminal\n\ngit config --global user.name \"YourName\"\ngit config --global user.email your_email\ngit config --global core.editor \"editor_name\"\ngit config --global init.defaultBranch main\ngit config --global merge.ff false\n\n# Add PGP key to your commits\n\ngpg --list-secret-keys --keyid-format LONG\ngit config user.signingkey key_id\ngit config commit.gpgsign true\n\n# check git config settings\n\ngit config --list --show-origin\n\nOf course you can access your git config file on your Home directory (at least on Ubuntu installation).\n\n\n\n\n\n\nWarning\n\n\n\nNote that the .gitconfig file, which contains our settings, may not be visible in the Home directory. In general, files whose names begin with a period are not displayed. However, if everything has been done correctly, it’s probably there. For example, in Ubuntu you should choose to show hidden files.\n\n\nIn case you open that file you will see probably something like the above :"
  },
  {
    "objectID": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#acknowledgements",
    "href": "blog/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#acknowledgements",
    "title": "Git Series (Part I - Configuration)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nImage by Daniel Skovran from Pixabay"
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "",
    "text": "Καλησπέρα σας.\nΠρώτο άρθρο στα ελληνικά και ελπίζω να μην τα γράφω τζάμπα και καποιος, κάπου, κάποτε να βρει αυτή τη σελίδα αν ποτέ τη χρειαστεί. :)\nΠροϋποθέσεις για να συμπεριληφθεί κάτι στη σελίδα :\n\nΝα είναι δωρεάν\nΝα είναι στα ελληνικά\nΝα είναι κατανοητό για όλο το φάσμα των χρηστών της R"
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βιβλία-για-την-r",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βιβλία-για-την-r",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "Βιβλία για την R",
    "text": "Βιβλία για την R\n\n\n\n\n\n\n\n\nΤίτλος βιβλίου\nΣυγγραφέας\nΣύνδεσμος\n\n\n\n\nΕισαγωγή στην R Πρόχειρες σημειώσεις\nΦωκιανός, Κ.  Χαραλάμπους, Χ.\nΣύνδεσμος  (απευθείας κατέβασμα)\n\n\nΕισαγωγή στον προγραμματισμό και στη στατιστική ανάλυση με R\nΝτζούφρας, Ι.  Καρλής, Δ.\nΣύνδεσμος\n\n\nΗ επιστήμη των δεδομένων μέσα από τη γλώσσα R\nΒερύκιος, Β.  Καγκλής, Β.  Σταυρόπουλος, Η.\nΣύνδεσμος\n\n\nΕισαγωγή στην επιχειρησιακή έρευνα και στον γραμμικό προγραμματισμό\nΚουνέτας, Κ  Χατζησταμούλου, Ν.\nΣύνδεσμος\n\n\nΕισαγωγή στην εκπαιδευτική και ψυχολογική μέτρηση με τη χρήση της R\nAlbano, A.  Markos, A. (tr)\nΣύνδεσμος\n\n\n\nΔυστυχώς, οι επιλογές μας σε σχέση με το υλικό που υπάρχει στα αγγλικά (ελεύθερα διαθέσιμο) είναι αρκετά περιορισμένες. Ωστόσο, υπάρχουν κάποιες πολύ καλές επιλογές (ανάλογα το επίπεδο και τον σκοπό του χρήστη).\nΗ πρώτη μου επιλογή (και προσωπικά η αγαπημένη μου) είναι το βιβλίο “Εισαγωγή στην R - Πρόχειρες σημειώσεις”. Είναι ένας συνδυασμός σημειώσεων και εφαρμογής των εντολών για κατηγορίες προβλημάτων. Αναφέρεται σε ένα μεγάλο εύρος θεμάτων (κυρίως στατιστικής), από τα πιο απλά (έλεγχοι t-test) μέχρι πιο σύνθετα θέματα (ανάλυση κατά συστάδες). Πολύ καλό για φοιτητές στατιστικής (μάλλον για αυτό μου αρέσει).\nΗ δεύτερη επιλογή (“Εισαγωγή στον προγραμματισμό και στη στατιστική ανάλυση με R”) κινείται σε παρόμοια νερά. Είναι ένα βιβλίο που με προβλημάτισε κάπως. Αυτό το βιβλίο είχε τα φόντα να γίνει το προσωπικό μου αγαπημένο, διότι δεν σου δείχνει απλά τις εντολές. Σου μαθαίνει να προγραμματίζεις με την R, αφού δίνει μεγαλύτερη σημασία σε ελέγχους ροής, συναρτήσεις και άλλα θέματα. Αυτό είναι πολύ σημαντικό, αν θες να φτιάξεις κάτι πιο περίπλοκο (π.χ. μία περίπλοκη ανάλυση, ένα πακέτο στην R, κτλ.). Αν και προγραμματισμός μαθαίνεται κυρίως κάνοντας και όχι διαβαζοντας πιστεύω ότι είναι μία καλή προσθήκη στη λίστα.\nΗ τρίτη μου επιλογή είναι το “Επιστήμη των δεδομένων μέσα από τη γλώσσα R”. Πιθανότατα αυτό το βιβλίο πλησιάζει περισσότερο στη λογική των notebooks και στο να ανεβάσεις δικά σου project. Σε βάζει σε μία λογική να αρχίσεις να κάνεις αναλύσεις. Καλό, αν κάποιος θέλει να φτιάξει το δικό του portfolio, προκειμένου κάποτε να βρει μία δουλειά (εγώ με αυτή την ελπίδα ζω ακόμα :) ). Προσωπικά πιστεύω ότι είναι καλό για κάποιον που έχει ήδη κάποια εξοικείωση στην R.\nΤα τελευταία 2 βιβλία της λίστας μου αφορούν εξειδικευμένα θέματα, συνεπώς προορίζονται για ανθρώπους με πολύ συγκεκριμένους σκοπούς."
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βίντεομαθήματα-για-την-r",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βίντεομαθήματα-για-την-r",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "Βίντεομαθήματα για την R",
    "text": "Βίντεομαθήματα για την R\n\n\n\n\n\n\n\nΌνομα καναλιού\nΣύνδεσμος\n\n\n\n\nChristos Malliarakis\nΣύνδεσμος\n\n\n\nΠέρα όμως από τα βιβλία έψαξα να βρω και υλικό για την R στο Youtube. Το υλικό είναι επίσης αρκετά περιορισμένο. Προς το παρόν θα αφήσω μία επιλογή η οποία είναι και η πιο πλήρης. Στη σειρά βιντεομαθημάτων (playlist) του κ. Χρήστου Μαλλιαράκη γίνεται μία αναφορά σε βασικά στοιχεία της R ενώ σε επόμενα μαθήματα ασχολείται με κάποια απλά παραδείγματα μηχανικής μάθησης."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "All posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nAsylum applicants in Europe\n\n\n\n\n\n\n\nR\n\n\nEurostat\n\n\n\n\nCreate a Europe map based on the number of asylum applications per country.\n\n\n\n\n\n\nJan 8, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Cost of Housing in Kallithea\n\n\n\n\n\n\n\nR\n\n\nRegression\n\n\n\n\nBuild a regression model using various ML algorithms to predict cost to buy a house in Kallithea.\n\n\n\n\n\n\nDec 6, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Possible Interested Clients\n\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\n\n\nBuild a classification machine learning model (using LightGBM & XGBoost) in order to classify people based on their interest to have a term deposit or not.\n\n\n\n\n\n\nNov 24, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nInstall LightGBM and CatBoost on Ubuntu 22.04\n\n\n\n\n\n\n\nLinux\n\n\nLightGBM\n\n\nCatBoost\n\n\nXGBoost\n\n\n\n\nInstall high performance algorithms (LightGBM, CatBoost & XGBoost) on your Linux device\n\n\n\n\n\n\nNov 13, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nGit Series (Part I - Configuration)\n\n\n\n\n\n\n\nGit\n\n\n\n\nAn article that brings together some configuration setttings of Git. A beginner’s approach to Git.\n\n\n\n\n\n\nNov 4, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nForecasting Unemployment in Greece\n\n\n\n\n\n\n\nR\n\n\nTime Series\n\n\nARIMA\n\n\n\n\nMake a prediction about the future value of Greece’s unemployment using ARIMA model.\n\n\n\n\n\n\nOct 22, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nEDA on Greek Parliament\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nGreek Parliament\n\n\n\n\nLet’s explore the MPs that got elected the most over the years (1981-2019).\n\n\n\n\n\n\nOct 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nVerify your commits !\n\n\n\n\n\n\n\nGPG\n\n\nQuarto\n\n\n\n\nUsing GPG keys to add a signature to your GitHub commits\n\n\n\n\n\n\nOct 3, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nList of Quarto Websites\n\n\n\n\n\n\n\nQuarto\n\n\n\n\nA collection of websites built with Quarto. Includes links to websites and their respective repositories. Further additions are always welcome.\n\n\n\n\n\n\nAug 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nHello, World\n\n\n\n\n\n\n\nfirst article\n\n\n\n\nMy first article on my Quarto website.\n\n\n\n\n\n\nJul 27, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html",
    "href": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html",
    "title": "Asylum applicants in Europe",
    "section": "",
    "text": "Introduction \n\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset \n\n\nDescriptive Statistics \n\n\nMaking Map    4.1 Shapefile    4.2 Visualization \n\nReferences"
  },
  {
    "objectID": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#import-libraries",
    "href": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#import-libraries",
    "title": "Asylum applicants in Europe",
    "section": "Import Libraries",
    "text": "Import Libraries\n\nShow the code# General purpose R libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(kableExtra)\n\n# Data packages\n\nlibrary(eurostat)\n\n# Packages for maps\n\nlibrary(ggplot2)\nlibrary(sf)\n\n\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, François, Henry, & Müller, 2022). The kableExtra (Zhu, 2021) package was used to print the results in table format. Also, I use eurostat (Lahti, Huovari, Kainu, & Biecek, 2022) package to analyze Eurostat data.\nIn order to make the visualization (map with asylum applicants) I will need (as always) ggplot2 (Wickham, Chang, et al., 2022) and sf (Pebesma, 2022)."
  },
  {
    "objectID": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#import-dataset",
    "href": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#import-dataset",
    "title": "Asylum applicants in Europe",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading the libraries I am able to use the commands of the readr package to import my data. My data is in .csv format, so I’ll use the read_csv() command (Wickham, Hester, et al., 2022) to import them.\nAdditionally, I choose not to include EA-19 values (as I investigate Greece’s unemployment).\n\nShow the codeasylum_applicants = read_csv(\"data/Asylum_applicants_EU_2021.csv\")\n\nasylum_applicants_time_series = read_csv(\"data/tps00191_linear.csv\")"
  },
  {
    "objectID": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#preview-dataset",
    "href": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#preview-dataset",
    "title": "Asylum applicants in Europe",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nShow the code#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_dataset = head(asylum_applicants, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %>%\n  kable_paper() %>%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\n DATAFLOW \n    LAST UPDATE \n    freq \n    citizen \n    sex \n    unit \n    age \n    asyl_app \n    geo \n    TIME_PERIOD \n    OBS_VALUE \n    OBS_FLAG \n  \n\n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    AT \n    2021 \n    39900 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    BE \n    2021 \n    24970 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    BG \n    2021 \n    11000 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    CH \n    2021 \n    14850 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    CY \n    2021 \n    13670 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    CZ \n    2021 \n    1405 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    DE \n    2021 \n    190545 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    DK \n    2021 \n    2080 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    EE \n    2021 \n    80 \n    NA \n  \n\n ESTAT:TPS00191(1.0) \n    29/08/22 23:00:00 \n    A \n    EXT_EU27_2020 \n    TRUE \n    PER \n    TOTAL \n    ASY_APP \n    EL \n    2021 \n    28355 \n    NA"
  },
  {
    "objectID": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#shapefile",
    "href": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#shapefile",
    "title": "Asylum applicants in Europe",
    "section": "Shapefile",
    "text": "Shapefile\n\nShow the codeSHP_0 <- get_eurostat_geospatial(resolution = 10, \n                                 nuts_level = 0, \n                                 year = 2016)\n\nSHP_0 %>% \n  ggplot() +\n  geom_sf()"
  },
  {
    "objectID": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#visualization",
    "href": "notebooks/2023-01-08-Asylum-Applicants/2022-01-08-Asylum-Applicants.html#visualization",
    "title": "Asylum applicants in Europe",
    "section": "Visualization",
    "text": "Visualization\n\nShow the codeEU27 <- eu_countries %>% \n  filter(code != 'UK') %>% \n  select(geo = code, name)\n\nSHP_27 <- SHP_0 %>% \n  select(geo = NUTS_ID, geometry) %>% \n  inner_join(EU27, by = \"geo\") %>% \n  arrange(geo) %>% \n  st_as_sf()\n\nSHP_27 %>% \n  ggplot(fill = values) +\n  geom_sf() +\n  scale_x_continuous(limits = c(-10, 35)) +\n  scale_y_continuous(limits = c(35, 65)) +\n    labs(\n    title = \"Asylum Applicants (2021)\",\n    subtitle = \"Annual % of change, 2020 vs 2019\",\n    caption = \"Data: Eurostat\"\n  ) +\n  theme_void() +\n  theme(\n    legend.position = c(0.97, 0.50)\n  )\n\n\n\n\n\nShow the codeasylum_applicants_shp = asylum_applicants %>%\n  select(geo, OBS_VALUE) %>%\n  inner_join(SHP_27, by = \"geo\") %>% \n  st_as_sf()\n#asylum_applicants_shp\n\n\n\nShow the codeasylum_applicants_shp  %>% \n  ggplot(aes(fill = OBS_VALUE)) +\n  geom_sf() +\n  scale_fill_distiller(\n    palette = 12,\n    direction = 1   # reverse default order\n  ) +\n  scale_x_continuous(limits = c(-10, 35)) +\n  scale_y_continuous(limits = c(35, 65)) +\n  theme_void() +\n    labs(\n    title = \"Asylum Applicants (2021)\",\n    subtitle = \"Total applications of people seeking for asylum in EU. \",\n    caption = \"Data: Eurostat\"\n  ) +\n  theme_void() +\n  theme(\n    legend.position = c(0.97, 0.50))"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html",
    "title": "EDA on Greek Parliament",
    "section": "",
    "text": "Introduction\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset    2.4 Structure of Dataset    2.5 Recoding variables    2.6 Setting colors \n\n\nParliament over the years \n\n\nMost elected members of parliament \n\n\nMost elected members by party    5.1 KKE    5.2 ND    5.3 PASOK    5.4 SYRIZA \n\n\nMost elected members per constituency    6.1 Attica    6.2 Central Greece    6.3 Central Macedonia    6.4 Crete    6.5 Eastern Macedonia and Thrace    6.6 Epirus    6.7 Ionian Islands    6.8 North Aegean    6.9 Peloponnese    6.10 South Aegean    6.11 Thessaly    6.12 Western Greece    6.13 Western Macedonia \n\nAcknowledgements\n\nReferences"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-libraries",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-libraries",
    "title": "EDA on Greek Parliament",
    "section": "Import Libraries",
    "text": "Import Libraries\nFirst and foremost, we have to load our libraries.\n\nShow the code# General purpose R libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggpol) \nlibrary(ggtext)\n\n# Other settings\noptions(digits=2) # print only 2 decimals"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-dataset",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading R libraries, then I will load my data.\n\nShow the codeparliament <- read_csv(\"data/greek_parliament.csv\")"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#preview-dataset",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#preview-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nShow the codepreview_dataset = head(parliament, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %>%\n  kable_paper() %>%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\nTable 1:  Preview Dataset (first 6 rows) \n \n FullName \n    Party \n    Constituency \n    Term \n  \n\n\n Agorastis Vasileios \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Larissa \n    3 \n  \n\n Akrita Sylva - Kaiti \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Athens B \n    3 \n  \n\n Akritidis Nikolaos \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Thessaloniki A \n    3 \n  \n\n Akrivakis Alexandros \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Viotia \n    3 \n  \n\n Alevras Ioannis \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Athens A \n    3 \n  \n\n Alexandris Efstathios (Stathis) \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Athens B \n    3 \n  \n\n Alexiadis Konstantinos \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Trikala \n    3 \n  \n\n Alexiou Thomas \n    NEA DIMOKRATIA \n    Xanthi \n    3 \n  \n\n Allamanis Stylianos \n    NEA DIMOKRATIA \n    Karditsa \n    3 \n  \n\n Amanatidis Konstantinos \n    PA.SO.K. (Panhellenic Socialist Movement) \n    Thessaloniki B \n    3"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#structure-of-dataset",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#structure-of-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Structure of Dataset",
    "text": "Structure of Dataset\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nFull Name\n\nqualitative  (nominal)\nSurname and name of the member of parliament\n\n\nParty\n\nqualitative  (nominal)\nThe party on which the MP got elected\n\n\nConstituency\n\nqualitative  (nominal)\nMP got elected on this area\n\n\nTerm\n\nqualitative  (ordinal)\nPlenum term\n\n\n\nThus, my sample has 4 variables, of which 0 are quantitative and 4 are quantitative properties, of which 3 are nominal and the rest one (Term) is ordinal."
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#recoding-variables",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#recoding-variables",
    "title": "EDA on Greek Parliament",
    "section": "Recoding variables",
    "text": "Recoding variables\n\nShow the codetable(parliament$Party)\n\n\n\nShow the code## Recoding parliament$Party\nparliament$Party[parliament$Party == \"ANEXARTITOI DIMOKRATIKOI VOULEFTES\"] <- \"ADP\"\nparliament$Party[parliament$Party == \"ANEXARTITOI ELLINES (Independent Hellenes)\"] <- \"ANEL\"\nparliament$Party[parliament$Party == \"ANEXARTITOI ELLINES (Independent Hellenes) National Patriotic Democratic Alliance\"]<- \"ANEL\"\nparliament$Party[parliament$Party == \"Coalition of the Left and Progress\"] <- \"SYRIZA\"\nparliament$Party[parliament$Party == \"Communist Party of Greece (Interior)\"] <- \"KKE (interior)\"\nparliament$Party[parliament$Party == \"DEMOCRATIC COALITION (Panhellenic Socialist Movement Democratic Left )\"] <- \"PASOK\"\nparliament$Party[parliament$Party == \"DHM.AR (Democratic Left)\"] <- \"DHMAR\"\nparliament$Party[parliament$Party == \"DI.ANA.\"] <- \"DIANA\"\nparliament$Party[parliament$Party == \"DI.K.KI.\"] <- \"DIKKI\"\nparliament$Party[parliament$Party == \"INDEPENDENT\"] <- \"INDEPENDENT\"\nparliament$Party[parliament$Party == \"KOMMOUNISTIKO KOMMA ELLADAS\"] <- \"KKE\"\nparliament$Party[parliament$Party == \"LA.O.S.\"] <- \"LAOS\"\nparliament$Party[parliament$Party == \"LAIKI ENOTITA\"] <- \"LAE\"\nparliament$Party[parliament$Party == \"LAIKOS SYNDESMOS - CHRYSI AVGI (People’s Association – Golden Dawn)\"] <- \"XA\"\nparliament$Party[parliament$Party == \"NEA DIMOKRATIA\"] <- \"ND\"\nparliament$Party[parliament$Party == \"PA.SO.K. (Panhellenic Socialist Movement)\"] <- \"PASOK\"\nparliament$Party[parliament$Party == \"POL.A.\"] <- \"POLA\"\nparliament$Party[parliament$Party == \"SYNASPISMOS RIZOSPASTIKIS ARISTERAS\"] <- \"SYRIZA\"\nparliament$Party[parliament$Party == \"TO POTAMI (The River)\"] <- \"POTAMI\"\nparliament$Party[parliament$Party == \"ΟΟ.ΕΟ.\"] <- \"ΟΟ.ΕΟ\""
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#setting-colors",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#setting-colors",
    "title": "EDA on Greek Parliament",
    "section": "Setting colors",
    "text": "Setting colors\nA few days after, I decided that there should be a consistency in the choice of colors. That’s the reason of this section. Set a hex color for each party.\n\nShow the codekke_color = \"#FF6666\"\nnd_color = \"#0492c2\"\npasok_color = \"#95bb72\"\nsyriza_color = \"#e27bb1\""
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#kke",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#kke",
    "title": "EDA on Greek Parliament",
    "section": "KKE",
    "text": "KKE\n\nShow the codeparty_plot(\"KKE\", \"#FF6666\", times_elected_min = 5)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#nd",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#nd",
    "title": "EDA on Greek Parliament",
    "section": "ND",
    "text": "ND\n\nShow the codeparty_plot(\"ND\", \"#0492c2\", times_elected_min = 10)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#pasok",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#pasok",
    "title": "EDA on Greek Parliament",
    "section": "PASOK",
    "text": "PASOK\n\nShow the codeparty_plot(\"PASOK\", \"#95bb72\", times_elected_min = 10)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#syriza",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#syriza",
    "title": "EDA on Greek Parliament",
    "section": "SYRIZA",
    "text": "SYRIZA\n\nShow the codeparty_plot(\"SYRIZA\", \"#e27bb1\", times_elected_min = 5)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#state",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#state",
    "title": "EDA on Greek Parliament",
    "section": "State",
    "text": "State\n\nShow the codeconstituency_freqs(\"State\", 3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#attica",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#attica",
    "title": "EDA on Greek Parliament",
    "section": "Attica",
    "text": "Attica\n\n\nAthens A\nAthens B\nPiraeus A\nPiraeus B\nOf Attica (rest)\n\n\n\n\nShow the codeconstituency_freqs(\"Athens A\",5)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Athens B\",7)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Piraeus A\",5)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Piraeus B\",5)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Of Attica (rest)\",5)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-greece",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-greece",
    "title": "EDA on Greek Parliament",
    "section": "Central Greece",
    "text": "Central Greece\n\n\nViotia\nEvrytania\nFokida\nFthiotida\n\n\n\n\nShow the codeconstituency_freqs(\"Viotia\",5)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Evrytania\",2)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Fokida\",2)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Fthiotida\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-macedonia",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-macedonia",
    "title": "EDA on Greek Parliament",
    "section": "Central Macedonia",
    "text": "Central Macedonia\n\n\nThessaloniki A\nThessaloniki B\nKilkis\nPella\nPieria\nSerres\nHalkidiki\n\n\n\n\nShow the codeconstituency_freqs(\"Thessaloniki A\",6)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Thessaloniki B\",6)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kilkis\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Pella\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Pieria\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Serres\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Halkidiki\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#crete",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#crete",
    "title": "EDA on Greek Parliament",
    "section": "Crete",
    "text": "Crete\n\n\nChania\nHeraklion\nLasithi\nRethymno\n\n\n\n\nShow the codeconstituency_freqs(\"Chania\",3)\n\n\n\n\n\n\n\nShow the code#constituency_freqs(\"Irakleio\",3)\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lasithi\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Rethymno\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#eastern-macedonia-and-thrace",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#eastern-macedonia-and-thrace",
    "title": "EDA on Greek Parliament",
    "section": "Eastern Macedonia and Thrace",
    "text": "Eastern Macedonia and Thrace\n\n\nDrama\nEvros\nKavala\nXanthi\nRodopi\n\n\n\n\nShow the codeconstituency_freqs(\"Drama\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Evros\",4)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kavala\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Xanthi\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Rodopi\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#epirus",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#epirus",
    "title": "EDA on Greek Parliament",
    "section": "Epirus",
    "text": "Epirus\n\n\nArta\nIoannina\nPreveza\nThesprotia\n\n\n\n\nShow the codeconstituency_freqs(\"Arta\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Ioannina\",4)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Preveza\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Thesprotia\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#ionian-islands",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#ionian-islands",
    "title": "EDA on Greek Parliament",
    "section": "Ionian Islands",
    "text": "Ionian Islands\n\n\nCorfu\nKefallonia\nLefkada\nZakynthos\n\n\n\n\nShow the codeconstituency_freqs(\"Corfu\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kefallonia\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lefkada\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Zakynthos\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#north-aegean",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#north-aegean",
    "title": "EDA on Greek Parliament",
    "section": "North Aegean",
    "text": "North Aegean\n\n\nChios\nLesvos\nSamos\n\n\n\n\nShow the codeconstituency_freqs(\"Chios\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lesvos\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Samos\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#peloponnese",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#peloponnese",
    "title": "EDA on Greek Parliament",
    "section": "Peloponnese",
    "text": "Peloponnese\n\n\nArgolida\nArkadia\nKorinthia\nLakonia\nMessinia\n\n\n\n\nShow the codeconstituency_freqs(\"Argolida\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Arcadia\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Korinthia\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lakonia\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Messinia\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#south-aegean",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#south-aegean",
    "title": "EDA on Greek Parliament",
    "section": "South Aegean",
    "text": "South Aegean\n\n\nDodecanese Islands\nCyclades\n\n\n\n\nShow the codeconstituency_freqs(\"Dodecanese Islands\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Cyclades\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#thessaly",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#thessaly",
    "title": "EDA on Greek Parliament",
    "section": "Thessaly",
    "text": "Thessaly\n\n\nKarditsa\nLarissa\nMagnesia\nTrikala\n\n\n\n\nShow the codeconstituency_freqs(\"Karditsa\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Larissa\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Magnesia\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Trikala\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-greece",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-greece",
    "title": "EDA on Greek Parliament",
    "section": "Western Greece",
    "text": "Western Greece\n\n\nAchaia\nAitoloakarnania\nIleia\n\n\n\n\nShow the codeconstituency_freqs(\"Achaia\",3)\n\n\n\n\n\n\n\nShow the code#constituency_freqs(\"Aitoloakarnania\",3)\n\n\n\n\n\nShow the codeconstituency_freqs(\"Ileia\",3)"
  },
  {
    "objectID": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-macedonia",
    "href": "notebooks/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-macedonia",
    "title": "EDA on Greek Parliament",
    "section": "Western Macedonia",
    "text": "Western Macedonia\n\n\nFlorina\nGrevena\nKastoria\nKozani\n\n\n\n\nShow the codeconstituency_freqs(\"Florina\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Grevena\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kastoria\",3)\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kozani\",3)"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html",
    "title": "Predict Possible Interested Clients",
    "section": "",
    "text": "Introduction\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset    2.4 Dataset Structure    2.5 Custon Functions \n\n\nEDA with R    3.1 Missing Values    3.2 Univariate Analysis        3.2.1 Qualitative variables        3.2.2 Quantitative variables    3.3 Bivariate Analysis        3.3.1 Qualitative variables        3.3.2 Quantitative variables \n\n\nBuilding Model    4.1 Split train/test Dataset    4.2 Recipes    4.3 Create Validation Set    4.4 Specify Models    4.5 Hyperparameters tuning    4.6 Fit Resamples    4.7 Evaluate Model    4.8 Last Fit \n\n\nResults"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-libraries",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-libraries",
    "title": "Predict Possible Interested Clients",
    "section": "Import libraries",
    "text": "Import libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, François, Henry, & Müller, 2022). The kableExtra (Zhu, 2021) package was used to print the results in table format. Concerning general purpose R libraries, I also used gridExtra in order to show ggplot items side to side.\nOn its basis this analysis is about to predict if someone is interested or not to have a term deposit. Thus, we need to build a ML model. The all-in-one solution package tidymodels is crucial to this. Although, there are some concerns about our data (imbalanced predicted value and our implementation of LightGBM. Thankfully, these are solved by bonsai and treesnip packages, respectively.\nFinally, the ggplot2 (Wickham, Chang, et al., 2022) package was used to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nShow the code# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(kableExtra)\nlibrary(gridExtra)\n\n# Build ML models\nlibrary(tidymodels)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Other R packages\nlibrary(fontawesome)\n\n\n# Build ML models\n\nlibrary(tidymodels)\nlibrary(bonsai)\nlibrary(themis)\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-dataset",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading R libraries, then I will load my data. The initial source of my dataset has various versions of the same dataset. I will use the smaller one, as the fitting process on Boosting algorithms it is more time consuming in comparison with other methods (e.g. Logistic Regression, k-Nearest Neighbors etc.).\n\nShow the codebank_dataset <- read_delim(\"bank_dataset_files/bank.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#preview-dataset",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#preview-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Preview dataset",
    "text": "Preview dataset\nHere we can see a small chunk of my dataset (first 10 rows / observations) just to understand the dataset’s structure and type of variables.\n\nShow the code#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_bank_dataset = head(bank_dataset, 10)\nkbl(preview_bank_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %>%\n  kable_paper() %>%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\n age \n    job \n    marital \n    education \n    default \n    balance \n    housing \n    loan \n    contact \n    day \n    month \n    duration \n    campaign \n    pdays \n    previous \n    poutcome \n    y \n  \n\n\n 30 \n    unemployed \n    married \n    primary \n    no \n    1787 \n    no \n    no \n    cellular \n    19 \n    oct \n    79 \n    1 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 33 \n    services \n    married \n    secondary \n    no \n    4789 \n    yes \n    yes \n    cellular \n    11 \n    may \n    220 \n    1 \n    339 \n    4 \n    failure \n    no \n  \n\n 35 \n    management \n    single \n    tertiary \n    no \n    1350 \n    yes \n    no \n    cellular \n    16 \n    apr \n    185 \n    1 \n    330 \n    1 \n    failure \n    no \n  \n\n 30 \n    management \n    married \n    tertiary \n    no \n    1476 \n    yes \n    yes \n    unknown \n    3 \n    jun \n    199 \n    4 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 59 \n    blue-collar \n    married \n    secondary \n    no \n    0 \n    yes \n    no \n    unknown \n    5 \n    may \n    226 \n    1 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 35 \n    management \n    single \n    tertiary \n    no \n    747 \n    no \n    no \n    cellular \n    23 \n    feb \n    141 \n    2 \n    176 \n    3 \n    failure \n    no \n  \n\n 36 \n    self-employed \n    married \n    tertiary \n    no \n    307 \n    yes \n    no \n    cellular \n    14 \n    may \n    341 \n    1 \n    330 \n    2 \n    other \n    no \n  \n\n 39 \n    technician \n    married \n    secondary \n    no \n    147 \n    yes \n    no \n    cellular \n    6 \n    may \n    151 \n    2 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 41 \n    entrepreneur \n    married \n    tertiary \n    no \n    221 \n    yes \n    no \n    unknown \n    14 \n    may \n    57 \n    2 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 43 \n    services \n    married \n    primary \n    no \n    -88 \n    yes \n    yes \n    cellular \n    17 \n    apr \n    313 \n    1 \n    147 \n    2 \n    failure \n    no"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#dataset-structure",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#dataset-structure",
    "title": "Predict Possible Interested Clients",
    "section": "Dataset structure",
    "text": "Dataset structure\nBefore we do any analysis we have to define what kind of data we have available. We can assess this type of information by looking on the values of each variable. Generally, we can classify our variables, depending their values, as follows :\n\n\nShow the codegraph TD;\n  A(Type of variables) --> B(Quantitative)\n  A(Type of variables) --> C(Qualitative)\n  B --> D(Discrete)\n  B --> E(Continuous)\n  C --> J(Nominal)\n  C --> G(Ordinal)\n\n\n\n\ngraph TD;\n  A(Type of variables) --> B(Quantitative)\n  A(Type of variables) --> C(Qualitative)\n  B --> D(Discrete)\n  B --> E(Continuous)\n  C --> J(Nominal)\n  C --> G(Ordinal)\n\n\n\n\n\n\n\n\n\nOur dataset is consisted by 17 variables (columns) and 4521 observations (rows). More specifically, concerning my variables, are as follows :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nAge\n\nquantitative  (continuous)\nThe age of the respondent\n\n\nJob\n\nqualitative  (nominal)\nThe sector of employment of the respondent\n\n\nMarital\n\nqualitative  (nominal)\nThe marital status of the respondent\n\n\nEducation\n\nqualitative  (ordinal)\nThe higher education level that the respondent has ever reached\n\n\nDefault\n\nqualitative  (nominal)\nhas credit in default?\n\n\nBalance\n\nquantitative  (continuous)\nAverage yearly balance, in euros\n\n\nHousing\n\nqualitative  (nominal)\nHas housing loan?\n\n\nLoan\n\nqualitative  (nominal)\nHas personal loan?\n\n\nContact\n\nqualitative  (nominal)\nContact communication type\n\n\nMonth\n\nqualitative  (ordinal)\nLast contact day of the month\n\n\nDuration\n\nquantitative  (continuous)\nLast contact duration, in seconds (numeric)\n\n\nCampaign\nquantitative\nNumber of contacts performed during this campaign and for this client\n\n\npdays\nquantitative\nNumber of days that passed by after the client was last contacted from a previous campaign\n\n\npprevious\nquantitative\nNumber of contacts performed before this campaign and for this client\n\n\npoutcome\n\nqualitative (nominal)\nOutcome of the previous marketing campaign\n\n\nDeposit\n\nqualitative  (nominal)\nHas the client subscribed a term deposit?\n\n\n\nThus, my sample has 17 variables, of which 7 are quantitative and 10 are quantitative properties, of which 8 are nominal and the rest ones (Education, Month) are ordinal.\n\nShow the codebank_dataset$y = as.factor(bank_dataset$y)"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#custom-functions",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#custom-functions",
    "title": "Predict Possible Interested Clients",
    "section": "Custom functions",
    "text": "Custom functions\n\nSo, I have a basic idea about my data. Can we start analyzing our data?\n\nIt depends. If you want to do a simple analysis then yes. Although most of the times this is not the case. Probably there is the need for repetitive actions. In order to not repeat ourselves we need to define some actions, prior to our analysis.\nOn this occasion, I found beneficial the definition of a function for qualitative data.\n\nShow the codeunivariate_qualitative = function(variable, title_plot){\ntable = bank_dataset %>%\n    select(variable) %>%\n    table() %>%\n    prop.table() %>%\n    as.data.frame() %>%\n    magrittr::set_colnames(c(\"Var1\", \"Freq\"))\n  \nplot =  ggplot(data = table, aes(x = fct_reorder(Var1,Freq, .desc = T), fill=Var1, y = Freq)) + \n     geom_bar(stat = \"identity\")+\n     scale_fill_hue(c = 40) +\n     geom_text(aes(label = sprintf(\"%.2f %%\", Freq*100),  stat=\"identity\",\n        vjust = -.1)) +\n     labs(\n       title = title_plot,\n       caption = \"Bank Marketing Dataset from <b>UCI</b>\",\n       x = \"Response\",\n       y = \"Observations\"\n        ) +\n     theme_classic() +\n     theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5),)\n  \nreturn(plot)\n}\n\n\nI will do the same for univariate numeric data.\n\nShow the codeuniv_quanti = function(variable_sel){\n  ggplot(bank_dataset, aes(x = variable_sel )) +\n  geom_histogram(x = variable_sel, stat = \"count\") +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Age Distribution of Respondents\",\n    caption = \"Bank Marketing Dataset from <b>UCI</b>\",\n    x = \"Age of Respondent\",\n    y = \"Observations\"\n  ) +\n  theme_classic() + \n  theme(\n    plot.caption = element_markdown(lineheight = 1.2),\n    plot.title = element_text(hjust = 0.5))\n}"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#missing-values",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#missing-values",
    "title": "Predict Possible Interested Clients",
    "section": "Missing Values",
    "text": "Missing Values\n\nShow the codehow_many_nas = sum(is.na(bank_dataset))\n\n\nOn this dataset there are 0 missing values, in total. So, there is no need for imputation."
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#univariate-analysis",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#univariate-analysis",
    "title": "Predict Possible Interested Clients",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nQualitative variables\n\n\nJob\nMarital status\nEducation\nDefault\nHousing\nLoan\nContact\nMonth\npoutcome\nDeposit\n\n\n\n\nShow the codeunivariate_qualitative(\"job\", \"Job of Respondent\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"marital\", \"Marital Status of the respondent\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"education\", \"Educational Backgroung\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"default\", \"Has credit in default ?\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"housing\", \"Has housing loan?\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"loan\", \"Has personal loan ?\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"contact\", \"Type of Contact\")\n\n\n\n\n\n\n\n\n\n\nShow the codeoptions(digits =2)\n\nperc_month = table(bank_dataset$month) %>%\n  prop.table() %>%\n  sort(decreasing = T) %>%\n  as.data.frame()\n\nnum_month = table(bank_dataset$month) %>%\n  sort(decreasing = T) %>%\n  as.data.frame()\n\nperc_month %>%\n    ggplot(aes(x = factor(Var1, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), y = Freq)) + \n  geom_bar(stat = \"identity\")+\n  scale_fill_hue(c = 40) +\n  geom_text(aes(label = sprintf(\"%.2f\", Freq*100),  stat=\"identity\",\n        vjust = -.25)) +\n  labs(\n    title = \"Calls per month\",\n    caption = \"Bank Marketing Dataset from <b>UCI</b>\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"poutcome\", \"Outcome of previous approach\")\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"y\", \"How many people made a deposit account ?\")\n\n\n\n\n\n\n\n\n\n\nQuantitative variables\n\n\nAge\nBalance\nDuration\nCampaign\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x = age )) +\n  geom_bar() +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Age Distribution of Respondents\",\n    caption = \"Bank Marketing Dataset from <b>UCI</b>\",\n    x = \"Age of Respondent\",\n    y = \"Observations\"\n  ) +\n  theme_classic() + \n  theme(\n    plot.caption = element_markdown(lineheight = 1.2),\n    plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\nShow the code# NOTE : In order to make HTML tags to work I need to specify element on theme command.\n\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x=balance)) + \n  geom_histogram(bins = 20) +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Average yearly balance\",\n    caption = \" Bank Marketing Data Set from <b>UCI</b>\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x=duration, fill=duration)) + \n  geom_histogram( ) +\n  scale_fill_hue(c = 40) +\n  theme_bw() +\n  labs(\n    title = \"How many people made a deposit account ?\",\n    caption = \"Data from the 1974 Motor Trend US magazine.\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x= campaign, fill=campaign )) + \n  geom_bar() +\n  scale_fill_hue(c = 40) +\n  theme_bw() +\n  labs(\n    title = \"Number of Approaches to a specific person\",\n    x = \"# of Approaches\",\n    y = \"Observations\"\n  ) + \n  theme_classic()"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#bivariate-analysis",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#bivariate-analysis",
    "title": "Predict Possible Interested Clients",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nOn the previous section I learned a lot about my dataset. Now, I have to reveal relationships between my variables. Visualizing those relationships will make it even easier to explain our results. In order to make the right plots on the right occasions I used the book “Datavis with R” (Chapter 4 : Bivariate Graphs).\nQualitative variables\n\n\nJob\nMarital status\nEducation\nDefault\nHousing\nLoan\nContact\nMonth\npoutcome\n\n\n\n\nShow the codeplotjob <- bank_dataset %>%\n  group_by(job, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct))\n\nplot_job = ggplot(plotjob, \n       aes(x = fct_reorder(job, pct),\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Job of Respondent by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\nplot_job\n\n\n\n\n\n\n\nShow the codeplot_marital1 <- ggplot(bank_dataset, \n       aes(x = marital, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n       geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplotmarital <- bank_dataset %>%\n  group_by(marital, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct))\n\nplot_marital2 = ggplot(plotmarital, \n       aes(x = marital,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Marital Status by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nShow the codegridExtra::grid.arrange(plot_marital1, plot_marital2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_education1 <- ggplot(bank_dataset, \n       aes(x = education, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n       geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_education2 = bank_dataset %>%\n  group_by(education, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %>%\n    ggplot(aes(x = education,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Educational Background by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nShow the codegridExtra::grid.arrange(plot_education1, plot_education2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_default1 <- ggplot(bank_dataset, \n       aes(x = default, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_default2 = bank_dataset %>%\n  group_by(default, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %>%\n    ggplot(aes(x = default,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Has credit in default ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'default'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_default1, plot_default2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_housing1 <- ggplot(bank_dataset, \n       aes(x = housing, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_housing2 = bank_dataset %>%\n  group_by(housing, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %>%\n    ggplot(aes(x = housing,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Has housing loan ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'housing'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_housing1, plot_housing2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_loan1 <- ggplot(bank_dataset, \n       aes(x = loan, \n           fill = y)) + \n      scale_fill_hue(c = 40) +\n      theme_bw() +\n      geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_loan2 = bank_dataset %>%\n  group_by(loan, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %>%\n    ggplot(aes(x = loan,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Has personal loan ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'loan'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_loan1, plot_loan2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_contact1 <- ggplot(bank_dataset, \n       aes(x = contact, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_contact2 = bank_dataset %>%\n  group_by(contact, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %>%\n    ggplot(aes(x = contact,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Forms of contact\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'contact'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_contact1, plot_contact2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_month1 <- ggplot(bank_dataset, \n       aes(x = factor(month, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_month2 <- ggplot(bank_dataset, \n       aes(x = factor(month, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), fill = y)) + \n       geom_bar(position = \"fill\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal()\n\n\n\nShow the codegridExtra::grid.arrange(plot_month1, plot_month2, nrow =1)\n\n\n\n\n\n\n\nShow the codeplot_poutcome1 <- ggplot(bank_dataset, \n       aes(x = poutcome, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_poutcome2 = bank_dataset %>%\n  group_by(poutcome, y) %>%\n  summarize(n = n()) %>% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %>%\n   ggplot(aes(x = poutcome,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Previous Campaign outcome\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nShow the codegridExtra::grid.arrange(plot_poutcome1, plot_poutcome2, nrow =1)\n\n\n\n\n\n\n\nQuantitative variables\n\n\nAge\nBalance\nDuration\nCampaign\n\n\n\n\nShow the codebank_dataset %>%\nggplot(aes(x=y, y=age, fill=y)) +\n  geom_boxplot() +\n  scale_fill_hue(c = 40) +\n  theme_classic() +\n  labs(\n     title = \"Age & Desire of Bank Deposit Account\" \n  )\n\n\n\n\n\n\n\nShow the codeplot1 = bank_dataset[bank_dataset$balance < 15000, ] %>%\nggplot(aes(x = balance, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_histogram(bins=15)\n\nplot1\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, \n       aes(x = duration, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, \n       aes(x = campaign, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#split-traintest-dataset",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#split-traintest-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Split train/test dataset",
    "text": "Split train/test dataset\nOur first step is to split our dataset on 2 parts. Each of those will be used for a different purpose. The first part’s (train dataset) purpose is to build our model. The other part (test dataset) will be used to evaluate our model’s performance.\n\nShow the codeset.seed(123)\nbank_dataset_split <- initial_split(bank_dataset,\n                                prop = 0.75,\n                                strata = y)\n\n# Create training data\nbank_train <- bank_dataset_split %>%\n                    training()\n\n# Create testing data\nbank_test <- bank_dataset_split %>%\n                    testing()\n\n\n\n\nTrain dataset\nTest dataset\n\n\n\n\nShow the codehead(bank_train) %>%\n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n age \n    job \n    marital \n    education \n    default \n    balance \n    housing \n    loan \n    contact \n    day \n    month \n    duration \n    campaign \n    pdays \n    previous \n    poutcome \n    y \n  \n\n\n 30 \n    unemployed \n    married \n    primary \n    no \n    1787 \n    no \n    no \n    cellular \n    19 \n    oct \n    79 \n    1 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 33 \n    services \n    married \n    secondary \n    no \n    4789 \n    yes \n    yes \n    cellular \n    11 \n    may \n    220 \n    1 \n    339 \n    4 \n    failure \n    no \n  \n\n 30 \n    management \n    married \n    tertiary \n    no \n    1476 \n    yes \n    yes \n    unknown \n    3 \n    jun \n    199 \n    4 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 59 \n    blue-collar \n    married \n    secondary \n    no \n    0 \n    yes \n    no \n    unknown \n    5 \n    may \n    226 \n    1 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 36 \n    self-employed \n    married \n    tertiary \n    no \n    307 \n    yes \n    no \n    cellular \n    14 \n    may \n    341 \n    1 \n    330 \n    2 \n    other \n    no \n  \n\n 39 \n    technician \n    married \n    secondary \n    no \n    147 \n    yes \n    no \n    cellular \n    6 \n    may \n    151 \n    2 \n    -1 \n    0 \n    unknown \n    no \n  \n\n\n\n\n\n\n\nShow the codehead(bank_test) %>%\n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n age \n    job \n    marital \n    education \n    default \n    balance \n    housing \n    loan \n    contact \n    day \n    month \n    duration \n    campaign \n    pdays \n    previous \n    poutcome \n    y \n  \n\n\n 35 \n    management \n    single \n    tertiary \n    no \n    1350 \n    yes \n    no \n    cellular \n    16 \n    apr \n    185 \n    1 \n    330 \n    1 \n    failure \n    no \n  \n\n 35 \n    management \n    single \n    tertiary \n    no \n    747 \n    no \n    no \n    cellular \n    23 \n    feb \n    141 \n    2 \n    176 \n    3 \n    failure \n    no \n  \n\n 31 \n    blue-collar \n    married \n    secondary \n    no \n    360 \n    yes \n    yes \n    cellular \n    29 \n    jan \n    89 \n    1 \n    241 \n    1 \n    failure \n    no \n  \n\n 44 \n    services \n    single \n    secondary \n    no \n    106 \n    no \n    no \n    unknown \n    12 \n    jun \n    109 \n    2 \n    -1 \n    0 \n    unknown \n    no \n  \n\n 45 \n    blue-collar \n    divorced \n    primary \n    no \n    844 \n    no \n    no \n    unknown \n    5 \n    jun \n    1018 \n    3 \n    -1 \n    0 \n    unknown \n    yes \n  \n\n 37 \n    technician \n    single \n    secondary \n    no \n    228 \n    yes \n    no \n    cellular \n    20 \n    aug \n    1740 \n    2 \n    -1 \n    0 \n    unknown \n    no"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#recipes",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#recipes",
    "title": "Predict Possible Interested Clients",
    "section": "Recipes",
    "text": "Recipes\nAn important part in the process of model building is preprocessing. Depending of model type and data structure, I have to do the necessary changes. The tidymodels offers some ready-made preprocessing functions which make the whole process piece of cake.\nIn instance, the dataset I am working right now has imbalanced response variable (term deposit interest). For that reason, I used the recipe step_smote() from themis package.\n\nShow the codebank_recipe <- recipes::recipe(y~., \n                               data = bank_train) %>%\n  step_rm(poutcome) %>%\n  step_corr(all_numeric(), threshold = 0.75) %>%\n  step_dummy(all_nominal(), -all_outcomes()) %>% prep() %>%\n  step_smote(y) %>%\n  prep()\n\n\nLet’s preview our dataset after applying our recipes :\n\nShow the codebank_recipe %>%\n  prep() %>%\n  juice() %>%\n  head() %>%\n  kbl() %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\nTable 1:  Dataset after recipes \n \n age \n    balance \n    day \n    duration \n    campaign \n    pdays \n    previous \n    job_blue.collar \n    job_entrepreneur \n    job_housemaid \n    job_management \n    job_retired \n    job_self.employed \n    job_services \n    job_student \n    job_technician \n    job_unemployed \n    job_unknown \n    marital_married \n    marital_single \n    education_secondary \n    education_tertiary \n    education_unknown \n    default_yes \n    housing_yes \n    loan_yes \n    contact_telephone \n    contact_unknown \n    month_aug \n    month_dec \n    month_feb \n    month_jan \n    month_jul \n    month_jun \n    month_mar \n    month_may \n    month_nov \n    month_oct \n    month_sep \n    y \n  \n\n\n 30 \n    1787 \n    19 \n    79 \n    1 \n    -1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    no \n  \n\n 33 \n    4789 \n    11 \n    220 \n    1 \n    339 \n    4 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    1 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    no \n  \n\n 30 \n    1476 \n    3 \n    199 \n    4 \n    -1 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    no \n  \n\n 59 \n    0 \n    5 \n    226 \n    1 \n    -1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    no \n  \n\n 36 \n    307 \n    14 \n    341 \n    1 \n    330 \n    2 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    no \n  \n\n 39 \n    147 \n    6 \n    151 \n    2 \n    -1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    1 \n    0 \n    1 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    no"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#create-validation-set",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#create-validation-set",
    "title": "Predict Possible Interested Clients",
    "section": "Create validation set",
    "text": "Create validation set\n\nSo, how good is the model? Not so fast…\n\nWe could actually build the model and evaluate its performance. The problem with that approach is the sample.\n\nShow the codecv_folds <- recipes::bake(\n  bank_recipe,\n  new_data = bank_train) %>%\n  rsample::vfold_cv(v = 5, strata = y)"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#specify-models",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#specify-models",
    "title": "Predict Possible Interested Clients",
    "section": "Specify models",
    "text": "Specify models\nNext, parsnip helps us to specify our models. Initially, I will define a LightGBM model,\n\nShow the codelightgbm_model<- parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %>%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\nand an XGBoost one.\n\nShow the codexgboost_model<- parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %>%\n set_engine(\"xgboost\")"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#hyperparameters-tuning",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#hyperparameters-tuning",
    "title": "Predict Possible Interested Clients",
    "section": "Hyperparameters tuning",
    "text": "Hyperparameters tuning\nNow, we are specifying the hyperpaterers’ values and a grid to check whicη combination of those are performing better according to our desired metric (in our case ROC). This has to be done for both, LightGBM\n\nShow the codelightgbm_params <- dials::parameters(\n min_n(),\n tree_depth(range = c(4,10)),\n learn_rate() # learning rate\n)\n\n\n\nShow the codelightgbm_grid <- dials::grid_max_entropy(\n lightgbm_params,\n size = 10)\n\nhead(lightgbm_grid) %>%\n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n min_n \n    tree_depth \n    learn_rate \n  \n\n\n 3 \n    5 \n    0.00 \n  \n\n 3 \n    7 \n    0.00 \n  \n\n 11 \n    10 \n    0.00 \n  \n\n 33 \n    4 \n    0.08 \n  \n\n 10 \n    5 \n    0.01 \n  \n\n 31 \n    9 \n    0.00 \n  \n\n\n\n\nand XGBoost.\n\nShow the codexgboost_params <- dials::parameters(\n min_n(),\n tree_depth(range = c(4,10)),\n learn_rate() # learning rate\n)\n\n\n\nShow the codexgboost_grid <- dials::grid_max_entropy(\n  xgboost_params,\n  size = 10\n)\n\nhead(xgboost_grid) %>%\n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n min_n \n    tree_depth \n    learn_rate \n  \n\n\n 5 \n    6 \n    0.00 \n  \n\n 4 \n    8 \n    0.00 \n  \n\n 37 \n    9 \n    0.00 \n  \n\n 2 \n    5 \n    0.00 \n  \n\n 21 \n    9 \n    0.01 \n  \n\n 21 \n    5 \n    0.05"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#fit-resamples",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#fit-resamples",
    "title": "Predict Possible Interested Clients",
    "section": "Fit resamples",
    "text": "Fit resamples\n\nShow the code# build workflow for LightGBM\n\nlightgbm_workflow <- workflows::workflow() %>%\n add_model(lightgbm_model) %>%\n add_formula(y ~.)\n\n\n\nShow the code# build workflow for XGBoost\n\nxgboost_workflow <- workflows::workflow() %>%\n  add_model(xgboost_model) %>%\n  add_formula(y~.)\n\n\nFinally, we can build the LightGBM model by combining :\n\nThe workflows we set it up above\nThe resamples\nGrid of values (hyperparameters)\nMetric based on which we will evaluate our model’s performance\n\n\nShow the codestart_time_lightgbm <- Sys.time()\n\nlightgbm_tuned_model <- tune::tune_grid(\n object = lightgbm_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = lightgbm_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)\n\nend_time_lightgbm <- Sys.time()\n\ntime_lightgbm = difftime(end_time_lightgbm,start_time_lightgbm,units = \"secs\")\n\n\nSimilarly, for XGBoost.\n\nShow the codestart_time_xgboost <- Sys.time()\n\nxgboost_tuned_model <- tune::tune_grid(\n object = xgboost_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = xgboost_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)\n\nend_time_xgboost <- Sys.time()\n\ntime_xgboost= difftime(end_time_xgboost,start_time_xgboost,units = \"secs\")"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#evaluate-model",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#evaluate-model",
    "title": "Predict Possible Interested Clients",
    "section": "Evaluate model",
    "text": "Evaluate model\nOur first results based on resamples for LightGBM\n\nShow the codelightgbm_tuned_model %>%\n  show_best(\"roc_auc\",n=5) %>% \n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n min_n \n    tree_depth \n    learn_rate \n    .metric \n    .estimator \n    mean \n    n \n    std_err \n    .config \n  \n\n\n 33 \n    4 \n    0.08 \n    roc_auc \n    binary \n    0.90 \n    5 \n    0.01 \n    Preprocessor1_Model04 \n  \n\n 16 \n    10 \n    0.06 \n    roc_auc \n    binary \n    0.90 \n    5 \n    0.01 \n    Preprocessor1_Model10 \n  \n\n 10 \n    5 \n    0.01 \n    roc_auc \n    binary \n    0.89 \n    5 \n    0.01 \n    Preprocessor1_Model05 \n  \n\n 34 \n    10 \n    0.00 \n    roc_auc \n    binary \n    0.86 \n    5 \n    0.01 \n    Preprocessor1_Model07 \n  \n\n 29 \n    6 \n    0.00 \n    roc_auc \n    binary \n    0.86 \n    5 \n    0.01 \n    Preprocessor1_Model09 \n  \n\n\n\n\nand XGBoost\n\nShow the codexgboost_tuned_model %>%\n  show_best(\"roc_auc\",n=5) %>% \n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n min_n \n    tree_depth \n    learn_rate \n    .metric \n    .estimator \n    mean \n    n \n    std_err \n    .config \n  \n\n\n 21 \n    5 \n    0.05 \n    roc_auc \n    binary \n    0.88 \n    5 \n    0.01 \n    Preprocessor1_Model06 \n  \n\n 21 \n    9 \n    0.01 \n    roc_auc \n    binary \n    0.85 \n    5 \n    0.01 \n    Preprocessor1_Model05 \n  \n\n 5 \n    6 \n    0.00 \n    roc_auc \n    binary \n    0.84 \n    5 \n    0.01 \n    Preprocessor1_Model01 \n  \n\n 40 \n    5 \n    0.00 \n    roc_auc \n    binary \n    0.83 \n    5 \n    0.01 \n    Preprocessor1_Model08 \n  \n\n 19 \n    7 \n    0.00 \n    roc_auc \n    binary \n    0.83 \n    5 \n    0.01 \n    Preprocessor1_Model07"
  },
  {
    "objectID": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#last-fit",
    "href": "notebooks/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#last-fit",
    "title": "Predict Possible Interested Clients",
    "section": "Last fit",
    "text": "Last fit\nBy now we can assess which is the best combination of values. Given those I will assess my model’s performance on unknown (to my model) data. LightGBM model has 0.8469 ROC-value\n\nShow the codelast_fit_lightgbm_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = 33,\n learn_rate = 0.0787,\n tree_depth = 4) %>%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\n\nShow the codeoptions(digits = 4)\n\nlast_fit_workflow <- lightgbm_workflow %>% \n  update_model(last_fit_lightgbm_model)\n\nlast_lightgbm_fit <- \n  last_fit_workflow %>% \n  last_fit(bank_dataset_split)\n\n! train/test split: preprocessor 1/1, model 1/1: NAs introduced by coercion\n\n\n! train/test split: preprocessor 1/1, model 1/1 (predictions): NAs introduced by coercion\n\nShow the codelast_lightgbm_fit %>% \n  collect_metrics() %>%\n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n .metric \n    .estimator \n    .estimate \n    .config \n  \n\n\n accuracy \n    binary \n    0.8815 \n    Preprocessor1_Model1 \n  \n\n roc_auc \n    binary \n    0.8458 \n    Preprocessor1_Model1 \n  \n\n\n\n\nand XGBoost, 0.8736.\n\nShow the codelast_fit_xgboost_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = 21,\n learn_rate = 0.0472,\n tree_depth = 5) %>%\nset_engine(\"xgboost\")\n\n\n\nShow the codeoptions(digits = 4)\n\nlast_fit_xgboost_workflow <- xgboost_workflow %>% \n  update_model(last_fit_xgboost_model)\n\nlast_xgboost_fit <- \n  last_fit_xgboost_workflow %>% \n  last_fit(bank_dataset_split)\n\nlast_xgboost_fit %>% \n  collect_metrics() %>%\n  kbl(toprule = T,align = 'c',booktabs = T)  %>%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n .metric \n    .estimator \n    .estimate \n    .config \n  \n\n\n accuracy \n    binary \n    0.8957 \n    Preprocessor1_Model1 \n  \n\n roc_auc \n    binary \n    0.8702 \n    Preprocessor1_Model1"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html",
    "title": "Forecasting Unemployment in Greece",
    "section": "",
    "text": "Introduction \n\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Datasset    2.4 Dataset Structure    2.5 Time Series Preprocessing \n\n\nMissing Values \n\n\nDescriptive Statistics \n\n\nExamine Stationarity    5.1 Definition of stationarity    5.2 Examine Stationarity Graphically    5.3 Examine Stationarity with Statistical Tests      5.3.1 ADF test      5.3.2 PP test      5.3.3 KPSS test \n\n\nIdentify Model \n\n\nBuild Time Series Model \n\n\nCompare Models \n\n\nForecast Future Unemployment    9.1 ARIMA (0,2,1) forecasts    9.2 ARIMA (9,2,1) forecasts \n\nResults"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#background",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#background",
    "title": "Forecasting Unemployment in Greece",
    "section": "Background",
    "text": "Background"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series",
    "title": "Forecasting Unemployment in Greece",
    "section": "Time series",
    "text": "Time series"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#procedure",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#procedure",
    "title": "Forecasting Unemployment in Greece",
    "section": "Procedure",
    "text": "Procedure"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#short-answer",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#short-answer",
    "title": "Forecasting Unemployment in Greece",
    "section": "Short Answer",
    "text": "Short Answer\nIf you are in a hurry, I predicted that unemployment on Greece is expected to further reduce. It will range between 10% - 13% in February, 2023."
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-libraries",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-libraries",
    "title": "Forecasting Unemployment in Greece",
    "section": "Import Libraries",
    "text": "Import Libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, François, Henry, & Müller, 2022). The kableExtra (Zhu, 2021) package was used to print the results in table format, while the flextable (Gohel & Skintzos, 2022) package was used to print the results of the Dickey-Fuller and KPSS tests.\nThen, due to the nature of the data (time series) it was deemed necessary to use relevant libraries such as lubridate(Spinu, Grolemund, & Wickham, 2021), tseries(Trapletti & Hornik, 2022) & forecast(R. Hyndman et al., 2022) packages.\nFinally, the ggplot2 (Wickham, Chang, et al., 2022) package was used to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nShow the code# General purpose R libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(kableExtra)\nlibrary(flextable)\n\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Time Series \n\nlibrary(lubridate)\nlibrary(tseries)\nlibrary(forecast)\n\n# Other settings\noptions(digits=2) # print only 2 decimals"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-dataset",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-dataset",
    "title": "Forecasting Unemployment in Greece",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading the libraries I am able to use the commands of the readr package to import my data. My data is in .csv format, so I’ll use the read_csv() command (Wickham, Hester, et al., 2022) to import them.\nAdditionally, I choose not to include EA-19 values (as I investigate Greece’s unemployment).\n\nShow the codeunemployment <- read_csv(\"data/unemployment.csv\") %>%\n  select(LOCATION, TIME, Value) %>% filter(LOCATION != \"EA19\")"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#preview-dataset",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#preview-dataset",
    "title": "Forecasting Unemployment in Greece",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nShow the code#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_dataset = head(unemployment, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %>%\n  kable_paper() %>%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\n LOCATION \n    TIME \n    Value \n  \n\n\n GRC \n    1998-04 \n    11 \n  \n\n GRC \n    1998-05 \n    11 \n  \n\n GRC \n    1998-06 \n    11 \n  \n\n GRC \n    1998-07 \n    11 \n  \n\n GRC \n    1998-08 \n    11 \n  \n\n GRC \n    1998-09 \n    11 \n  \n\n GRC \n    1998-10 \n    11 \n  \n\n GRC \n    1998-11 \n    11 \n  \n\n GRC \n    1998-12 \n    11 \n  \n\n GRC \n    1999-01 \n    11"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#dataset-structure",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#dataset-structure",
    "title": "Forecasting Unemployment in Greece",
    "section": "Dataset Structure",
    "text": "Dataset Structure\nOur dataset is consisted by 3 variables (columns). More specifically, concerning my variables, are as follows :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nLOCATION\n\nqualitative  (nominal)\nSpecific country’s statistics\n\n\nTIME\n\nqualitative  (ordinal)\nMonth of the reported data\n\n\nValue\n\nquantitative  (continuous)\nUnemployment at the given Time and Country\n\n\n\nThus, my sample has 3 variables, of which 2 are qualitative and 1 is quantitative property."
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series-preprocessing",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series-preprocessing",
    "title": "Forecasting Unemployment in Greece",
    "section": "Time Series Preprocessing",
    "text": "Time Series Preprocessing\nThe TIME variable needs to be a Date variable which is not fulfilled on our case.\n\nShow the codesapply(unemployment, class) %>% kbl() %>% kable_styling(full_width = F, position = \"center\")\n\n\n\n\n   \n    x \n  \n\n\n LOCATION \n    character \n  \n\n TIME \n    character \n  \n\n Value \n    numeric \n  \n\n\n\n\nSo, above I see that I have dates in a format “YYYY-MM” (Year - Month) and they are considered as characters. With the help of lubridate package I will convert my time series on a Date format.\n\nShow the codeunemployment$TIME <- lubridate::ym(unemployment$TIME)\n\n\nAnd let’s check again :\n\nShow the codesapply(unemployment, class) %>% kbl() %>% kable_styling(full_width = F, position = \"center\")\n\n\n\n\n   \n    x \n  \n\n\n LOCATION \n    character \n  \n\n TIME \n    Date \n  \n\n Value \n    numeric \n  \n\n\n\n\nAnd now I got the Date format. I am able to continue my analysis."
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#definition-of-stationarity",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#definition-of-stationarity",
    "title": "Forecasting Unemployment in Greece",
    "section": "Definition of stationarity",
    "text": "Definition of stationarity\nAn important concept in studying time series is stationarity. A time series is called stationary (“Applied Time Series Analysis,” n.d.) if: \n\n\nE(X_t) = \\text{constant} \n\nVar(X_t) = \\text{constant} \nCov(X_t, X_s) = \\text{constant}"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-graphically",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-graphically",
    "title": "Forecasting Unemployment in Greece",
    "section": "Examine Stationarity Graphically",
    "text": "Examine Stationarity Graphically\n\n\nLevel\nFirst Diff.\nSecond Diff.\n\n\n\nIt is apparent that there is a big variation on the values of unemployment. This time series is not stationary and the differencing is justified.\n\nShow the codeplot(grc_unemployment$Value,type = \"l\")\n\n\n\n\n\n\nHere we can see a big improvement in comparison with original data. I have some concerns about points close to 150 (mildly upwards trend) and 250 (outlier).\n\nShow the codegrc_unemployment_diff1 <- diff(grc_unemployment$Value, differences = 1)\n\nplot(grc_unemployment_diff1,type = \"l\")\n\n\n\n\n\n\nGiven the concerns of above, I made also a second difference plot. It seems to solve the problem on points close to 150.\n\nShow the codegrc_unemployment_diff2<- diff(grc_unemployment$Value, differences = 2)\n\nplot(grc_unemployment_diff2, type = \"l\")"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-with-statistical-tests",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-with-statistical-tests",
    "title": "Forecasting Unemployment in Greece",
    "section": "Examine Stationarity with Statistical tests",
    "text": "Examine Stationarity with Statistical tests\nThe graphical interpretation of stationarity can be beneficial for a quick assessment on topic of stationarity. However it can be considered a subjective metric, which leads on a non consistent decision (someone may consider the second figure as stationary and some others not.\nThankfully, there are some statistical tests which can help us on our decisions. Some commonly used are :\n\n\nAugmented Dickey-Fuller (ADF) test\n\nPhillips- Perron (PP) test\n\nKwiatkowski-Phillips-Schmidt-Shin (KPSS) test\n\nSummary\n\nShow the codesummary_stationarity_results <- data.frame(\n                             \"Type\" = c(\"levels\", \"Diff(GRC)\", \"Diff2(GRC)\"),\n                             \"ADF test\" = c(\"Non Stationary\", \"Stationary\", \"Stationary\"),\n                              \"PP test\" = c(\"Non Stationary\", \"Stationary\", \"Stationary\"),\n                             \"KPSS test\" =c(\"Non Stationary\", \"Non Stationary\", \"Stationary\")\n)\n\n\nsummary_stationarity_results  %>% kbl() %>% kable_styling()\n\n\n\n\n Type \n    ADF.test \n    PP.test \n    KPSS.test \n  \n\n\n levels \n    Non Stationary \n    Non Stationary \n    Non Stationary \n  \n\n Diff(GRC) \n    Stationary \n    Stationary \n    Non Stationary \n  \n\n Diff2(GRC) \n    Stationary \n    Stationary \n    Stationary \n  \n\n\n\n\nADF test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is not stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is a unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nShow the codeadf.test(grc_unemployment$Value) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-0.9\n0.9485   \n6.0\nAugmented Dickey-Fuller Test\nstationary\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\nΣυνεπώς, είναι προφανές από τα αποτελέσματα του στατιστικού ελέγχου Dickey Fuller ότι η χρονοσειρά μου δεν είναι στάσιμη. Θα πρέπει να εφαρμόσω τον έλεγχο Dickey-Fuller στις δοαφορές.\n\nShow the codeadf.test(grc_unemployment_diff1) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-3.5\n0.0424  *\n6.0\nAugmented Dickey-Fuller Test\nstationary\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\nAnd finally the results for the second differences are :\n\nShow the codeadf.test(grc_unemployment_diff2) %>% as_flextable()\n\nWarning in adf.test(grc_unemployment_diff2): p-value smaller than printed p-\nvalue\n\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-9.5\n0.0100 **\n6.0\nAugmented Dickey-Fuller Test\nstationary\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\nPP test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is not stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is a unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nShow the codepp.test(grc_unemployment$Value,) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n0.2\n0.9900   \n5.0\nPhillips-Perron Unit Root Test\nstationary\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\n\nShow the codepp.test(grc_unemployment_diff1) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-279.8\n0.0100 **\n5.0\nPhillips-Perron Unit Root Test\nstationary\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\n\nShow the codepp.test(grc_unemployment_diff2) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-337.1\n0.0100 **\n5.0\nPhillips-Perron Unit Root Test\nstationary\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\nKPSS test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is not  unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nShow the codekpss.test(grc_unemployment$Value,) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n2.5\n0.0100 **\n5.0\nKPSS Test for Level Stationarity\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\n\nShow the codekpss.test(grc_unemployment_diff1) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n0.6\n0.0231  *\n5.0\nKPSS Test for Level Stationarity\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05\n\n\n\n\n\nShow the codekpss.test(grc_unemployment_diff2) %>% as_flextable()\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n0.0\n0.1000  .\n5.0\nKPSS Test for Level Stationarity\n\nSignif. codes: 0 <= '***' < 0.001 < '**' < 0.01 < '*' < 0.05"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-021-forecasts",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-021-forecasts",
    "title": "Forecasting Unemployment in Greece",
    "section": "ARIMA (0,2,1) forecasts",
    "text": "ARIMA (0,2,1) forecasts\n\nShow the codeforecast(auto_model,6) %>% autoplot()\n\n\n\nShow the codeforecast(auto_model,6) %>% kbl() %>% kable_paper()\n\n\n\n\n   \n    Point Forecast \n    Lo 80 \n    Hi 80 \n    Lo 95 \n    Hi 95 \n  \n\n\n 294 \n    12 \n    11.5 \n    13 \n    11.2 \n    13 \n  \n\n 295 \n    12 \n    11.1 \n    13 \n    10.7 \n    13 \n  \n\n 296 \n    12 \n    10.7 \n    13 \n    10.2 \n    13 \n  \n\n 297 \n    12 \n    10.3 \n    13 \n    9.7 \n    13 \n  \n\n 298 \n    11 \n    10.0 \n    13 \n    9.2 \n    13 \n  \n\n 299 \n    11 \n    9.6 \n    13 \n    8.8 \n    14"
  },
  {
    "objectID": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-921-forecasts",
    "href": "notebooks/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-921-forecasts",
    "title": "Forecasting Unemployment in Greece",
    "section": "ARIMA (9,2,1) forecasts",
    "text": "ARIMA (9,2,1) forecasts\n\nShow the codeforecast(arimaModel_3,6) %>% autoplot()\n\n\n\nShow the codeforecast(arimaModel_3,6) %>% kbl() %>% kable_paper()\n\n\n\n\n   \n    Point Forecast \n    Lo 80 \n    Hi 80 \n    Lo 95 \n    Hi 95 \n  \n\n\n 294 \n    12 \n    11 \n    12 \n    11.1 \n    13 \n  \n\n 295 \n    12 \n    11 \n    13 \n    10.9 \n    13 \n  \n\n 296 \n    12 \n    11 \n    13 \n    10.7 \n    13 \n  \n\n 297 \n    12 \n    11 \n    13 \n    10.1 \n    13 \n  \n\n 298 \n    12 \n    10 \n    13 \n    9.8 \n    13 \n  \n\n 299 \n    12 \n    10 \n    13 \n    9.4 \n    14"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "",
    "text": "Introduction\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset    2.4 Dataset structure    2.5 Recoding variables    2.6 Custom functions \nEDA with R    3.1 Missing Values    3.2 Univariate Analysis        3.2.1 Qualitative (Nominal) variables        3.2.2 Qualitative (Ordinal) variables        3.2.2 Qualitative (Discrete) variables        3.2.2 Qualitative (Continuous) variables        3.2.2 Time series \nAcknowledgements\nReferences"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-libraries",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-libraries",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Import libraries",
    "text": "Import libraries\nIn brief,\n\nfor data entry purposes, I will use readr package (part of tidyverse)\nfor plots, ggplot2\nand building models with tidymodels\n\n\n\nShow the code\n# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(forcats)\n\n# Deal with dates\n\nlibrary(lubridate)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Build ML models\n\nlibrary(tidymodels)\nlibrary(bonsai)\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-dataset",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-dataset",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Import dataset",
    "text": "Import dataset\nAfter importing my libraries I can use readr’s, read_csv function in order to import my dataset. This dataset was retrieved from Kaggle. Some customization need to be made in order to make an efficient analysis :\n\nfilter data for apartments in Kallithea\nconvert Greek characters to English ones\n\n\n\nShow the code\ndata <- read_csv(\"kallithea.csv\")"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#preview-dataset",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#preview-dataset",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Preview dataset",
    "text": "Preview dataset\nAs usual, one of my first steps is to preview my dataset. That way I can have a first impression on my dataset and its possible problems. More specifically, the preview reveals :\n\nA LOT variables that need recoding (energyclass, solar, etc.)\nSome values on specific variables are on greek (parking)\nDuplicate ID column\nThere are missing values (!!!)\n\n\n\nShow the code\n#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n\npreview_data = head(data, 7) %>%\n  kbl(align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %>%\n  kable_paper() %>%\n  scroll_box(width = \"600px\", height = \"250px\")\n\npreview_data\n\n\n\n\n \n  \n    ...1 \n    ...2 \n    location_name \n    res_date \n    res_price \n    res_price_sqr \n    res_sqr \n    construction_year \n    levels \n    bedrooms \n    bathrooms \n    deleted \n    deleted_at \n    status \n    energyclass \n    auto_heating \n    solar \n    cooling \n    safe_door \n    gas \n    fireplace \n    furniture \n    student \n    parking \n  \n \n\n  \n    1 \n    1 \n    Kallithea \n    2022-03-09 \n    220000 \n    2558 \n    86 \n    2002 \n    2nd \n    2 \n    1 \n    1 \n    2022-04-15 \n    Excellent \n    C \n    1 \n    0 \n    1 \n    1 \n    0 \n    0 \n    1 \n    0 \n    Parking πιλωτής \n  \n  \n    2 \n    2 \n    Kallithea \n    2022-04-15 \n    180000 \n    2400 \n    75 \n    1975 \n    3rd \n    2 \n    1 \n    1 \n    2022-04-22 \n    Renovated \n    D \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    NA \n  \n  \n    3 \n    3 \n    Kallithea \n    2022-02-11 \n    180000 \n    3000 \n    60 \n    2022 \n    1st \n    2 \n    1 \n    1 \n    2022-04-14 \n    Excellent \n    A+ \n    1 \n    1 \n    0 \n    1 \n    1 \n    0 \n    0 \n    0 \n    NA \n  \n  \n    4 \n    4 \n    Kallithea \n    2022-05-27 \n    39000 \n    1300 \n    30 \n    1965 \n    Basement \n    1 \n    1 \n    1 \n    2022-06-02 \n    Renovated \n    F \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    1 \n    0 \n    NA \n  \n  \n    5 \n    5 \n    Kallithea \n    2022-04-06 \n    92000 \n    1533 \n    60 \n    1981 \n    1st \n    1 \n    1 \n    1 \n    2022-04-08 \n    Good \n    E \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    NA \n  \n  \n    6 \n    6 \n    Kallithea \n    2021-02-17 \n    220000 \n    1864 \n    118 \n    1992 \n    1st \n    3 \n    1 \n    1 \n    2022-03-23 \n    Newly built \n    D \n    1 \n    0 \n    0 \n    1 \n    0 \n    0 \n    0 \n    0 \n    NA \n  \n  \n    7 \n    8 \n    Kallithea \n    2022-04-10 \n    130000 \n    1461 \n    89 \n    1976 \n    Ground \n    2 \n    1 \n    1 \n    2022-06-10 \n    Good \n    F \n    1 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n    NA"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#recoding-variables",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#recoding-variables",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Recoding variables",
    "text": "Recoding variables\n\nDates\n\n\nShow the code\ndata$res_date = ymd(data$res_date)\n\n\n\n\nQualitative\nAs we noted previously, there are some variables that need recoding. Based on the 15th chapter of R-graphics book (Chang, 2018) we have 2 main choices to do that :\n\nrecode() from dplyr\nfct_recode() from forcats\n\n\n\nShow the code\n# Deleted\n\ndata$deleted = as.factor(data$deleted)\ndata$deleted = fct_recode(data$deleted, Yes = \"1\", No = \"0\")\n\n# Auto Heating\n\ndata$auto_heating = data$auto_heating %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Solar\n\ndata$solar = data$solar %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Cooling\n\ndata$cooling = data$cooling %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Safe door\n\ndata$safe_door = data$safe_door %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Gas\n\ndata$gas = data$gas %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Fireplace\n\ndata$fireplace = data$fireplace %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Furniture\n\ndata$furniture = data$furniture %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Student\n\ndata$student = data$student %>%\n  as.factor() %>%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n## Recoding data$parking\ndata$parking <- data$parking %>%\n  fct_recode(\n    \"Yes\" = \"Parking πιλωτής\",\n    \"Yes\" = \"Ανοιχτό parking\",\n    \"Yes\" = \"Ανοιχτό parking, Parking πιλωτής\",\n    \"Yes\" = \"Κλειστό parking\",\n    \"Yes\" = \"Υπόγειο parking\"\n  ) %>%\n  fct_explicit_na(\"No\")\n\n\n## Levels\ndata$levels <- data$levels %>%\n  as.factor() %>%\n  fct_recode(., \"Mezzanine\" = \"Ημιώροφος\")\n\n# Delete ID column\n\ndata$...2 <- NULL\n\n\nLet’s see one more time our dataset structure after recoding :\n\n\nShow the code\nhead(data, 7) %>%\n  kbl(align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %>%\n  kable_paper() %>%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\n \n  \n    ...1 \n    location_name \n    res_date \n    res_price \n    res_price_sqr \n    res_sqr \n    construction_year \n    levels \n    bedrooms \n    bathrooms \n    deleted \n    deleted_at \n    status \n    energyclass \n    auto_heating \n    solar \n    cooling \n    safe_door \n    gas \n    fireplace \n    furniture \n    student \n    parking \n  \n \n\n  \n    1 \n    Kallithea \n    2022-03-09 \n    220000 \n    2558 \n    86 \n    2002 \n    2nd \n    2 \n    1 \n    Yes \n    2022-04-15 \n    Excellent \n    C \n    Yes \n    No \n    Yes \n    Yes \n    No \n    No \n    Yes \n    No \n    Yes \n  \n  \n    2 \n    Kallithea \n    2022-04-15 \n    180000 \n    2400 \n    75 \n    1975 \n    3rd \n    2 \n    1 \n    Yes \n    2022-04-22 \n    Renovated \n    D \n    No \n    No \n    No \n    No \n    No \n    No \n    Yes \n    No \n    No \n  \n  \n    3 \n    Kallithea \n    2022-02-11 \n    180000 \n    3000 \n    60 \n    2022 \n    1st \n    2 \n    1 \n    Yes \n    2022-04-14 \n    Excellent \n    A+ \n    Yes \n    Yes \n    No \n    Yes \n    Yes \n    No \n    No \n    No \n    No \n  \n  \n    4 \n    Kallithea \n    2022-05-27 \n    39000 \n    1300 \n    30 \n    1965 \n    Basement \n    1 \n    1 \n    Yes \n    2022-06-02 \n    Renovated \n    F \n    No \n    No \n    No \n    No \n    No \n    No \n    Yes \n    No \n    No \n  \n  \n    5 \n    Kallithea \n    2022-04-06 \n    92000 \n    1533 \n    60 \n    1981 \n    1st \n    1 \n    1 \n    Yes \n    2022-04-08 \n    Good \n    E \n    No \n    No \n    No \n    No \n    No \n    No \n    No \n    No \n    No \n  \n  \n    6 \n    Kallithea \n    2021-02-17 \n    220000 \n    1864 \n    118 \n    1992 \n    1st \n    3 \n    1 \n    Yes \n    2022-03-23 \n    Newly built \n    D \n    Yes \n    No \n    No \n    Yes \n    No \n    No \n    No \n    No \n    No \n  \n  \n    7 \n    Kallithea \n    2022-04-10 \n    130000 \n    1461 \n    89 \n    1976 \n    Ground \n    2 \n    1 \n    Yes \n    2022-06-10 \n    Good \n    F \n    Yes \n    No \n    No \n    No \n    No \n    No \n    No \n    No \n    No"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#custom-functions",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#custom-functions",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Custom functions",
    "text": "Custom functions\n\nQualitative - Categorical\n\n\nShow the code\ncategorical_plot <- function(var, custom_title){\ndata %>%\n  as.data.frame() %>%\n  select(var) %>%\n  table() %>%\n  as.data.frame() %>%\n  `colnames<-`(c(\"Categories\", \"Occurencies\")) %>%\n  ggplot(., aes(x = Categories, y = Occurencies, fill=Categories)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Occurencies, vjust = -.1)) +\n    labs(\n        title = custom_title\n    ) +\n   theme_classic()\n}\n\n\n\n\nQuantitative - Discrete\n\n\nShow the code\ndiscrete_plot <- function(var){\n  ggplot(data, aes(x = var)) +\n  geom_bar(stat = \"count\") +\n  theme_classic()\n}"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#missing-values",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#missing-values",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Missing Values",
    "text": "Missing Values\n\n\n\nOn this dataset there are 438 missing values, in total. More specifically,\n\n\nShow the code\ndata %>%\n  is.na() %>%\n  colSums() %>%\n  as.data.frame() %>%\n  `colnames<-`(\"Occurencies\") %>%\n  filter(Occurencies >0) %>%\n  arrange(-Occurencies) %>%\n  kbl(caption = \"Missing Values of Dataset\") %>%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\n\nMissing Values of Dataset\n \n  \n      \n    Occurencies \n  \n \n\n  \n    deleted_at \n    144 \n  \n  \n    status \n    97 \n  \n  \n    energyclass \n    74 \n  \n  \n    bathrooms \n    57 \n  \n  \n    bedrooms \n    37 \n  \n  \n    construction_year \n    29"
  },
  {
    "objectID": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#univariate-analysis",
    "href": "notebooks/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#univariate-analysis",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Univariate analysis",
    "text": "Univariate analysis\n\nQualitative (Nominal) variables\n\nAutoheatingSolarCoolingSafe doorGasFireplaceFurnitureStudentParkingDeleted\n\n\n\n\nShow the code\ncategorical_plot(\"auto_heating\",\"Autonomous Heating\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"solar\", \"Solar-powered water-heater\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"cooling\", \"Cooling\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"safe_door\", \"Safe door\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"gas\", \"Gas\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"fireplace\", \"Fireplace\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"furniture\", \"Available furniture\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"student\", \"Ideal for students\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"parking\", \"Parking\")\n\n\n\n\n\n\n\n\n\nShow the code\ncategorical_plot(\"deleted\", \"Deleted\")\n\n\n\n\n\n\n\n\n\n\nQualitative (Ordinal) variables\n\nStatusEnergy classFloor\n\n\n\n\nShow the code\ntable(data$status) %>%\n  sort(decreasing = F) %>%\n  as.data.frame() %>%\n  ggplot(., aes(x = Var1, y = Freq)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Freq, y = Freq +17)) +\n   theme_classic() +\n   coord_flip()\n\n\n\n\n\n\n\n\n\nShow the code\ntable(data$energyclass) %>%\n  sort(decreasing = F) %>%\n  as.data.frame() %>%\n  ggplot(., aes(x = Var1, y = Freq)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Freq, y = Freq +17)) +\n   theme_classic() +\n   coord_flip()\n\n\n\n\n\n\n\n\n\nShow the code\ntable(data$levels) %>%\n  sort(decreasing = F) %>%\n  as.data.frame() %>%\n  ggplot(., aes(x = Var1, y = Freq)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Freq, y = Freq +17)) +\n   theme_classic() +\n   coord_flip()\n\n\n\n\n\n\n\n\n\n\nQuantitative (Discrete) variables\n\nBedroomsBathrooms\n\n\n\n\nShow the code\nggplot(data, aes(x = bedrooms)) +\n  geom_bar(stat = \"count\") +\n  scale_x_discrete() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data, aes(x = bathrooms)) +\n  geom_bar(stat = \"count\") +\n  scale_x_discrete() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nQuantitative (Continuous) variables\n\nPricePrice per sqrSquaremeters\n\n\n\n\nShow the code\nggplot(data, aes(x= res_price)) +\n  geom_histogram() +\n  theme_classic()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data, aes(x= res_price_sqr)) +\n  geom_histogram() +\n  theme_classic()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nShow the code\nggplot(data, aes(x= res_sqr)) +\n  geom_line(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nTime Series\n\nDate publishedDeleted atConstruction Year\n\n\n\n\nShow the code\ndata$Year_Published = lubridate::year(data$res_date)\n\nggplot(data, aes(x= Year_Published)) +\n  geom_line(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nShow the code\ndata$Year_Deleted = lubridate::ym(data$deleted_at)\n\nggplot(data, aes(x= Year_Deleted)) +\n  geom_line(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nShow the code\ndata$construction_year <- cut(data$construction_year,\n  include.lowest = TRUE,\n  right = FALSE,\n  dig.lab = 4,\n  breaks = c(1920, 1940, 1960, 1980, 2000, 2020, 2030)\n)\n\n\n\n\nShow the code\nggplot(data, aes(x = construction_year)) +\n  geom_bar(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nShow the code\ndata_split <- initial_split(data, prop = 0.75)\n\ntrain <- training(data_split)\ntest  <- testing(data_split)\n\nimpute_rec <- recipe(res_price ~ bathrooms + bedrooms, data = data) %>%\n  step_impute_mean(all_predictors())"
  },
  {
    "objectID": "shiny.html",
    "href": "shiny.html",
    "title": "Shiny Apps",
    "section": "",
    "text": "A simple Shiny App that calculates the number of possible samples depending on the chosen sampling method.\n Website |  Repository"
  },
  {
    "objectID": "shiny.html#shiny-distributions",
    "href": "shiny.html#shiny-distributions",
    "title": "Shiny Apps",
    "section": "Shiny Distributions",
    "text": "Shiny Distributions\nA Shiny App to showcase various distributions and their characteristics.\n Website |  Repository"
  }
]