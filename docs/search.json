[
  {
    "objectID": "shiny.html",
    "href": "shiny.html",
    "title": "Web Projects",
    "section": "",
    "text": "A dashboard for an Ageing World (1800 - 2060)\n    \n    \n     \n     \n     \n    \n\n\n    \n      \n      A simple Shiny App that calculates the number of possible samples depending on the chosen sampling method.\n    \n    \n     \n     \n     \n     \n    \n\n\n    \n      \n      A Shiny App to showcase various distributions and their characteristics.\n    \n    \n     \n     \n     \n     \n    \n\n\n    \n      \n      A Shiny App to calculate parliamentary seats for each party (Greek parliament).\n    \n    \n     \n     \n     \n     \n    \n\n\n    \n      \n      Predict your wage based on your dev role (frontend, backend, analytics) and your job experience."
  },
  {
    "objectID": "shiny.html#shiny-apps",
    "href": "shiny.html#shiny-apps",
    "title": "Web Projects",
    "section": "",
    "text": "A dashboard for an Ageing World (1800 - 2060)\n    \n    \n     \n     \n     \n    \n\n\n    \n      \n      A simple Shiny App that calculates the number of possible samples depending on the chosen sampling method.\n    \n    \n     \n     \n     \n     \n    \n\n\n    \n      \n      A Shiny App to showcase various distributions and their characteristics.\n    \n    \n     \n     \n     \n     \n    \n\n\n    \n      \n      A Shiny App to calculate parliamentary seats for each party (Greek parliament).\n    \n    \n     \n     \n     \n     \n    \n\n\n    \n      \n      Predict your wage based on your dev role (frontend, backend, analytics) and your job experience."
  },
  {
    "objectID": "shiny.html#deployed-models",
    "href": "shiny.html#deployed-models",
    "title": "Web Projects",
    "section": "Deployed Models",
    "text": "Deployed Models\n\n\n    \n      Developers' Wages API (soon)\n      Predict your wage based on your dev role (frontend, backend, analytics) and your job experience.\n    \n    \n     \n     \n    \n\n\n    \n      Glass API\n      Determine the type of glass (window/non-window) based on its components\n    \n    \n     \n     \n    \n\n\n    \n      Tyre Condition API (soon)\n      A DL model to check if the car's tyres are defective or not"
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "",
    "text": "Καλησπέρα σας.\nΠρώτο άρθρο στα ελληνικά και ελπίζω να μην τα γράφω τζάμπα και καποιος, κάπου, κάποτε να βρει αυτή τη σελίδα αν ποτέ τη χρειαστεί. :)\nΠροϋποθέσεις για να συμπεριληφθεί κάτι στη σελίδα :\n\nΝα είναι δωρεάν\nΝα είναι στα ελληνικά\nΝα είναι κατανοητό για όλο το φάσμα των χρηστών της R"
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#εισαγωγή",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#εισαγωγή",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "",
    "text": "Καλησπέρα σας.\nΠρώτο άρθρο στα ελληνικά και ελπίζω να μην τα γράφω τζάμπα και καποιος, κάπου, κάποτε να βρει αυτή τη σελίδα αν ποτέ τη χρειαστεί. :)\nΠροϋποθέσεις για να συμπεριληφθεί κάτι στη σελίδα :\n\nΝα είναι δωρεάν\nΝα είναι στα ελληνικά\nΝα είναι κατανοητό για όλο το φάσμα των χρηστών της R"
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βιβλία-για-την-r",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βιβλία-για-την-r",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "Βιβλία για την R",
    "text": "Βιβλία για την R\n\n\n\n\n\n\n\n\nΤίτλος βιβλίου\nΣυγγραφέας\nΣύνδεσμος\n\n\n\n\nΕισαγωγή στην R Πρόχειρες σημειώσεις\nΦωκιανός, Κ.  Χαραλάμπους, Χ.\nΣύνδεσμος  (απευθείας κατέβασμα)\n\n\nΕισαγωγή στον προγραμματισμό και στη στατιστική ανάλυση με R\nΝτζούφρας, Ι.  Καρλής, Δ.\nΣύνδεσμος\n\n\nΗ επιστήμη των δεδομένων μέσα από τη γλώσσα R\nΒερύκιος, Β.  Καγκλής, Β.  Σταυρόπουλος, Η.\nΣύνδεσμος\n\n\nΕισαγωγή στην επιχειρησιακή έρευνα και στον γραμμικό προγραμματισμό\nΚουνέτας, Κ  Χατζησταμούλου, Ν.\nΣύνδεσμος\n\n\nΕισαγωγή στην εκπαιδευτική και ψυχολογική μέτρηση με τη χρήση της R\nAlbano, A.  Markos, A. (tr)\nΣύνδεσμος\n\n\n\nΔυστυχώς, οι επιλογές μας σε σχέση με το υλικό που υπάρχει στα αγγλικά (ελεύθερα διαθέσιμο) είναι αρκετά περιορισμένες. Ωστόσο, υπάρχουν κάποιες πολύ καλές επιλογές (ανάλογα το επίπεδο και τον σκοπό του χρήστη).\nΗ πρώτη μου επιλογή (και προσωπικά η αγαπημένη μου) είναι το βιβλίο “Εισαγωγή στην R - Πρόχειρες σημειώσεις”. Είναι ένας συνδυασμός σημειώσεων και εφαρμογής των εντολών για κατηγορίες προβλημάτων. Αναφέρεται σε ένα μεγάλο εύρος θεμάτων (κυρίως στατιστικής), από τα πιο απλά (έλεγχοι t-test) μέχρι πιο σύνθετα θέματα (ανάλυση κατά συστάδες). Πολύ καλό για φοιτητές στατιστικής (μάλλον για αυτό μου αρέσει).\nΗ δεύτερη επιλογή (“Εισαγωγή στον προγραμματισμό και στη στατιστική ανάλυση με R”) κινείται σε παρόμοια νερά. Είναι ένα βιβλίο που με προβλημάτισε κάπως. Αυτό το βιβλίο είχε τα φόντα να γίνει το προσωπικό μου αγαπημένο, διότι δεν σου δείχνει απλά τις εντολές. Σου μαθαίνει να προγραμματίζεις με την R, αφού δίνει μεγαλύτερη σημασία σε ελέγχους ροής, συναρτήσεις και άλλα θέματα. Αυτό είναι πολύ σημαντικό, αν θες να φτιάξεις κάτι πιο περίπλοκο (π.χ. μία περίπλοκη ανάλυση, ένα πακέτο στην R, κτλ.). Αν και προγραμματισμός μαθαίνεται κυρίως κάνοντας και όχι διαβαζοντας πιστεύω ότι είναι μία καλή προσθήκη στη λίστα.\nΗ τρίτη μου επιλογή είναι το “Επιστήμη των δεδομένων μέσα από τη γλώσσα R”. Πιθανότατα αυτό το βιβλίο πλησιάζει περισσότερο στη λογική των notebooks και στο να ανεβάσεις δικά σου project. Σε βάζει σε μία λογική να αρχίσεις να κάνεις αναλύσεις. Καλό, αν κάποιος θέλει να φτιάξει το δικό του portfolio, προκειμένου κάποτε να βρει μία δουλειά (εγώ με αυτή την ελπίδα ζω ακόμα :) ). Προσωπικά πιστεύω ότι είναι καλό για κάποιον που έχει ήδη κάποια εξοικείωση στην R.\nΤα τελευταία 2 βιβλία της λίστας μου αφορούν εξειδικευμένα θέματα, συνεπώς προορίζονται για ανθρώπους με πολύ συγκεκριμένους σκοπούς."
  },
  {
    "objectID": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βίντεομαθήματα-για-την-r",
    "href": "greek/2022-10-23-Material-for-R-Greek/2022-10-23-Material-for-R-Greek.html#βίντεομαθήματα-για-την-r",
    "title": "Συγκεντρωμένο υλικό για την R στα ελληνικά",
    "section": "Βίντεομαθήματα για την R",
    "text": "Βίντεομαθήματα για την R\n\n\n\n\n\n\n\nΌνομα καναλιού\nΣύνδεσμος\n\n\n\n\nChristos Malliarakis\nΣύνδεσμος\n\n\n\nΠέρα όμως από τα βιβλία έψαξα να βρω και υλικό για την R στο Youtube. Το υλικό είναι επίσης αρκετά περιορισμένο. Προς το παρόν θα αφήσω μία επιλογή η οποία είναι και η πιο πλήρης. Στη σειρά βιντεομαθημάτων (playlist) του κ. Χρήστου Μαλλιαράκη γίνεται μία αναφορά σε βασικά στοιχεία της R ενώ σε επόμενα μαθήματα ασχολείται με κάποια απλά παραδείγματα μηχανικής μάθησης."
  },
  {
    "objectID": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html",
    "href": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html",
    "title": "Πρόσβαση στο API του data.gov.gr",
    "section": "",
    "text": "Στην παραδοσιακή ανάλυση δεδομένων συνήθως ο αναλυτής καλείται να &lt;&gt; τα δεδομένα, να τους δώσει μία κατάλληλη μορφή πορκειμένου να αναλυθούν. Αυτή η δαιδικασία υπονοεί ότι τα δεδομένα υπάρχουν συγκεντρωμένα σε ένα αρχείο. Ωστόσο, δεν είναι πάντα έτσι. Το πρόβλημα με την ανάλυση ενός dataset είναι ότι δεν λαμβάνει υπόψιν τις όποιες νέες τιμές. Σε αυτή τη περίπτωση θα πρέπει να ξανακατβάσω τα νέα δεδομένα και να ξανατρέξω την ανάλυση μέσω της R ή όποιου εργαλείου χρησιμοποιώ. Αυτό όπως γίνεται αντιληπτό είναι μη παραγωγικό, ωστόσο όταν γίνεται λίγες φορές μέσα στο χρόνο, ίσως να μην είναι και τόσο . Εκεί που πλέον γίνεται εμφανής η μη αποτελεσματικότητα της παραπάνω διαδικασίας είναι όταν υπάρχει συνεχής ροή δεδομένων, άρα πρέπει να γίνεται αυτή η διαδικασία καθημερινά. Σε αυτές τις περιπτώσεις φαίνεται η χρησιμότητα του API αφού μας δίνει τις νέες τιμές με μικρό σχετικά κόπο. Παράλληλα η χρήση του API ευνοεί την ένατξη νέων δεδομένων, συνεπώς αν φτιάχουμε ένα προβλεπτικό μοντέλο η ακρίβειά του θα παραμένει σε ένα ικανοποιητικό επίπεδο. Τέλος, άλλη μία θετική συμβολή είναι σε Shiny Apps, προκειμένου να αυτοματοποιείται η ανάλυση δεδομένων και οι πληροφορίες να είναι αξιόπιστες για τον επισκέπτη αυτού.\nΓενικά υπάρχουν πάρα πολλά API από τα οποία μπορούμε να λάβουμε σημαντικές πληροφορίες. Για περισσότερες λεπτομέρειες ως προς τη διαθεσιμότητα δωρεάν APIs μπορείτε να δείτε ένα σχετικό repository με μία λίστα αυτών. Σε αυτό το άρθρο θα ασχοληθούμε με τα ανοικτά δεδομένα της χώρας μας που διατίθενται μέσω του data.gov.gr."
  },
  {
    "objectID": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#εισαγωγή",
    "href": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#εισαγωγή",
    "title": "Πρόσβαση στο API του data.gov.gr",
    "section": "",
    "text": "Στην παραδοσιακή ανάλυση δεδομένων συνήθως ο αναλυτής καλείται να &lt;&gt; τα δεδομένα, να τους δώσει μία κατάλληλη μορφή πορκειμένου να αναλυθούν. Αυτή η δαιδικασία υπονοεί ότι τα δεδομένα υπάρχουν συγκεντρωμένα σε ένα αρχείο. Ωστόσο, δεν είναι πάντα έτσι. Το πρόβλημα με την ανάλυση ενός dataset είναι ότι δεν λαμβάνει υπόψιν τις όποιες νέες τιμές. Σε αυτή τη περίπτωση θα πρέπει να ξανακατβάσω τα νέα δεδομένα και να ξανατρέξω την ανάλυση μέσω της R ή όποιου εργαλείου χρησιμοποιώ. Αυτό όπως γίνεται αντιληπτό είναι μη παραγωγικό, ωστόσο όταν γίνεται λίγες φορές μέσα στο χρόνο, ίσως να μην είναι και τόσο . Εκεί που πλέον γίνεται εμφανής η μη αποτελεσματικότητα της παραπάνω διαδικασίας είναι όταν υπάρχει συνεχής ροή δεδομένων, άρα πρέπει να γίνεται αυτή η διαδικασία καθημερινά. Σε αυτές τις περιπτώσεις φαίνεται η χρησιμότητα του API αφού μας δίνει τις νέες τιμές με μικρό σχετικά κόπο. Παράλληλα η χρήση του API ευνοεί την ένατξη νέων δεδομένων, συνεπώς αν φτιάχουμε ένα προβλεπτικό μοντέλο η ακρίβειά του θα παραμένει σε ένα ικανοποιητικό επίπεδο. Τέλος, άλλη μία θετική συμβολή είναι σε Shiny Apps, προκειμένου να αυτοματοποιείται η ανάλυση δεδομένων και οι πληροφορίες να είναι αξιόπιστες για τον επισκέπτη αυτού.\nΓενικά υπάρχουν πάρα πολλά API από τα οποία μπορούμε να λάβουμε σημαντικές πληροφορίες. Για περισσότερες λεπτομέρειες ως προς τη διαθεσιμότητα δωρεάν APIs μπορείτε να δείτε ένα σχετικό repository με μία λίστα αυτών. Σε αυτό το άρθρο θα ασχοληθούμε με τα ανοικτά δεδομένα της χώρας μας που διατίθενται μέσω του data.gov.gr."
  },
  {
    "objectID": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#αίτηση-για-api-key",
    "href": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#αίτηση-για-api-key",
    "title": "Πρόσβαση στο API του data.gov.gr",
    "section": "Αίτηση για API Key",
    "text": "Αίτηση για API Key\nΩστόσο, το συγκεκριμένο API (όπως τα περισσότερα χρειάζονται\nΚάνουμε άιτηση στην αντίστοιχη σελίδα και συμπληρώνουμε τα στοιχεία μας και όλα τα πεδία της φόρμας όπως αυτή φαίνεται παρακάτω:\n\n\nΠροεπισκόπηση σελίδας αίτησης για πρόσβαση στο API\n\nΣτη συνέχεια θα πρέπει να κοιτάξετε το e-mail σας γιατί θα σας έρθει ένα μήνυμα με τον Token μέσω του οποίου θα χρησιμοποιείται το API. Να δείτε οπωσδήποτε και τον φάκελο με την Ανεπιθύμητη αλληλογραφία (spam) καθώς εμένα μου ήρθε εκεί. Παρεπιπτόντως, σε περίπτωση που χάσετε το token και έχετε σβήσει το mail και ξανακάνετε αίτηση (με το ίδιο mail) θα σας το ξαναστείλει. Το έπαθα μόλις :)"
  },
  {
    "objectID": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#χρήση-api",
    "href": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#χρήση-api",
    "title": "Πρόσβαση στο API του data.gov.gr",
    "section": "Χρήση API",
    "text": "Χρήση API\nΑφού λάβουμε το Token, θα πρέπει με κάποιο τρόπο να λάβουμε τα δεδομένα. Στην συγκεκριμένη πλατφόρμα υπάρχουν δύο τρόποι.\n\nΧρήση API από την ιστοσελίδα:\nΧρήση API με την R\n\nΟ ένας τρόπος (και μάλλον ο λιγότερο αποδοτικός) είναι να κάνεις ζητήσεις τα δεδομένα απευθείας από την ιστοσελίδα data.gov.gr. Αυτό είναι από τη μία εξαιρετικά απλό, αλλά από την άλλη κατεβάζουμε μία σταθερή εκδοση των δεδομένων και συνεπώς αν θελήσω να ανανεώσω τα δεδομένα θα πρέπει πάλι να κατεβάσω τα δεδομένα."
  },
  {
    "objectID": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#παράδειγμα-χρήσης",
    "href": "greek/2023-07-04-GovGR-API-Greek/2023-07-04-GovGR-API-Greek.html#παράδειγμα-χρήσης",
    "title": "Πρόσβαση στο API του data.gov.gr",
    "section": "Παράδειγμα χρήσης",
    "text": "Παράδειγμα χρήσης\nΠριν ολοκληρωθεί αυτό το άρθρο έκρινα ως σημαντική την εφαρμογή ενός παραδείγματος. Τη στιγμή που γράφεται αυτό το άρθρο, υπάρχουν συνολικά 49 βάσεις δεδομένων από τις οποίες μπορώ να επιλέξω. Προκειμένου να δούμε την ωφέλεια του API θα διαλέξω κάποιο που ανανεώνεται σε αρκετά συχνή βάση. Ένα τέτοιο δεδομένο είναι οι επιβάτες που ταξιδεύουν με πλοία.\n\nlibrary(httr)\nlibrary(jsonlite)\n\nΣτη συνέχεια θέτω σε μία μεταβλητή τον βασικό σύνδεσμο των δεδομένων. Εγώ που επέλεξα την κίνηση των πλοίων θέτω το εξής:\n\nbase = \"https://data.gov.gr/api/v1/query/sailing_traffic\"\n\nΣτη συνέχεια, όπως τονίζει το documentation της σελίδας για τις άλλες γλώσσες, θα πρέπει να ορίσουμε ένα εύρος ημερομηνιών για το οποίο ενδιοαφερόμαστε. Αξίζει να σημειωθεί ότι δεν μπορείτε να πάρετε μεγάλο εύρος με μία μόνο κλήση του API. Για να επιστρέψω στο προηγούμενο παράδειγμα, τα δεδομένα της επιβατικής κίνησης των πλοίων ξεκινάνε από το 2017 μέχρι και σήμερα (2023). Ας υποθέσουμε ότι δεν μας πειράζει αυτό και ότι θέλουμε τα δεδομένα από τις 4 πρώτες μέρες του Ιουλίου του 2023.\n\ndate_from = \"2023-07-01\"\ndate_to = \"2023-07-04\"\n\nAPI_URL = paste0(base, \"?date_from=\", date_from, \"&\", \"date_to=\", date_to)\n\ncall = httr::GET(url = API_URL,\n    add_headers(`Authorization` = paste0('Token token_id')\n    )\n)\n\nΌπου στο σημείο που αναφέρεται το token_id θα πρέπει να βάλετε το token που σας έστειλε το data.gov.gr μέσω mail. Αφού λοιπόν αιτηθούμε τα δεδομένα μέσω της GET και κάνουμε λίγο υπομονή βλέπουμε ότι λαμβάνω μία λίστα με διάφορες πληροφορίες. Εμάς μας ενδιαφέρουν τα δεδομένα, οπότε κοιτάμε στη κατηγορία content της λίστας, ωστόσο παρατηρούμε μία μη αναγνώσιμη μορφή των στοιχειών μιας και είναι σε δεκαεξαδική μορφή.\n\ndata = base::rawToChar(call$content)\n\nΜε την παραπάνω εντολή μετατρέπονται οι χαρακτήρες και είναι πλέον αναγνώσιμοι, ωστόσο τωρα θα πρέπει να πάρουν και μορφή πίνακα προκειμένου να γίνει η ανάλυση.\n\ndata = jsonlite::fromJSON(data, flatten = T)\n\nΚαι τέλος, με τη βοήθεια του πακέτου jsnolite λαμβάνω ένα data.frame με όνομα data που περιέχει όλους τους προορισμούς, τον αριθμό επιβατών, αυτοκινήτων για τη κάθε ημέρα που ζήτησα."
  },
  {
    "objectID": "gallery.html#day-map-challenge",
    "href": "gallery.html#day-map-challenge",
    "title": "Gallery",
    "section": "30 Day Map Challenge",
    "text": "30 Day Map Challenge\n\n\n\n\n\nPublic Music Schools in Greece\n\n\n\n\n\n\n\nRailway Network of Greece\n\n\n\n\n\n\n\nRegions of Greece\n\n\n\n\n\n\n\nPharmacies in Greece\n\n\n\n\n\n\n\nPorts in Ukraine\n\n\n\n\n\n\n\nLuxembourg’s City Bus Transportation\n\n\n\n\n\n\n\nPopulation in Europe\n\n\n\n\n\n\n\nPublic Buildings, Lamia city\n\n\n\n\n\n\n\nStarmap of Athens\n\n\n\n\n\n\n\nWildfire in Euboea"
  },
  {
    "objectID": "gallery.html#greece-in-figures",
    "href": "gallery.html#greece-in-figures",
    "title": "Gallery",
    "section": "Greece in Figures",
    "text": "Greece in Figures\n\n\n\n\n\nPharmacies in Greece\n\n\n\n\n\n\n\nGDP per capita\n\n\n\n\n\n\n\nDentists per Region\n\n\n\n\n\n\n\nPopulation Density\n\n\n\n\n\n\n\nPhysiotherapists, 2020\n\n\n\n\n\n\n\nHeating Oil Consumption\n\n\n\n\n\n\n\nElectricity consumption, 2012\n\n\n\n\n\n\n\nVineyard Areas, 2020\n\n\n\n\n\n\n\nWeddings, 2021"
  },
  {
    "objectID": "gallery.html#eu-in-figures",
    "href": "gallery.html#eu-in-figures",
    "title": "Gallery",
    "section": "EU in Figures",
    "text": "EU in Figures\n\n\n\n\n\nUnemployment, 2022\n\n\n\n\n\n\n\nR&D, 2021"
  },
  {
    "objectID": "gallery.html#other-visualizations",
    "href": "gallery.html#other-visualizations",
    "title": "Gallery",
    "section": "Other Visualizations",
    "text": "Other Visualizations\n\n\n\n\n\nMost elected MPs\n\n\n\n\n\n\n\nWomen Participation in DS\n\n\n\n\n\n\n\nAge Distribution (GR & Rest of World)\n\n\n\n\n\n\n\nGit vs SVN\n\n\n\n\n\n\n\nMInimum Admission Grade\n\n\n\n\n\n\n\nAdmission Seats on each Statistics Department\n\n\n\n\n\n\n\nPercentage of Electives"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "",
    "text": "Introduction\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset    2.4 Dataset structure    2.5 Recoding variables    2.6 Custom functions \nEDA with R    3.1 Missing Values    3.2 Univariate Analysis        3.2.1 Qualitative (Nominal) variables        3.2.2 Qualitative (Ordinal) variables        3.2.2 Qualitative (Discrete) variables        3.2.2 Qualitative (Continuous) variables        3.2.2 Time series \nAcknowledgements\nReferences"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-libraries",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-libraries",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Import libraries",
    "text": "Import libraries\nIn brief,\n\nfor data entry purposes, I will use readr package (part of tidyverse)\nfor plots, ggplot2\nand building models with tidymodels\n\n\n\nCode\n# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(kableExtra)\nlibrary(forcats)\n\n# Deal with dates\n\nlibrary(lubridate)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Build ML models\n\nlibrary(tidymodels)\nlibrary(bonsai)\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-dataset",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#import-dataset",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Import dataset",
    "text": "Import dataset\nAfter importing my libraries I can use readr’s, read_csv function in order to import my dataset. This dataset was retrieved from Kaggle. Some customization need to be made in order to make an efficient analysis :\n\nfilter data for apartments in Kallithea\nconvert Greek characters to English ones\n\n\n\nCode\ndata &lt;- read_csv(\"kallithea.csv\")"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#preview-dataset",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#preview-dataset",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Preview dataset",
    "text": "Preview dataset\nAs usual, one of my first steps is to preview my dataset. That way I can have a first impression on my dataset and its possible problems. More specifically, the preview reveals :\n\nA LOT variables that need recoding (energyclass, solar, etc.)\nSome values on specific variables are on greek (parking)\nDuplicate ID column\nThere are missing values (!!!)\n\n\n\nCode\n#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n\npreview_data = head(data, 7) %&gt;%\n  kbl(align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\npreview_data\n\n\n\n\n\n\n...1\n...2\nlocation_name\nres_date\nres_price\nres_price_sqr\nres_sqr\nconstruction_year\nlevels\nbedrooms\nbathrooms\ndeleted\ndeleted_at\nstatus\nenergyclass\nauto_heating\nsolar\ncooling\nsafe_door\ngas\nfireplace\nfurniture\nstudent\nparking\n\n\n\n\n1\n1\nKallithea\n2022-03-09\n220000\n2558\n86\n2002\n2nd\n2\n1\n1\n2022-04-15\nExcellent\nC\n1\n0\n1\n1\n0\n0\n1\n0\nParking πιλωτής\n\n\n2\n2\nKallithea\n2022-04-15\n180000\n2400\n75\n1975\n3rd\n2\n1\n1\n2022-04-22\nRenovated\nD\n0\n0\n0\n0\n0\n0\n1\n0\nNA\n\n\n3\n3\nKallithea\n2022-02-11\n180000\n3000\n60\n2022\n1st\n2\n1\n1\n2022-04-14\nExcellent\nA+\n1\n1\n0\n1\n1\n0\n0\n0\nNA\n\n\n4\n4\nKallithea\n2022-05-27\n39000\n1300\n30\n1965\nBasement\n1\n1\n1\n2022-06-02\nRenovated\nF\n0\n0\n0\n0\n0\n0\n1\n0\nNA\n\n\n5\n5\nKallithea\n2022-04-06\n92000\n1533\n60\n1981\n1st\n1\n1\n1\n2022-04-08\nGood\nE\n0\n0\n0\n0\n0\n0\n0\n0\nNA\n\n\n6\n6\nKallithea\n2021-02-17\n220000\n1864\n118\n1992\n1st\n3\n1\n1\n2022-03-23\nNewly built\nD\n1\n0\n0\n1\n0\n0\n0\n0\nNA\n\n\n7\n8\nKallithea\n2022-04-10\n130000\n1461\n89\n1976\nGround\n2\n1\n1\n2022-06-10\nGood\nF\n1\n0\n0\n0\n0\n0\n0\n0\nNA"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#recoding-variables",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#recoding-variables",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Recoding variables",
    "text": "Recoding variables\n\nDates\n\n\nCode\ndata$res_date = ymd(data$res_date)\n\n\n\n\nQualitative\nAs we noted previously, there are some variables that need recoding. Based on the 15th chapter of R-graphics book (Chang, 2018) we have 2 main choices to do that :\n\nrecode() from dplyr\nfct_recode() from forcats\n\n\n\nCode\n# Deleted\n\ndata$deleted = as.factor(data$deleted)\ndata$deleted = fct_recode(data$deleted, Yes = \"1\", No = \"0\")\n\n# Auto Heating\n\ndata$auto_heating = data$auto_heating %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Solar\n\ndata$solar = data$solar %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Cooling\n\ndata$cooling = data$cooling %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Safe door\n\ndata$safe_door = data$safe_door %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Gas\n\ndata$gas = data$gas %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Fireplace\n\ndata$fireplace = data$fireplace %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Furniture\n\ndata$furniture = data$furniture %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n# Student\n\ndata$student = data$student %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., Yes = \"1\", No = \"0\")\n\n## Recoding data$parking\ndata$parking &lt;- data$parking %&gt;%\n  fct_recode(\n    \"Yes\" = \"Parking πιλωτής\",\n    \"Yes\" = \"Ανοιχτό parking\",\n    \"Yes\" = \"Ανοιχτό parking, Parking πιλωτής\",\n    \"Yes\" = \"Κλειστό parking\",\n    \"Yes\" = \"Υπόγειο parking\"\n  ) %&gt;%\n  fct_explicit_na(\"No\")\n\n\n## Levels\ndata$levels &lt;- data$levels %&gt;%\n  as.factor() %&gt;%\n  fct_recode(., \"Mezzanine\" = \"Ημιώροφος\")\n\n# Delete ID column\n\ndata$...2 &lt;- NULL\n\n\nLet’s see one more time our dataset structure after recoding :\n\n\nCode\nhead(data, 7) %&gt;%\n  kbl(align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\n\n\n...1\nlocation_name\nres_date\nres_price\nres_price_sqr\nres_sqr\nconstruction_year\nlevels\nbedrooms\nbathrooms\ndeleted\ndeleted_at\nstatus\nenergyclass\nauto_heating\nsolar\ncooling\nsafe_door\ngas\nfireplace\nfurniture\nstudent\nparking\n\n\n\n\n1\nKallithea\n2022-03-09\n220000\n2558\n86\n2002\n2nd\n2\n1\nYes\n2022-04-15\nExcellent\nC\nYes\nNo\nYes\nYes\nNo\nNo\nYes\nNo\nYes\n\n\n2\nKallithea\n2022-04-15\n180000\n2400\n75\n1975\n3rd\n2\n1\nYes\n2022-04-22\nRenovated\nD\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nNo\n\n\n3\nKallithea\n2022-02-11\n180000\n3000\n60\n2022\n1st\n2\n1\nYes\n2022-04-14\nExcellent\nA+\nYes\nYes\nNo\nYes\nYes\nNo\nNo\nNo\nNo\n\n\n4\nKallithea\n2022-05-27\n39000\n1300\n30\n1965\nBasement\n1\n1\nYes\n2022-06-02\nRenovated\nF\nNo\nNo\nNo\nNo\nNo\nNo\nYes\nNo\nNo\n\n\n5\nKallithea\n2022-04-06\n92000\n1533\n60\n1981\n1st\n1\n1\nYes\n2022-04-08\nGood\nE\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo\n\n\n6\nKallithea\n2021-02-17\n220000\n1864\n118\n1992\n1st\n3\n1\nYes\n2022-03-23\nNewly built\nD\nYes\nNo\nNo\nYes\nNo\nNo\nNo\nNo\nNo\n\n\n7\nKallithea\n2022-04-10\n130000\n1461\n89\n1976\nGround\n2\n1\nYes\n2022-06-10\nGood\nF\nYes\nNo\nNo\nNo\nNo\nNo\nNo\nNo\nNo"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#custom-functions",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#custom-functions",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Custom functions",
    "text": "Custom functions\n\nQualitative - Categorical\n\n\nCode\ncategorical_plot &lt;- function(var, custom_title){\ndata %&gt;%\n  as.data.frame() %&gt;%\n  select(var) %&gt;%\n  table() %&gt;%\n  as.data.frame() %&gt;%\n  `colnames&lt;-`(c(\"Categories\", \"Occurencies\")) %&gt;%\n  ggplot(., aes(x = Categories, y = Occurencies, fill=Categories)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Occurencies, vjust = -.1)) +\n    labs(\n        title = custom_title\n    ) +\n   theme_classic()\n}\n\n\n\n\nQuantitative - Discrete\n\n\nCode\ndiscrete_plot &lt;- function(var){\n  ggplot(data, aes(x = var)) +\n  geom_bar(stat = \"count\") +\n  theme_classic()\n}"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#missing-values",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#missing-values",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Missing Values",
    "text": "Missing Values\nOn this dataset there are 438 missing values, in total. More specifically,\n\n\nCode\ndata %&gt;%\n  is.na() %&gt;%\n  colSums() %&gt;%\n  as.data.frame() %&gt;%\n  `colnames&lt;-`(\"Occurencies\") %&gt;%\n  filter(Occurencies &gt;0) %&gt;%\n  arrange(-Occurencies) %&gt;%\n  kbl(caption = \"Missing Values of Dataset\") %&gt;%\n  kable_classic(full_width = F, html_font = \"Cambria\")\n\n\n\nMissing Values of Dataset\n\n\n\nOccurencies\n\n\n\n\ndeleted_at\n144\n\n\nstatus\n97\n\n\nenergyclass\n74\n\n\nbathrooms\n57\n\n\nbedrooms\n37\n\n\nconstruction_year\n29"
  },
  {
    "objectID": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#univariate-analysis",
    "href": "english/2022-12-03-House-Price-Kallithea/2022-12-03-House-Price-Kallithea.html#univariate-analysis",
    "title": "Predict Cost of Housing in Kallithea",
    "section": "Univariate analysis",
    "text": "Univariate analysis\n\nQualitative (Nominal) variables\n\nAutoheatingSolarCoolingSafe doorGasFireplaceFurnitureStudentParkingDeleted\n\n\n\n\nCode\ncategorical_plot(\"auto_heating\",\"Autonomous Heating\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"solar\", \"Solar-powered water-heater\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"cooling\", \"Cooling\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"safe_door\", \"Safe door\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"gas\", \"Gas\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"fireplace\", \"Fireplace\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"furniture\", \"Available furniture\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"student\", \"Ideal for students\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"parking\", \"Parking\")\n\n\n\n\n\n\n\n\n\nCode\ncategorical_plot(\"deleted\", \"Deleted\")\n\n\n\n\n\n\n\n\n\n\nQualitative (Ordinal) variables\n\nStatusEnergy classFloor\n\n\n\n\nCode\ntable(data$status) %&gt;%\n  sort(decreasing = F) %&gt;%\n  as.data.frame() %&gt;%\n  ggplot(., aes(x = Var1, y = Freq)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Freq, y = Freq +17)) +\n   theme_classic() +\n   coord_flip()\n\n\n\n\n\n\n\n\n\nCode\ntable(data$energyclass) %&gt;%\n  sort(decreasing = F) %&gt;%\n  as.data.frame() %&gt;%\n  ggplot(., aes(x = Var1, y = Freq)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Freq, y = Freq +17)) +\n   theme_classic() +\n   coord_flip()\n\n\n\n\n\n\n\n\n\nCode\ntable(data$levels) %&gt;%\n  sort(decreasing = F) %&gt;%\n  as.data.frame() %&gt;%\n  ggplot(., aes(x = Var1, y = Freq)) +\n   geom_bar(stat = \"identity\") +\n   geom_text(aes(label = Freq, y = Freq +17)) +\n   theme_classic() +\n   coord_flip()\n\n\n\n\n\n\n\n\n\n\nQuantitative (Discrete) variables\n\nBedroomsBathrooms\n\n\n\n\nCode\nggplot(data, aes(x = bedrooms)) +\n  geom_bar(stat = \"count\") +\n  scale_x_discrete() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\nggplot(data, aes(x = bathrooms)) +\n  geom_bar(stat = \"count\") +\n  scale_x_discrete() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nQuantitative (Continuous) variables\n\nPricePrice per sqrSquaremeters\n\n\n\n\nCode\nggplot(data, aes(x= res_price)) +\n  geom_histogram() +\n  theme_classic()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nCode\nggplot(data, aes(x= res_price_sqr)) +\n  geom_histogram() +\n  theme_classic()\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nCode\nggplot(data, aes(x= res_sqr)) +\n  geom_line(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nTime Series\n\nDate publishedDeleted atConstruction Year\n\n\n\n\nCode\ndata$Year_Published = lubridate::year(data$res_date)\n\nggplot(data, aes(x= Year_Published)) +\n  geom_line(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\ndata$Year_Deleted = lubridate::ym(data$deleted_at)\n\nggplot(data, aes(x= Year_Deleted)) +\n  geom_line(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nCode\ndata$construction_year &lt;- cut(data$construction_year,\n  include.lowest = TRUE,\n  right = FALSE,\n  dig.lab = 4,\n  breaks = c(1920, 1940, 1960, 1980, 2000, 2020, 2030)\n)\n\n\n\n\nCode\nggplot(data, aes(x = construction_year)) +\n  geom_bar(stat = \"count\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nCode\ndata_split &lt;- initial_split(data, prop = 0.75)\n\ntrain &lt;- training(data_split)\ntest  &lt;- testing(data_split)\n\nimpute_rec &lt;- recipe(res_price ~ bathrooms + bedrooms, data = data) %&gt;%\n  step_impute_mean(all_predictors())"
  },
  {
    "objectID": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html",
    "href": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html",
    "title": "Git Series (Part I - Configuration)",
    "section": "",
    "text": "A Version Control System (VCS) is a way to manage and track code changes. As we build an application, we add functions, change frontend features, fix bugs. We will need to edit the code many times. So we need a way to manage these changes. The tracking of every change to our code is the key point of VCS.\n\n\nWorkflow without Version Control\n\nSome popular Version Control Software are the following :\n\nGit\nApache Subversion (SVN)\nMercurial\nBazaar\n\nHaving seen what a VCS is, it would be interesting to see which one is the most widely used. In order to study which VCS is the most popular, I pulled data from Google Trends.\n\nCode  ggplot(data = trends_vcs_tidy, aes(x= Month, y = counts)) +\n  geom_line(aes(color = VCS)) +\n  labs(title = \"Trends on Version Control Systems\",\n              subtitle = \"Compare trends of Git and SVN (Subversion) from 2004 to 2022\",\n              caption = \"Data source: Google Trends\") +\n  theme_classic()\n\n\n\n\nThe figure above makes clear the dominance of Git as a version control tool. Also, we notice that Subversion (SVN) was quite popular and a capable competitor of Git until 2010. After that period there is a continuous decline in SVN’s interest and the exact opposite for Git. Today, in 2022, the difference is chaotic between them.\n\n\nWhy should I use VCS ?\n\n\nEasy transition between versions\nMore productive, Time saver if a version produces error\nEnables cooperation with other developers (especially with a hosting service like GitHub).\n\n\nOk. There are some good points. But where is the catch ?\n\n\nWe are adding a new tool to our workflow (Git)\nKind of steep learning curve.\n\nWe have mentioned some of the most important programs for managing the code of an application. Of course, there are not a few times when we want to save the progress of our application somewhere else to enable developers communicate their code commits to each other. The solution is some code hosting services. The best known are GitHub, GitLab and Bitbucket. Finally, in case none of the options outlined earlier satisfy us, there is also the self-host solution. For example, if I had concerns about the terms of the above services, I could host Gitea on my own server or even to rent a cloud server. That way I would have my own “GitHub”, without depending on a third party service."
  },
  {
    "objectID": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#introduction",
    "href": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#introduction",
    "title": "Git Series (Part I - Configuration)",
    "section": "",
    "text": "A Version Control System (VCS) is a way to manage and track code changes. As we build an application, we add functions, change frontend features, fix bugs. We will need to edit the code many times. So we need a way to manage these changes. The tracking of every change to our code is the key point of VCS.\n\n\nWorkflow without Version Control\n\nSome popular Version Control Software are the following :\n\nGit\nApache Subversion (SVN)\nMercurial\nBazaar\n\nHaving seen what a VCS is, it would be interesting to see which one is the most widely used. In order to study which VCS is the most popular, I pulled data from Google Trends.\n\nCode  ggplot(data = trends_vcs_tidy, aes(x= Month, y = counts)) +\n  geom_line(aes(color = VCS)) +\n  labs(title = \"Trends on Version Control Systems\",\n              subtitle = \"Compare trends of Git and SVN (Subversion) from 2004 to 2022\",\n              caption = \"Data source: Google Trends\") +\n  theme_classic()\n\n\n\n\nThe figure above makes clear the dominance of Git as a version control tool. Also, we notice that Subversion (SVN) was quite popular and a capable competitor of Git until 2010. After that period there is a continuous decline in SVN’s interest and the exact opposite for Git. Today, in 2022, the difference is chaotic between them.\n\n\nWhy should I use VCS ?\n\n\nEasy transition between versions\nMore productive, Time saver if a version produces error\nEnables cooperation with other developers (especially with a hosting service like GitHub).\n\n\nOk. There are some good points. But where is the catch ?\n\n\nWe are adding a new tool to our workflow (Git)\nKind of steep learning curve.\n\nWe have mentioned some of the most important programs for managing the code of an application. Of course, there are not a few times when we want to save the progress of our application somewhere else to enable developers communicate their code commits to each other. The solution is some code hosting services. The best known are GitHub, GitLab and Bitbucket. Finally, in case none of the options outlined earlier satisfy us, there is also the self-host solution. For example, if I had concerns about the terms of the above services, I could host Gitea on my own server or even to rent a cloud server. That way I would have my own “GitHub”, without depending on a third party service."
  },
  {
    "objectID": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#git-settings",
    "href": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#git-settings",
    "title": "Git Series (Part I - Configuration)",
    "section": "Git settings",
    "text": "Git settings\nSet up Name & Email\nSo, you decided to start Git without setting Name and Email?\nYou may think of it again. In case you try to commit without setting a Name and email. Git will not commit your changes, without prior setting those.\n\n\nTerminal\n\ngit config --global user.name \"YourName\"\ngit config --global user.email your_email\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are planning to host your repository on GitHub, you may want to hide your casual email. In that case GitHub offers a noreply email for this purpose. You can read more here.\n\n\nSet editor\nA part that I considered a little bit hard is editing Git commits. By default, Ubuntu has installed Vim, so this was my first editor for my commits. I think this choice is good if you are writing short commit messages or you are acquainted with Vim options/shortcuts. In case you are in a hurry, the use of an alterantive (most familiar) IDE is justified.\n\n\nTerminal\n\ngit config --global core.editor \"editor_name\"\n\nMost notable is Visual Studio Code, which is the most popular IDE, according to recent Stackoveflow’s survey.\n\n\nEditor\nCommand\n\n\n\nAtom\ngit config –global core.editor “atom –wait”\n\n\nVisual Studio Code\ngit config –global core.editor “code –wait”\n\n\nDefault branch name to main\nIn October of 2020, GitHub announced that will change the default name of initial branch from master to main. \n\nThe default branch name for new repositories is now main. GitHub.blog - October 1,2020\n\nTherefore, it would be good to make this change in our local environment as well, as follows :\n\n\nTerminal\n\ngit config --global init.defaultBranch main\n\nMerge method\nOne change that is not exactly necessary but helps me is to change the defaults regarding merge. Let’s say that I want to add a new feature in my application. Most of the times I will make a branch on which I will start developing my new feature. When I implement this function and I’m ready to merge my changes into the main code there are two situations.\n1. There are commits to main branch \nThe predefined action is to merge. The branch is visible. Our setting has not any effect on this case.\n2. There are no commits to main branch\nThe predefined action of Git is to take the feature branch and paste it on the top of main branch. By making the setting above I am telling Git to keep the branch and react like the first case. The branch is visible again.\nWith simple words, I am forcing Git to keep branch, regardless of changes to main branch.\n\n\nTerminal\n\ngit config --global merge.ff false\n\nAuto-sign your commits\nIn a previous article we saw how to sign our commits as well as the reasons for doing so. In short, we made a PGP key which we added to our GitHub account. From that moment to sign my commits I had to write git commit -S -m \"something\", instead of git commit -m \"something\". Of course, that method is a little bit problematic. It is a little bit longer, little different in comparison to what I am used to type and most importantly I may forget some times to sign it manually. The last one happened to me A LOT. Thankfully, there is a way to be carefree about that anymore. I can set git config in a way that my commits will be signed automatically.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do not have already a GPG key, you can have a look in this guide in order to generate one. Also, depending your hosting platform for your code, you can link your GPG with your account : \n\n\nGitHub and GPG keys \n\n\nBitBucket and GPG keys \n\nGitLab and GPG keys\n\n\n\n\n\nTerminal\n\ngpg --list-secret-keys --keyid-format LONG\ngit config user.signingkey key_id\ngit config commit.gpgsign true\n\nCheck your settings\nMaking the above settings, we can have a summary of those with the corresponding command:\n\n\nTerminal\n\ngit config --list\n\nHere is the output on my machine :\n\n\nOutput of git-config command\n\nThe image above sums up the settings of Git. Although, each user has different needs and for that reason it would be good in case you want to learn more about git config to see their documentation page."
  },
  {
    "objectID": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#to-sum-up",
    "href": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#to-sum-up",
    "title": "Git Series (Part I - Configuration)",
    "section": "To sum up",
    "text": "To sum up\nA summary of the commands we used to configure Git :\n\n\nTerminal\n\ngit config --global user.name \"YourName\"\ngit config --global user.email your_email\ngit config --global core.editor \"editor_name\"\ngit config --global init.defaultBranch main\ngit config --global merge.ff false\n\n# Add PGP key to your commits\n\ngpg --list-secret-keys --keyid-format LONG\ngit config user.signingkey key_id\ngit config commit.gpgsign true\n\n# check git config settings\n\ngit config --list --show-origin\n\nOf course you can access your git config file on your Home directory (at least on Ubuntu installation).\n\n\n\n\n\n\nWarning\n\n\n\nNote that the .gitconfig file, which contains our settings, may not be visible in the Home directory. In general, files whose names begin with a period are not displayed. However, if everything has been done correctly, it’s probably there. For example, in Ubuntu you should choose to show hidden files.\n\n\nIn case you open that file you will see probably something like the above :"
  },
  {
    "objectID": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#acknowledgements",
    "href": "english/2022-11-04-Git-Commands/2022-11-04-Git-Commands.html#acknowledgements",
    "title": "Git Series (Part I - Configuration)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nImage by Daniel Skovran from Pixabay"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html",
    "title": "Predict Possible Interested Clients",
    "section": "",
    "text": "Introduction\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset    2.4 Dataset Structure    2.5 Custon Functions \n\n\nEDA with R    3.1 Missing Values    3.2 Univariate Analysis        3.2.1 Qualitative variables        3.2.2 Quantitative variables    3.3 Bivariate Analysis        3.3.1 Qualitative variables        3.3.2 Quantitative variables \n\n\nBuilding Model    4.1 Split train/test Dataset    4.2 Recipes    4.3 Create Validation Set    4.4 Specify Models    4.5 Hyperparameters tuning    4.6 Fit Resamples    4.7 Evaluate Model    4.8 Last Fit \n\n\nResults"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-libraries",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-libraries",
    "title": "Predict Possible Interested Clients",
    "section": "Import libraries",
    "text": "Import libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, François, Henry, Müller, & Vaughan, 2023). The kableExtra (Zhu, 2021) package was used to print the results in table format. Concerning general purpose R libraries, I also used gridExtra in order to show ggplot items side to side.\nOn its basis this analysis is about to predict if someone is interested or not to have a term deposit. Thus, we need to build a ML model. The all-in-one solution package tidymodels is crucial to this. Although, there are some concerns about our data (imbalanced predicted value and our implementation of LightGBM. Thankfully, these are solved by bonsai and treesnip packages, respectively.\nFinally, the ggplot2 (Wickham, Chang, et al., 2022) package was used to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nCode# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(kableExtra)\nlibrary(gridExtra)\n\n# Build ML models\nlibrary(tidymodels)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Other R packages\nlibrary(fontawesome)\n\n\n# Build ML models\n\nlibrary(tidymodels)\nlibrary(bonsai)\nlibrary(themis)\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-dataset",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#import-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading R libraries, then I will load my data. The initial source of my dataset has various versions of the same dataset. I will use the smaller one, as the fitting process on Boosting algorithms it is more time consuming in comparison with other methods (e.g. Logistic Regression, k-Nearest Neighbours etc.).\n\nCodebank_dataset &lt;- read_delim(\"bank_dataset_files/bank.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\nbank_dataset = bank_dataset %&gt;% tibble::rowid_to_column(\"ID\")"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#preview-dataset",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#preview-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Preview dataset",
    "text": "Preview dataset\nHere we can see a small chunk of my dataset (first 10 rows / observations) just to understand the dataset’s structure and type of variables.\n\nCode#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_bank_dataset = head(bank_dataset, 10)\nkbl(preview_bank_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\nID\nage\njob\nmarital\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nday\nmonth\nduration\ncampaign\npdays\nprevious\npoutcome\ny\n\n\n\n1\n30\nunemployed\nmarried\nprimary\nno\n1787\nno\nno\ncellular\n19\noct\n79\n1\n-1\n0\nunknown\nno\n\n\n2\n33\nservices\nmarried\nsecondary\nno\n4789\nyes\nyes\ncellular\n11\nmay\n220\n1\n339\n4\nfailure\nno\n\n\n3\n35\nmanagement\nsingle\ntertiary\nno\n1350\nyes\nno\ncellular\n16\napr\n185\n1\n330\n1\nfailure\nno\n\n\n4\n30\nmanagement\nmarried\ntertiary\nno\n1476\nyes\nyes\nunknown\n3\njun\n199\n4\n-1\n0\nunknown\nno\n\n\n5\n59\nblue-collar\nmarried\nsecondary\nno\n0\nyes\nno\nunknown\n5\nmay\n226\n1\n-1\n0\nunknown\nno\n\n\n6\n35\nmanagement\nsingle\ntertiary\nno\n747\nno\nno\ncellular\n23\nfeb\n141\n2\n176\n3\nfailure\nno\n\n\n7\n36\nself-employed\nmarried\ntertiary\nno\n307\nyes\nno\ncellular\n14\nmay\n341\n1\n330\n2\nother\nno\n\n\n8\n39\ntechnician\nmarried\nsecondary\nno\n147\nyes\nno\ncellular\n6\nmay\n151\n2\n-1\n0\nunknown\nno\n\n\n9\n41\nentrepreneur\nmarried\ntertiary\nno\n221\nyes\nno\nunknown\n14\nmay\n57\n2\n-1\n0\nunknown\nno\n\n\n10\n43\nservices\nmarried\nprimary\nno\n-88\nyes\nyes\ncellular\n17\napr\n313\n1\n147\n2\nfailure\nno"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#dataset-structure",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#dataset-structure",
    "title": "Predict Possible Interested Clients",
    "section": "Dataset structure",
    "text": "Dataset structure\nBefore we do any analysis we have to define what kind of data we have available. We can assess this type of information by looking on the values of each variable. Generally, we can classify our variables, depending their values, as follows :\n\n\nCodegraph TD;\n  A(Type of variables) --&gt; B(Quantitative)\n  A(Type of variables) --&gt; C(Qualitative)\n  B --&gt; D(Discrete)\n  B --&gt; E(Continuous)\n  C --&gt; J(Nominal)\n  C --&gt; G(Ordinal)\n\n\n\ngraph TD;\n  A(Type of variables) --&gt; B(Quantitative)\n  A(Type of variables) --&gt; C(Qualitative)\n  B --&gt; D(Discrete)\n  B --&gt; E(Continuous)\n  C --&gt; J(Nominal)\n  C --&gt; G(Ordinal)\n\n\n\n\n\n\nOur dataset is consisted by 18 variables (columns) and 4521 observations (rows). More specifically, concerning my variables, are as follows :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nAge\n\nquantitative  (continuous)\nThe age of the respondent\n\n\nJob\n\nqualitative  (nominal)\nThe sector of employment of the respondent\n\n\nMarital\n\nqualitative  (nominal)\nThe marital status of the respondent\n\n\nEducation\n\nqualitative  (ordinal)\nThe higher education level that the respondent has ever reached\n\n\nDefault\n\nqualitative  (nominal)\nhas credit in default?\n\n\nBalance\n\nquantitative  (continuous)\nAverage yearly balance, in euros\n\n\nHousing\n\nqualitative  (nominal)\nHas housing loan?\n\n\nLoan\n\nqualitative  (nominal)\nHas personal loan?\n\n\nContact\n\nqualitative  (nominal)\nContact communication type\n\n\nMonth\n\nqualitative  (ordinal)\nLast contact day of the month\n\n\nDuration\n\nquantitative  (continuous)\nLast contact duration, in seconds (numeric)\n\n\nCampaign\nquantitative\nNumber of contacts performed during this campaign and for this client\n\n\npdays\nquantitative\nNumber of days that passed by after the client was last contacted from a previous campaign\n\n\npprevious\nquantitative\nNumber of contacts performed before this campaign and for this client\n\n\npoutcome\n\nqualitative (nominal)\nOutcome of the previous marketing campaign\n\n\nDeposit\n\nqualitative  (nominal)\nHas the client subscribed a term deposit?\n\n\n\nThus, my sample has 18 variables, of which 7 are quantitative and 10 are quantitative properties, of which 8 are nominal and the rest ones (Education, Month) are ordinal.\n\nCodebank_dataset$y = as.factor(bank_dataset$y)"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#custom-functions",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#custom-functions",
    "title": "Predict Possible Interested Clients",
    "section": "Custom functions",
    "text": "Custom functions\n\nSo, I have a basic idea about my data. Can we start analyzing our data?\n\nIt depends. If you want to do a simple analysis then yes. Although most of the times this is not the case. Probably there is the need for repetitive actions. In order to not repeat ourselves we need to define some actions, prior to our analysis.\nOn this occasion, I found beneficial the definition of a function for qualitative data.\n\nCodeunivariate_qualitative = function(variable, title_plot){\ntable = bank_dataset %&gt;%\n    select(variable) %&gt;%\n    table() %&gt;%\n    prop.table() %&gt;%\n    as.data.frame() %&gt;%\n    magrittr::set_colnames(c(\"Var1\", \"Freq\"))\n  \nplot =  ggplot(data = table, aes(x = fct_reorder(Var1,Freq, .desc = T), fill=Var1, y = Freq)) + \n     geom_bar(stat = \"identity\")+\n     scale_fill_hue(c = 40) +\n     geom_text(aes(label = sprintf(\"%.2f %%\", Freq*100),  stat=\"identity\",\n        vjust = -.1)) +\n     labs(\n       title = title_plot,\n       caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n       x = \"Response\",\n       y = \"Observations\"\n        ) +\n     theme_classic() +\n     theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5),)\n  \nreturn(plot)\n}\n\n\nI will do the same for univariate numeric data.\n\nCodeuniv_quanti = function(variable_sel){\n  ggplot(bank_dataset, aes(x = variable_sel )) +\n  geom_histogram(x = variable_sel, stat = \"count\") +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Age Distribution of Respondents\",\n    caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Age of Respondent\",\n    y = \"Observations\"\n  ) +\n  theme_classic() + \n  theme(\n    plot.caption = element_markdown(lineheight = 1.2),\n    plot.title = element_text(hjust = 0.5))\n}"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#missing-values",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#missing-values",
    "title": "Predict Possible Interested Clients",
    "section": "Missing Values",
    "text": "Missing Values\n\nCodehow_many_nas = sum(is.na(bank_dataset))\n\n\nOn this dataset there are 0 missing values, in total. So, there is no need for imputation."
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#univariate-analysis",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#univariate-analysis",
    "title": "Predict Possible Interested Clients",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nQualitative variables\n\n\nJob\nMarital status\nEducation\nDefault\nHousing\nLoan\nContact\nMonth\npoutcome\nDeposit\n\n\n\n\nCodeunivariate_qualitative(\"job\", \"Job of Respondent\")\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"marital\", \"Marital Status of the respondent\")\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"education\", \"Educational Backgroung\")\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"default\", \"Has credit in default ?\")\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"housing\", \"Has housing loan?\")\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"loan\", \"Has personal loan ?\")\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"contact\", \"Type of Contact\")\n\n\n\n\n\n\n\n\n\n\nCodeoptions(digits =2)\n\nperc_month = table(bank_dataset$month) %&gt;%\n  prop.table() %&gt;%\n  sort(decreasing = T) %&gt;%\n  as.data.frame()\n\nnum_month = table(bank_dataset$month) %&gt;%\n  sort(decreasing = T) %&gt;%\n  as.data.frame()\n\nperc_month %&gt;%\n    ggplot(aes(x = factor(Var1, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), y = Freq)) + \n  geom_bar(stat = \"identity\")+\n  scale_fill_hue(c = 40) +\n  geom_text(aes(label = sprintf(\"%.2f\", Freq*100),  stat=\"identity\",\n        vjust = -.25)) +\n  labs(\n    title = \"Calls per month\",\n    caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"poutcome\", \"Outcome of previous approach\")\n\n\n\n\n\n\n\nCodeunivariate_qualitative(\"y\", \"How many people made a deposit account ?\")\n\n\n\n\n\n\n\n\n\n\nQuantitative variables\n\n\nAge\nBalance\nDuration\nCampaign\n\n\n\n\nCodeggplot(bank_dataset, aes(x = age )) +\n  geom_bar() +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Age Distribution of Respondents\",\n    caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Age of Respondent\",\n    y = \"Observations\"\n  ) +\n  theme_classic() + \n  theme(\n    plot.caption = element_markdown(lineheight = 1.2),\n    plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\nCode# NOTE : In order to make HTML tags to work I need to specify element on theme command.\n\n\n\n\n\nCodeggplot(bank_dataset, aes(x=balance)) + \n  geom_histogram(bins = 20) +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Average yearly balance\",\n    caption = \" Bank Marketing Data Set from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nCodeggplot(bank_dataset, aes(x=duration, fill=duration)) + \n  geom_histogram( ) +\n  scale_fill_hue(c = 40) +\n  theme_bw() +\n  labs(\n    title = \"How many people made a deposit account ?\",\n    caption = \"Data from the 1974 Motor Trend US magazine.\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nCodeggplot(bank_dataset, aes(x= campaign, fill=campaign )) + \n  geom_bar() +\n  scale_fill_hue(c = 40) +\n  theme_bw() +\n  labs(\n    title = \"Number of Approaches to a specific person\",\n    x = \"# of Approaches\",\n    y = \"Observations\"\n  ) + \n  theme_classic()"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#bivariate-analysis",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#bivariate-analysis",
    "title": "Predict Possible Interested Clients",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nOn the previous section I learned a lot about my dataset. Now, I have to reveal relationships between my variables. Visualizing those relationships will make it even easier to explain our results. In order to make the right plots on the right occasions I used the book “Datavis with R” (Chapter 4 : Bivariate Graphs).\nQualitative variables\n\n\nJob\nMarital status\nEducation\nDefault\nHousing\nLoan\nContact\nMonth\npoutcome\n\n\n\n\nCodeplotjob &lt;- bank_dataset %&gt;%\n  group_by(job, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct))\n\nplot_job = ggplot(plotjob, \n       aes(x = fct_reorder(job, pct),\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Job of Respondent by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\nplot_job\n\n\n\n\n\n\n\nCodeplot_marital1 &lt;- ggplot(bank_dataset, \n       aes(x = marital, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n       geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplotmarital &lt;- bank_dataset %&gt;%\n  group_by(marital, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct))\n\nplot_marital2 = ggplot(plotmarital, \n       aes(x = marital,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Marital Status by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nCodegridExtra::grid.arrange(plot_marital1, plot_marital2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_education1 &lt;- ggplot(bank_dataset, \n       aes(x = education, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n       geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_education2 = bank_dataset %&gt;%\n  group_by(education, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = education,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Educational Background by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nCodegridExtra::grid.arrange(plot_education1, plot_education2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_default1 &lt;- ggplot(bank_dataset, \n       aes(x = default, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_default2 = bank_dataset %&gt;%\n  group_by(default, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = default,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Has credit in default ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'default'. You can override using the\n`.groups` argument.\n\n\n\nCodegridExtra::grid.arrange(plot_default1, plot_default2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_housing1 &lt;- ggplot(bank_dataset, \n       aes(x = housing, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_housing2 = bank_dataset %&gt;%\n  group_by(housing, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = housing,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Has housing loan ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'housing'. You can override using the\n`.groups` argument.\n\n\n\nCodegridExtra::grid.arrange(plot_housing1, plot_housing2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_loan1 &lt;- ggplot(bank_dataset, \n       aes(x = loan, \n           fill = y)) + \n      scale_fill_hue(c = 40) +\n      theme_bw() +\n      geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_loan2 = bank_dataset %&gt;%\n  group_by(loan, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = loan,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Has personal loan ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'loan'. You can override using the\n`.groups` argument.\n\n\n\nCodegridExtra::grid.arrange(plot_loan1, plot_loan2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_contact1 &lt;- ggplot(bank_dataset, \n       aes(x = contact, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_contact2 = bank_dataset %&gt;%\n  group_by(contact, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = contact,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Forms of contact\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'contact'. You can override using the\n`.groups` argument.\n\n\n\nCodegridExtra::grid.arrange(plot_contact1, plot_contact2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_month1 &lt;- ggplot(bank_dataset, \n       aes(x = factor(month, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_month2 &lt;- ggplot(bank_dataset, \n       aes(x = factor(month, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), fill = y)) + \n       geom_bar(position = \"fill\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal()\n\n\n\nCodegridExtra::grid.arrange(plot_month1, plot_month2, nrow =1)\n\n\n\n\n\n\n\nCodeplot_poutcome1 &lt;- ggplot(bank_dataset, \n       aes(x = poutcome, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nCodeplot_poutcome2 = bank_dataset %&gt;%\n  group_by(poutcome, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n   ggplot(aes(x = poutcome,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Previous Campaign outcome\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nCodegridExtra::grid.arrange(plot_poutcome1, plot_poutcome2, nrow =1)\n\n\n\n\n\n\n\nQuantitative variables\n\n\nAge\nBalance\nDuration\nCampaign\n\n\n\n\nCodebank_dataset %&gt;%\nggplot(aes(x=y, y=age, fill=y)) +\n  geom_boxplot() +\n  scale_fill_hue(c = 40) +\n  theme_classic() +\n  labs(\n     title = \"Age & Desire of Bank Deposit Account\" \n  )\n\n\n\n\n\n\n\nCodeplot1 = bank_dataset[bank_dataset$balance &lt; 15000, ] %&gt;%\nggplot(aes(x = balance, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_histogram(bins=15)\n\nplot1\n\n\n\n\n\n\n\nCodeggplot(bank_dataset, \n       aes(x = duration, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nCodeggplot(bank_dataset, \n       aes(x = campaign, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#split-traintest-dataset",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#split-traintest-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Split train/test dataset",
    "text": "Split train/test dataset\nOur first step is to split our dataset on 2 parts. Each of those will be used for a different purpose. The first part’s (train dataset) purpose is to build our model. The other part (test dataset) will be used to evaluate our model’s performance.\n\nCodeset.seed(123)\nbank_dataset_split &lt;- initial_split(bank_dataset,\n                                prop = 0.75,\n                                strata = y)\n\n# Create training data\nbank_train &lt;- bank_dataset_split %&gt;%\n                    training()\n\n# Create testing data\nbank_test &lt;- bank_dataset_split %&gt;%\n                    testing()\n\n\n\n\nTrain dataset\nTest dataset\n\n\n\n\nCodehead(bank_train) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nID\nage\njob\nmarital\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nday\nmonth\nduration\ncampaign\npdays\nprevious\npoutcome\ny\n\n\n\n1\n30\nunemployed\nmarried\nprimary\nno\n1787\nno\nno\ncellular\n19\noct\n79\n1\n-1\n0\nunknown\nno\n\n\n2\n33\nservices\nmarried\nsecondary\nno\n4789\nyes\nyes\ncellular\n11\nmay\n220\n1\n339\n4\nfailure\nno\n\n\n4\n30\nmanagement\nmarried\ntertiary\nno\n1476\nyes\nyes\nunknown\n3\njun\n199\n4\n-1\n0\nunknown\nno\n\n\n5\n59\nblue-collar\nmarried\nsecondary\nno\n0\nyes\nno\nunknown\n5\nmay\n226\n1\n-1\n0\nunknown\nno\n\n\n7\n36\nself-employed\nmarried\ntertiary\nno\n307\nyes\nno\ncellular\n14\nmay\n341\n1\n330\n2\nother\nno\n\n\n8\n39\ntechnician\nmarried\nsecondary\nno\n147\nyes\nno\ncellular\n6\nmay\n151\n2\n-1\n0\nunknown\nno\n\n\n\n\n\n\n\n\nCodehead(bank_test) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nID\nage\njob\nmarital\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nday\nmonth\nduration\ncampaign\npdays\nprevious\npoutcome\ny\n\n\n\n3\n35\nmanagement\nsingle\ntertiary\nno\n1350\nyes\nno\ncellular\n16\napr\n185\n1\n330\n1\nfailure\nno\n\n\n6\n35\nmanagement\nsingle\ntertiary\nno\n747\nno\nno\ncellular\n23\nfeb\n141\n2\n176\n3\nfailure\nno\n\n\n15\n31\nblue-collar\nmarried\nsecondary\nno\n360\nyes\nyes\ncellular\n29\njan\n89\n1\n241\n1\nfailure\nno\n\n\n23\n44\nservices\nsingle\nsecondary\nno\n106\nno\nno\nunknown\n12\njun\n109\n2\n-1\n0\nunknown\nno\n\n\n51\n45\nblue-collar\ndivorced\nprimary\nno\n844\nno\nno\nunknown\n5\njun\n1018\n3\n-1\n0\nunknown\nyes\n\n\n52\n37\ntechnician\nsingle\nsecondary\nno\n228\nyes\nno\ncellular\n20\naug\n1740\n2\n-1\n0\nunknown\nno"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#recipes",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#recipes",
    "title": "Predict Possible Interested Clients",
    "section": "Recipes",
    "text": "Recipes\nAn important part in the process of model building is preprocessing. Depending of model type and data structure, I have to do the necessary changes. The tidymodels offers some ready-made preprocessing functions which make the whole process piece of cake.\nIn instance, the dataset I am working right now has imbalanced response variable (term deposit interest). For that reason, I used the recipe step_smote() from themis package.\n\nCodebank_recipe &lt;- recipes::recipe(y~., \n                               data = bank_train) %&gt;%\n  step_rm(poutcome, ID) %&gt;%\n  step_corr(all_numeric(), threshold = 0.75) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;% prep() %&gt;%\n  step_smote(y) %&gt;%\n  prep()\n\n\nLet’s preview our dataset after applying our recipes :\n\nCodebank_recipe %&gt;%\n  prep() %&gt;%\n  juice() %&gt;%\n  head() %&gt;%\n  kbl() %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nTable 1: Dataset after recipes\n\n\nage\nbalance\nday\nduration\ncampaign\npdays\nprevious\njob_blue.collar\njob_entrepreneur\njob_housemaid\njob_management\njob_retired\njob_self.employed\njob_services\njob_student\njob_technician\njob_unemployed\njob_unknown\nmarital_married\nmarital_single\neducation_secondary\neducation_tertiary\neducation_unknown\ndefault_yes\nhousing_yes\nloan_yes\ncontact_telephone\ncontact_unknown\nmonth_aug\nmonth_dec\nmonth_feb\nmonth_jan\nmonth_jul\nmonth_jun\nmonth_mar\nmonth_may\nmonth_nov\nmonth_oct\nmonth_sep\ny\n\n\n\n30\n1787\n19\n79\n1\n-1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\nno\n\n\n33\n4789\n11\n220\n1\n339\n4\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno\n\n\n30\n1476\n3\n199\n4\n-1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\nno\n\n\n59\n0\n5\n226\n1\n-1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno\n\n\n36\n307\n14\n341\n1\n330\n2\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno\n\n\n39\n147\n6\n151\n2\n-1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#create-validation-set",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#create-validation-set",
    "title": "Predict Possible Interested Clients",
    "section": "Create validation set",
    "text": "Create validation set\n\nSo, how good is the model? Not so fast…\n\nWe could actually build the model and evaluate its performance. The problem with that approach is the sample.\n\nCodecv_folds &lt;- recipes::bake(\n  bank_recipe,\n  new_data = bank_train) %&gt;%\n  rsample::vfold_cv(v = 5, strata = y)"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#specify-models",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#specify-models",
    "title": "Predict Possible Interested Clients",
    "section": "Specify models",
    "text": "Specify models\nNext, parsnip helps us to specify our models. Initially, I will define a LightGBM model,\n\nCodelightgbm_model&lt;- parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %&gt;%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\nand an XGBoost one.\n\nCodexgboost_model&lt;- parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %&gt;%\n set_engine(\"xgboost\")"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#hyperparameters-tuning",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#hyperparameters-tuning",
    "title": "Predict Possible Interested Clients",
    "section": "Hyperparameters tuning",
    "text": "Hyperparameters tuning\nNow, we are specifying the hyperpaterers’ values and a grid to check which combination of those are performing better according to our desired metric (in our case ROC). This has to be done for both, LightGBM\n\nCodelightgbm_params &lt;- dials::parameters(\n min_n(),\n tree_depth(range = c(4,10)),\n learn_rate() # learning rate\n)\n\n\n\nCodelightgbm_grid &lt;- dials::grid_max_entropy(\n lightgbm_params,\n size = 10)\n\nhead(lightgbm_grid) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n\n\n\n3\n5\n0.00\n\n\n3\n7\n0.00\n\n\n11\n10\n0.00\n\n\n33\n4\n0.08\n\n\n10\n5\n0.01\n\n\n31\n9\n0.00\n\n\n\n\n\nand XGBoost.\n\nCodexgboost_params &lt;- dials::parameters(\n min_n(),\n tree_depth(range = c(4,10)),\n learn_rate() # learning rate\n)\n\n\n\nCodexgboost_grid &lt;- dials::grid_max_entropy(\n  xgboost_params,\n  size = 10\n)\n\nhead(xgboost_grid) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n\n\n\n5\n6\n0.00\n\n\n4\n8\n0.00\n\n\n37\n9\n0.00\n\n\n2\n5\n0.00\n\n\n21\n9\n0.01\n\n\n21\n5\n0.05"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#fit-resamples",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#fit-resamples",
    "title": "Predict Possible Interested Clients",
    "section": "Fit resamples",
    "text": "Fit resamples\n\nCode# build workflow for LightGBM\n\nlightgbm_workflow &lt;- workflows::workflow() %&gt;%\n add_model(lightgbm_model) %&gt;%\n add_formula(y ~.)\n\n\n\nCode# build workflow for XGBoost\n\nxgboost_workflow &lt;- workflows::workflow() %&gt;%\n  add_model(xgboost_model) %&gt;%\n  add_formula(y~.)\n\n\nFinally, we can build the LightGBM model by combining :\n\nThe workflows we set it up above\nThe resamples\nGrid of values (hyperparameters)\nMetric based on which we will evaluate our model’s performance\n\n\nCodestart_time_lightgbm &lt;- Sys.time()\n\nlightgbm_tuned_model &lt;- tune::tune_grid(\n object = lightgbm_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = lightgbm_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)\n\nend_time_lightgbm &lt;- Sys.time()\n\ntime_lightgbm = difftime(end_time_lightgbm,start_time_lightgbm,units = \"secs\")\n\n\nSimilarly, for XGBoost.\n\nCodestart_time_xgboost &lt;- Sys.time()\n\nxgboost_tuned_model &lt;- tune::tune_grid(\n object = xgboost_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = xgboost_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)\n\nend_time_xgboost &lt;- Sys.time()\n\ntime_xgboost= difftime(end_time_xgboost,start_time_xgboost,units = \"secs\")"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#evaluate-model",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#evaluate-model",
    "title": "Predict Possible Interested Clients",
    "section": "Evaluate model",
    "text": "Evaluate model\nOur first results based on resamples for LightGBM\n\nCodelightgbm_tuned_model %&gt;%\n  show_best(\"roc_auc\",n=5) %&gt;% \n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n33\n4\n0.08\nroc_auc\nbinary\n0.90\n5\n0.01\nPreprocessor1_Model04\n\n\n16\n10\n0.06\nroc_auc\nbinary\n0.90\n5\n0.01\nPreprocessor1_Model10\n\n\n10\n5\n0.01\nroc_auc\nbinary\n0.89\n5\n0.01\nPreprocessor1_Model05\n\n\n34\n10\n0.00\nroc_auc\nbinary\n0.86\n5\n0.01\nPreprocessor1_Model07\n\n\n29\n6\n0.00\nroc_auc\nbinary\n0.86\n5\n0.01\nPreprocessor1_Model09\n\n\n\n\n\nand XGBoost\n\nCodexgboost_tuned_model %&gt;%\n  show_best(\"roc_auc\",n=5) %&gt;% \n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n21\n5\n0.05\nroc_auc\nbinary\n0.88\n5\n0.01\nPreprocessor1_Model06\n\n\n21\n9\n0.01\nroc_auc\nbinary\n0.85\n5\n0.01\nPreprocessor1_Model05\n\n\n5\n6\n0.00\nroc_auc\nbinary\n0.84\n5\n0.01\nPreprocessor1_Model01\n\n\n40\n5\n0.00\nroc_auc\nbinary\n0.83\n5\n0.01\nPreprocessor1_Model08\n\n\n19\n7\n0.00\nroc_auc\nbinary\n0.83\n5\n0.01\nPreprocessor1_Model07"
  },
  {
    "objectID": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#last-fit",
    "href": "english/2022-11-24-Predict-Possible-Clients/2022-11-24-Predict-Possible-Clients.html#last-fit",
    "title": "Predict Possible Interested Clients",
    "section": "Last fit",
    "text": "Last fit\nBy now we can assess which is the best combination of values. Given those I will assess my model’s performance on unknown (to my model) data. LightGBM model has 0.8469 ROC-value\n\nCodelast_fit_lightgbm_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = 33,\n learn_rate = 0.0787,\n tree_depth = 4) %&gt;%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\n\nCodeoptions(digits = 4)\n\nlast_fit_workflow &lt;- lightgbm_workflow %&gt;% \n  update_model(last_fit_lightgbm_model)\n\nlast_lightgbm_fit &lt;- \n  last_fit_workflow %&gt;% \n  last_fit(bank_dataset_split)\n\n! train/test split: preprocessor 1/1, model 1/1: NAs introduced by coercion\n\n\n! train/test split: preprocessor 1/1, model 1/1 (predictions): NAs introduced by coercion\n\nCodelast_lightgbm_fit %&gt;% \n  collect_metrics() %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\naccuracy\nbinary\n0.8833\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8471\nPreprocessor1_Model1\n\n\n\n\n\nand XGBoost, 0.8736.\n\nCodelast_fit_xgboost_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = 21,\n learn_rate = 0.0472,\n tree_depth = 5) %&gt;%\nset_engine(\"xgboost\")\n\n\n\nCodeoptions(digits = 4)\n\nlast_fit_xgboost_workflow &lt;- xgboost_workflow %&gt;% \n  update_model(last_fit_xgboost_model)\n\nlast_xgboost_fit &lt;- \n  last_fit_xgboost_workflow %&gt;% \n  last_fit(bank_dataset_split)\n\nlast_xgboost_fit %&gt;% \n  collect_metrics() %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\naccuracy\nbinary\n0.8921\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8693\nPreprocessor1_Model1"
  },
  {
    "objectID": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html",
    "href": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html",
    "title": "List of Quarto Websites",
    "section": "",
    "text": "Note\n\n\n\nI have decided to convert the article into a GitHub Repo.\n\n\nGiven the increased popularity of Quarto, I took the initiative to make a list of some sites that are using this framework. That way, users of other popular frameworks (e.g., distill, blogdown) will have the chance to see the features of a Quarto site. Furthermore, existing Quarto users can draw inspiration from other web pages.\nUnfortunately, it is certain that this list does not contain every Quarto website. However, you are welcome to comment yours in order to be added."
  },
  {
    "objectID": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#introduction",
    "href": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#introduction",
    "title": "List of Quarto Websites",
    "section": "",
    "text": "Note\n\n\n\nI have decided to convert the article into a GitHub Repo.\n\n\nGiven the increased popularity of Quarto, I took the initiative to make a list of some sites that are using this framework. That way, users of other popular frameworks (e.g., distill, blogdown) will have the chance to see the features of a Quarto site. Furthermore, existing Quarto users can draw inspiration from other web pages.\nUnfortunately, it is certain that this list does not contain every Quarto website. However, you are welcome to comment yours in order to be added."
  },
  {
    "objectID": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#inspiration",
    "href": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#inspiration",
    "title": "List of Quarto Websites",
    "section": "Inspiration",
    "text": "Inspiration\nA couple of years ago, I had the desire to create a portfolio website, and I tried out many options. Long story short, I ended up using Distill, and I really loved it because it offered a balance of simplicity and professionalism. Despite some minor issues with Distill (many of which are resolved by Quarto), I was extremely happy with the platform. However, I faced a challenge as I was not only an amateur R programmer but also lacked hands-on experience with HTML/CSS. Around the same time, I discovered a website that listed many Distill websites together. This compilation of websites provided several benefits for me:\n\nUnderstand the limits of the Distill\nMotivation to look on others’ websites and take some inspiration\nEasy access to implemented features and their respective code\n\nIn 2022, Quarto was announced and the things on website publishing with R changed a little bit. Many users have already considered the change to the new framework (based on the Distill sites listing above). Some others may are hesitant due to the fact that Quarto is new or they are not interested to read long documentation. Thus, I believe that a listing of Quarto websites is needed to make the framework more accessible to newer users and speed the implementation of features for existing ones."
  },
  {
    "objectID": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#list-of-quarto-sites",
    "href": "english/2022-08-10-List-of-Quarto-Sites/2022-08-10-List-of-Quarto-Sites.html#list-of-quarto-sites",
    "title": "List of Quarto Websites",
    "section": "List of Quarto Sites",
    "text": "List of Quarto Sites\nAn indicative list of websites using Quarto is as follows:\n\n\n\n\n\n\n\n\n   User\n\n   Website URL\n\n   Repository\n\n\n\naeturell\naeturrell.com\nhome\n\n\nalexpghayes\nalexpghayes.com\nquarto-blog\n\n\nalmeidasilvaf\nalmeidasilvaf.github.io/\nalmeidasilvaf.github.io\n\n\nandreashandel\nandreashandel.com/\nandreashandelwebsite\n\n\nandrewheiss\nandrewheiss.com\nath-quarto\n\n\nandrewheiss\nnonprofitf22.classes.andrewheiss.com\nnonprofitf22.classes.andrewheiss.com\n\n\naster-hu\nasterhu.com/\nAsteroid_Blog\n\n\nbeatrizmilz\nbeamilz.com\nblog-en\n\n\nBioconductor\nbioconductor.github.io/biocblog/\nbiocblog\n\n\ncgoo4\nquantumjitter.com/\nquantumjitter\n\n\nCrumpLab\ncrumplab.com/\nCrumpLab.github.io\n\n\ncurrocam\ncurrocam.github.io/biocblog/\ncurrocam.github.io\n\n\ncynthiahqy\ncynthiahqy.com/\ndigital-garden\n\n\ndaxkellie\ndaxkellie.com\nwebsite-quarto\n\n\nddimmery\nddimmery.com\nquarto-website\n\n\ndjnavarro\nblog.djnavarro.net/\nquarto-blog\n\n\ndrganghe\ndrganghe.github.io\ndrganghe.github.io\n\n\nekholme\nericekholm.com/\nee-quarto-site\n\n\nEllaKaye\nellakaye.co.uk/\nellakaye.co.uk \n\n\nEmilHvitfeldt\nemilhvitfeldt.com\nemilhvitfeldt.com\n\n\nepiforecasts\nepiforecasts.io/\nepiforecasts.github.io\n\n\nfusionet24\nmyyearindata.com/\nmyyearindata \n\n\nivelasq\nivelasq.rbind.io\npipedream\n\n\nJavOrraca\njavierorracadeatcu.com/\nquarto-blog \n\n\njbkunst\njkunst.com/blog/\nblog\n\n\njessesadler\njessesadler.com\nquarto-blog\n\n\njeweljohnsonj\nsciquest.netlify.app//\nSciQuest\n\n\njhelvy\njhelvy.com\njhelvy_quarto\n\n\njoelnitta\njoelnitta.com\njoelnitta-home\n\n\njournalovi\njournalovi.org\njournalovi.github.io\n\n\njthomasmock\nTheMockup.blog\nthemockup-blog\n\n\nkathoffman\nkhstats.com/\nkhstats-quarto\n\n\nkelly-sovacool\nsovacool.dev//\nkelly-sovacool.github.io\n\n\nkurianbenoy\nkurianbenoy.com\nkurianbenoy-website\n\n\nmagsol\nmagsol.github.io/\nmagsol.github.io\n\n\nmarioangst\nmarioangst.com/en/\n–\n\n\nmarkusschanta\nblog.markus.schanta.at/\nblog\n\n\nmarvinschmitt\nmarvinschmitt.com/\nmarvinschmitt-dot-com\n\n\nmatherion\nbehaviorchange.eu/\npersonal-website\n\n\nmaxdrohde\nmaximilianrohde.com\nblog_quarto\n\n\nmcanouil\nmickael.canouil.fr/\nmickael.canouil.fr\n\n\nmdsumner\nhypertidy.org\nquarto-blog\n\n\nMeghansaha\nthetidytrekker.com/\nthetidytrekker-quarto\n\n\nmine-cetinkaya-rundel\nA Quarto tip a day\nquarto-tip-a-day\n\n\nmiriamheiss\nmiriamheiss.com/\nmiriam-blog\n\n\nmmhamdy\nhypothesis-space.netlify.app/\nHypothesis-Space\n\n\nnjlyon0\nnjlyon0.github.io\nnjlyon0.github.io\n\n\nnucleic-acid\njollydata.blog\nquarto-blog\n\n\nnumbats\nnumbat.space/\nnumbats-quarto-website\n\n\nOpenscapes\nopenscapes.github.io/quarto-website-tutorial/\nquarto-website-tutorial\n\n\npat-alt\npaltmeyer.com/\npat-alt.github.io\n\n\npaul-buerkner\npaul-buerkner.github.io/\npaul-buerkner.github.io\n\n\npkollenda\nphilippkollenda.com/\nWebsite\n\n\nPossible-Institute\npossible.institute\nwebsite\n\n\nquarto-dev\nquarto.org\nquarto-web\n\n\nrlbarter\nrebeccabarter.com\npersonal-website-quarto\n\n\nrobertmitchellv\nrobertmitchellv.com\nrobertmitchellv.github.io\n\n\nrobjhyndman\nrobjhyndman.com/\nrobjhyndman.com\n\n\nrsangole\nrsangole.netlify.app/\nblog\n\n\nsamanthacsik\nsamanthacsik.github.io/\nsamanthacsik.github.io\n\n\nseeM\nwasimlorgat.com\nblog\n\n\nshamindras\nshamindras.com\nss_personal_distill_blog\n\n\nsrvanderplas\nsrvanderplas.github.io/\nsrvanderplas.github.io\n\n\nStefanThoma\nstefanthoma.github.io/quarto-blog/\nquarto-blog\n\n\nstesiam\nstesiam.com\nstesiam.github.io\n\n\ntidymodels\ntidymodels.org\ntidymodels.org\n\n\nladerast\nladerast.github.io/\nladerast.github.io\n\n\nvbaliga\nvbaliga.github.io\nvbaliga.github.io\n\n\nwillingc\nwillingconsulting.com/\nwilling-consulting-2022\n\n\nzekiakyol\nzekiakyol.com/\npersonal-website"
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html",
    "title": "Statistics of Statistics Graduates",
    "section": "",
    "text": "NOTE: Frequent updates should be expected until this note be erased.\nThe recent study guide includes data about the graduates and their average grade of graduation over the years. First and foremost the data we are interested in are included in table form (which is good) but is is part of a pdf file (which is not good :)). Thankfully, tabulizer is the solution to this kind of problems."
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#introduction",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#introduction",
    "title": "Statistics of Statistics Graduates",
    "section": "",
    "text": "NOTE: Frequent updates should be expected until this note be erased.\nThe recent study guide includes data about the graduates and their average grade of graduation over the years. First and foremost the data we are interested in are included in table form (which is good) but is is part of a pdf file (which is not good :)). Thankfully, tabulizer is the solution to this kind of problems."
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#load-packages",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#load-packages",
    "title": "Statistics of Statistics Graduates",
    "section": "Load Packages",
    "text": "Load Packages\nAs I will extract tables from a pdf file, I will definitely need tabulizer package. Unfortunately, I was not able to install the specific package, as I was getting an error similar to this one. This issue seems to be related to rJava package and this comment solved the issue. After installing rJava I was able to install successufully tabulizer as below:\n\n# remotes::install_github(c(\"ropensci/tabulizerjars\", \"ropensci/tabulizer\"))\n\n\nlibrary(rJava)\nlibrary(tabulizer)\nlibrary(dplyr)\nlibrary(pdftools)\nlibrary(tidyr)\nlibrary(reactable)\n\nlibrary(ggplot2)\nlibrary(ggtext)\nlibrary(showtext)\nlibrary(glue)\n\nfont_add_google(\"Lobster\", \"lobster\")\nfont_add_google(\"Economica\", \"economica\")\nshowtext_auto()"
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#extract-data",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#extract-data",
    "title": "Statistics of Statistics Graduates",
    "section": "Extract Data",
    "text": "Extract Data\nThe study guide gives a general description of the university, as well as the prerequisites for a degree and a detailed description of each course. In total, the guide is a little bit less than 200 pages! Of course we don’t need My main source of data is the Department’s study guide. The most recent one (2022) has data on admissions, graduations etc., since 2004. The study guide gives a general description of the university, as well as the prerequisites for a degree and a detailed description of each course. In total, the guide is a little bit less than 200 pages! Of course we don’t need everything in there. I am just interested on the tables of the last pages, so I will extract those pages first from the original pdf.\n\n# url = \"https://www.unipi.gr/faculty/mbouts/anak/OS_22_23.pdf\"\n# \n# download.file(url, \n#               destfile = \"sg22.pdf\",\n#               method = \"wget\",\n#               extra = \"--no-check-certificate\")\n\npdf_subset('sg22.pdf',\n  pages = 186:190,  output = \"subset.pdf\")\n\n[1] \"/home/stelios/stesiam.github.io/english/2023-07-23-Graduates-of-Statistics/subset.pdf\"\n\n\nSo, we extracted the pages which we are interested in. Let’s take a look at them:\n\n\nThankfully, tabulizer comes with a very handy function to extract all the tables from a PDF file. Yeap, I know the original study guide is written in greek but don’t worry that’s just to take a basic understanding of how the pdf and the tables look. I will translate the column names when I will work with the data. But look at the bright side. At least we will get a notebook with ggplot2 visualizations as an alternative of those Excel graphs :)\n\nstatistics_tables &lt;- extract_tables(\n    file   = \"subset.pdf\", \n    method = \"decide\", \n    output = \"data.frame\")\n\nExtracting the tables from splitted PDF I get a list of 5 tables with my data. It’s amazing that in a matter of seconds I get all the information in a format ready for analysis. If I were to write them the traditional way (copy-paste) it would definitely take me an hour."
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#analysing-data",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#analysing-data",
    "title": "Statistics of Statistics Graduates",
    "section": "Analysing Data",
    "text": "Analysing Data\nAdmitted students\nSo, in Greece there is 1 standard way to be admitted to a university. Although there are 3 more ways which require some certain conditions. I will try to explain them as simple as possible.\nMain Exams\nOnce a year, third-year high school students from all over Greece take exams on the same subjects at the same time. The exams are known as Panhellenic Exams. Until today, it’s one of the few things in Greece that as its integrity is not disputed, as the papers of students are getting graded by teachers from other areas. However, it has also faced considerable criticism for the pressure it places on students. In my opinion a fair one as everything in your life is depending on these exams… If you fail you should wait to retake them next year.\nTypically the exams are being held between the second half of May and the first week of June. The students’ grades are getting published approximately either the end of June or the first days of July. Then you are completing a list on which you are declare which departments you are interested to. On the end of July the minimum grades to be admitted for each department are announced. Those can fluctuate significantly every year as they are depending on both students’ performance on the Exams and the difficulty of the exams.\nIn a nutchell, the departments from big cities like Attica (Athens, Piraeus) and Thessaloniki have the biggest demand and so the minimum grades for those are higher from the rest ones. For example, the Statistics Department in Piraeus had a minimum grade of 11700 in 2019 (for simplicity consider it like 11.7/20). The corresponding department of Statistics in University of Aegean the same year had a minimum grade of 5100 (5.1/20) (yes, that’s not a typo). Well there are many reasons behind that, as the continuance of austerity in Greece, but in general that’s the pattern.\nNot so fun fact but when I made my list of preference for studies, Statistics in Piraeus was something like 15th place, so I guess my fate was that. Okay and a little bit of anxiety. :)\nTransfer\nAs I wrote earlier there are some exceptions. First of all the Admission by Transfer is referring to transfer your place in one department with one similar-study in other city. There are many criteria mainly based on your income. For example, a student admitted on Statistics on University of Aegean could be admitted on Statistics Department on Piraeus (i.e. in case his/her family hasn’t enough income).\nThese seats are limited.\nEntry Exams\nIn case you have already graduated a Bachelor programme then you are able to give Entry Exams on your department of choice, instead of the nightmare of Panhellenic Exams.\n\nadmitted_students = statistics_tables[[1]] %&gt;%\n  .[-1,] %&gt;%\n  setNames(c(\"Year\", \"Main_exams\", \"Transfer\", \"Entry_exams\", \"Other\", \"Total\"))\n\nadmitted_students$Main_exams = admitted_students$Main_exams %&gt;% as.integer()\nadmitted_students$Transfer= admitted_students$Transfer %&gt;% as.integer()\nadmitted_students$Entry_exams = admitted_students$Entry_exams %&gt;% as.integer()\nadmitted_students$Other = admitted_students$Other %&gt;% as.integer()\n\nrownames(admitted_students) = 1:nrow(admitted_students)\n\nadmitted_students = admitted_students %&gt;% \n  pivot_longer(\n    cols = !Year, \n    names_to = \"Admission_Type\", \n    values_to = \"count\"\n  )\n\nadmitted_students %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\n\n\nadmitted_students %&gt;%\n  filter(Admission_Type %in% c(\"Main_exams\", \"Total\")) %&gt;%\n  ggplot2::ggplot(., aes(x = Year, y = count, color = Admission_Type , group = Admission_Type)) +\n  geom_line() +\n  labs(\n    title = \"Admitted students\",\n    subtitle = \"Admitted students over the years (2003-2023) at Department of Statistics and Insurance Science of &lt;br&gt; University of Piraeus. A significant drop in admissions occured in 2021 which is maily caused by the &lt;br&gt; introduction of grade requirements to be admitted to specific departments.\",\n    caption = \"stesiam, 2023\",\n    x = \"Academic Year\",\n    y = \"Students\",\n    color = \"Type of Admission\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_markdown(family = \"lobster\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"economica\"),\n    plot.caption = element_markdown(family = \"economica\"),\n    axis.text.x = element_text(face=\"bold\", angle=90)\n  )\n\n\n\n\nMaster Programmes\nDepartment of Statistics and Isurance Science has 2 master programs\n\nmsc_students = statistics_tables[[2]] %&gt;%\n  setNames(c(\"AcademicYear\", \"BSc\", \"MSc (AppliedStat)\", \"MSc (Actuar)\", \"PhD\")) %&gt;%\n  .[-1,]\n\nrownames(msc_students) = 1:nrow(msc_students)\n\nmsc_students = msc_students %&gt;%\n  mutate_at(c(\"BSc\", \"MSc (AppliedStat)\", \"MSc (Actuar)\", \"PhD\"), as.numeric) %&gt;%\n  mutate(pct = round((PhD/BSc)*100, 2))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `MSc (Actuar) = .Primitive(\"as.double\")(`MSc (Actuar)`)`.\nCaused by warning:\n! NAs introduced by coercion\n\nmsc_students %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\n\n\nggplot(msc_students, aes(x = AcademicYear, y = pct, group = 1)) +\n  geom_line() +\n  labs(\n    title = \"Ratio of PhD students/ Undergraduates\",\n    subtitle = \"The decrease \",\n    caption = \"stesiam, 2023\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_markdown(family = \"serif\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"serif\"),\n    plot.caption = element_markdown(family = \"serif\"),\n    axis.text.x = element_text(face=\"bold\", angle=90)\n  )\n\n\n\n\n\ntidy_students = msc_students %&gt;%\n  select(!pct) %&gt;%\n  tidyr::pivot_longer(., cols = !c(AcademicYear), values_to = \"count\")\n\nggplot(tidy_students, aes(x = AcademicYear, y = count, fill = name)) +\n  geom_col() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(\n    title = \"Ratio of PhD students/ Undergraduates\",\n    subtitle = \"The decrease \",\n    caption = \"stesiam, 2023\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_markdown(family = \"serif\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"serif\"),\n    plot.caption = element_markdown(family = \"serif\"),\n    axis.text.x = element_text(face=\"bold\", angle=90)\n  )\n\nWarning: Removed 4 rows containing missing values (position_stack)."
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#msc-students",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#msc-students",
    "title": "Statistics of Statistics Graduates",
    "section": "MSc Students",
    "text": "MSc Students\n\nstatistics_tables[[3]] %&gt;%\n  select(c(1,2)) %&gt;%\n  setNames(c(\"Year\", \"S\")) %&gt;%\n  .[-c(1,2),] %&gt;%\n  separate(S, c('Admitted', 'Graduated')) %&gt;%\n  na.omit() %&gt;%\n  mutate(Ratio = round(as.numeric(Graduated)/as.numeric(Admitted), 2)) %&gt;%\n  select(Year, Ratio) %&gt;%\n  ggplot(.) +\n  geom_line(aes(x = Year, y = Ratio, group = 1))+\n  theme_classic()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 21 rows [1, 3,\n5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, ...]."
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#graduation-grade",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#graduation-grade",
    "title": "Statistics of Statistics Graduates",
    "section": "Graduation Grade",
    "text": "Graduation Grade\nI hope you are still here because for the end I hold the best part. Finally, how did we perform? The study guide gives a distribution\n\nstatistics_tables[[4]] %&gt;%\n  setNames(c(\"Year\", \"[5.0 - 6)\", \"[6, 7)\", \"X3\", \"(\", \"AVG_Grade\"))\n\n          Year  [5.0 - 6)      [6, 7)         X3          (    AVG_Grade\n1         Έτος                                               Βαθμολογίας\n2               [5.0-6.0)   [6.0-7.0)  [7.0-8.5) [8.5-10.0]             \n3  Αποφοίτησης                                              (Σύνολο απο-\n4                                                                φοίτων)\n5    2003-2004 20,71 (29)     60 (84) 19,29 (27)   0,00 (0)   6,46 (140)\n6    2004-2005 16,89 (37) 62,10 (136) 21,00 (46)   0,00 (0)   6,54 (219)\n7    2005-2006 24,17 (29)  55,83 (67) 19,17 (23)   0,83 (1)   6,48 (120)\n8    2006-2007  6,13 (10) 72,39 (118) 19,63 (32)   1,84 (3)   6,51 (163)\n9    2007-2008 23,38 (36)  59,09 (91) 16,88 (26)   0,65 (1)   6,41 (154)\n10   2008-2009 24,68 (38)  61,69 (95) 12,99 (20)   0,64 (1)   6,39 (154)\n11   2009-2010 34,62 (54)  54,48 (85) 10,90 (17)   0,00 (0)   6,30 (156)\n12   2010-2011 25,16 (40)  57,86 (92) 16,35 (26)   0,63 (1)   6,40 (159)\n13   2011-2012 24,10 (40)  59,04 (98) 14,46 (24)   2,41 (4)   6,43 (166)\n14   2012-2013 25,13 (50) 63,32 (126) 10,05 (20)   1,51 (3)   6,36 (199)\n15   2013-2014 32,33(107) 56,19 (186)  9,67 (32)   1,81 (6)   6,33 (331)\n16   2014-2015 31,60 (67) 52,36 (111) 13,21 (28)   2,83 (6)   6,38 (212)\n17   2015-2016 30,89 (38)  51,22 (63) 17,07 (21)   0,81 (1)   6,36 (123)\n18   2016-2017 29,91 (35)  57,27 (67) 11,97 (14)   0,85 (1)   6,35 (117)\n19   2017-2018 28,57 (18)  60,32 (38)   6,35 (4)   4,76 (3)    6,39 (63)\n20   2018-2019 27,36 (58) 60,38 (128) 10,85 (23)   1,41 (3)   6,38 (212)\n21   2019-2020 28,18 (62) 57,73 (127) 14,09 (31)   0,00 (0)   6,39 (220)\n22   2020-2021 13,36 (33) 67,61 (167) 18,22 (45)   0,81 (2)   6,41 (247)\n23   2021-2022 10,50 (19) 65,75 (119) 21,55 (39)   2,20 (4)   6,65 (181)"
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#acknowledgements",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#acknowledgements",
    "title": "Statistics of Statistics Graduates",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nDataset based on recent study guide recent study guide of Department of Statistics and Insurance Science of the University of Piraeus.\nImage by Victoria Loveland from Pixabay"
  },
  {
    "objectID": "english/2022-07-27-hello/27-07-2022-hello.html",
    "href": "english/2022-07-27-hello/27-07-2022-hello.html",
    "title": "Hello, World",
    "section": "",
    "text": "Finally, I made my site using Quarto and hosted it via GitHub Pages.\nIt was a month ago, that I decided to start building my website. Initially, I was experimenting with other frameworks (e.g., Hugo with the help of blogdown, Distill), which were pretty good, but Quarto fulfilled my needs. The reasons for my decision are going to be discussed in a new article."
  },
  {
    "objectID": "english/2022-07-27-hello/27-07-2022-hello.html#acknowledgments",
    "href": "english/2022-07-27-hello/27-07-2022-hello.html#acknowledgments",
    "title": "Hello, World",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nImage by R. E. Beck from Pixabay"
  },
  {
    "objectID": "greek.html",
    "href": "greek.html",
    "title": "Greek Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nΠρόσβαση στο API του data.gov.gr\n\n\n\n\n\n\n\nR\n\n\nAPI\n\n\n\n\nΈνας απλός οδηγός χρήσης του API του data.gov.gr, ώστε να λαμβάνετε τη ροή δεδομένων με τη χρήση της R.\n\n\n\n\n\n\nJul 4, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nΣπουδές Στατιστικής στην Ελλάδα\n\n\n\n\n\n\n\nΣπουδές\n\n\n\n\nΣυγκρίνω τις δημόσιες σχολές στατιστικής στην Ελλάδα και συγκρίνω τα βασικά τους στοιχεία με βάση τους οδηγούς σπουδών τους.\n\n\n\n\n\n\nJun 20, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nΣυγκεντρωμένο υλικό για την R στα ελληνικά\n\n\n\n\n\n\n\nR\n\n\n\n\nΜία λίστα (που θα ανανεώνεται συνεχώς) με υλικό που υπάρχει διαθέσιμο στο διαδίκτυο (δωρεάν) σχετικά με την R\n\n\n\n\n\n\nOct 23, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "material.html",
    "href": "material.html",
    "title": "Material",
    "section": "",
    "text": "Title\nType\nSize\nLanguage\nSource\n\n\n\n\nSummary of Distributions\nPDF\n44.8 KB\n\nRepository"
  },
  {
    "objectID": "material.html#personal-notes",
    "href": "material.html#personal-notes",
    "title": "Material",
    "section": "",
    "text": "Title\nType\nSize\nLanguage\nSource\n\n\n\n\nSummary of Distributions\nPDF\n44.8 KB\n\nRepository"
  },
  {
    "objectID": "material.html#assignments",
    "href": "material.html#assignments",
    "title": "Material",
    "section": "Assignments",
    "text": "Assignments\n\n\n\n\nTitle\nType\nSize\nLanguage\nSource\n\n\n\n\nMethods and Techniques of Sampling (II - 2023)\nPDF\n619 KB\n\nPrivate Repo\n\n\nAnalysis of Variance\nPDF\n479 KB\n\nPrivate Repo\n\n\nStatistical Packages II (R)\nPDF\n1.9 MB\n\n–\n\n\nNon Parametric Statistics (Hand)\nPDF\n948 KB\n\n–"
  },
  {
    "objectID": "material.html#posters",
    "href": "material.html#posters",
    "title": "Material",
    "section": "Posters",
    "text": "Posters\n\n\n\n\nTitle\nType\n\nSize\nLanguage\n\n\n\n\nBefore my First Stats Lecture\nPDF\n248 KB\n\nRepo"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html",
    "title": "Predict Survivors of MS Estonia",
    "section": "",
    "text": "Introduction \n\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Datasset    2.4 Dataset Structure    2.5 Convert Categorical variables    2.6 Outliers    2.7 Missing Values \n\n\nEDA with R    3.1 Univariate Analysis    3.2 Bivariate Analysis    3.3 Correlogram \n\n\nBuilding Predictive Model    4.1 Split train/test Dataset    4.2 Recipes    4.3 Build Model    4.4 Fit    4.5 Evaluate Model \n\nReferences"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#import-libraries",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#import-libraries",
    "title": "Predict Survivors of MS Estonia",
    "section": "Import Libraries",
    "text": "Import Libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, François, Henry, Müller, & Vaughan, 2023). The kableExtra (Zhu, 2021) package was used to print the results in table format.\nFinally, the ggplot2 (Wickham, Chang, et al., 2022) package is necessary to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nCode# General purpose R libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(kableExtra)\n\n\n# Packages for maps\n\nlibrary(ggplot2)\nlibrary(ggtext)\n\n\n# Build ML models\n\nlibrary(tidymodels)\nlibrary(bonsai)\nlibrary(themis)\nlibrary(vip)"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#import-dataset",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#import-dataset",
    "title": "Predict Survivors of MS Estonia",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading the libraries, I am able to use the commands of the readr package to import my data. My data is in .csv format, so I’ll use the read_csv() command (Wickham, Hester, et al., 2022) to import them.\n\nCodeestonia_passenger_list = read_csv(\"data/estonia-passenger-list.csv\")"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#preview-dataset",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#preview-dataset",
    "title": "Predict Survivors of MS Estonia",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nCode#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n\nhead(estonia_passenger_list, 10) %&gt;%\n  kbl(\n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\") %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n\nPassengerId\nCountry\nFirstname\nLastname\nSex\nAge\nCategory\nSurvived\n\n\n\n1\nSweden\nARVID KALLE\nAADLI\nM\n62\nP\n0\n\n\n2\nEstonia\nLEA\nAALISTE\nF\n22\nC\n0\n\n\n3\nEstonia\nAIRI\nAAVASTE\nF\n21\nC\n0\n\n\n4\nSweden\nJURI\nAAVIK\nM\n53\nC\n0\n\n\n5\nSweden\nBRITTA ELISABET\nAHLSTROM\nF\n55\nP\n0\n\n\n6\nSweden\nGERD INGA MAGNHILD\nAHLSTROM\nF\n71\nP\n0\n\n\n7\nSweden\nHJALMAR\nAHLSTROM\nM\n60\nP\n0\n\n\n8\nEstonia\nPILLE\nAHMAN\nF\n18\nP\n0\n\n\n9\nEstonia\nTORMI\nAINSALU\nM\n30\nC\n0\n\n\n10\nSweden\nANNA MARIA\nALDRIN\nF\n63\nP\n0"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#dataset-structure",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#dataset-structure",
    "title": "Predict Survivors of MS Estonia",
    "section": "Dataset Structure",
    "text": "Dataset Structure\nOur dataset is consisted by 8 variables (columns) and 989 observations (rows). More specifically :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nPassengerId\n\nqualitative  (discrete)\nId of passenger, Not important for analysis\n\n\nCountry\n\nqualitative  (nominal)\nCountry of Origin of the passenger\n\n\nFirstname\n\nqualitative  (nominal)\nPassenger’s first name\n\n\nLastname\n\nqualitative  (nominal)\nPassenger’s last name\n\n\nSex\n\nqualitative  (nominal)\nSex of Passenger\n\n\nAge\n\nquantitative  (continuous)\nThe age of the passenger\n\n\nCategory\n\nqualitative  (nominal)\nPassenger or member of the crew\n\n\nSurvived\n\nqualitative  (nominal)\nDid the person survive ?\n\n\n\nThus, my sample has 8 variables, of which 1 is quantitative and 7 are qualitative (nominal) properties."
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#convert-categorical-variables",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#convert-categorical-variables",
    "title": "Predict Survivors of MS Estonia",
    "section": "Convert Categorical variables",
    "text": "Convert Categorical variables\n\nCodeestonia_passenger_list$Country = as.factor(estonia_passenger_list$Country)\nestonia_passenger_list$Sex = as.factor(estonia_passenger_list$Sex)\nestonia_passenger_list$Category = as.factor(estonia_passenger_list$Category)\n\nestonia_passenger_list$Survived[estonia_passenger_list$Survived == \"0\"] &lt;- \"No\"\nestonia_passenger_list$Survived[estonia_passenger_list$Survived == \"1\"] &lt;- \"Yes\"\nestonia_passenger_list$Survived &lt;- factor(estonia_passenger_list$Survived)"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#outliers-and-nas",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#outliers-and-nas",
    "title": "Predict Survivors of MS Estonia",
    "section": "Outliers and NAs",
    "text": "Outliers and NAs\n\nCodeboxplot(estonia_passenger_list$Age)\n\n\n\n\nOn this dataset there are 0 missing values, in total.\n\nCodesum(is.na(estonia_passenger_list))"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#preview-cleaned-dataset",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#preview-cleaned-dataset",
    "title": "Predict Survivors of MS Estonia",
    "section": "Preview Cleaned Dataset",
    "text": "Preview Cleaned Dataset\n\nCode#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n\nhead(estonia_passenger_list, 10) %&gt;%\n  kbl(\n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\") %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n\n\nPassengerId\nCountry\nFirstname\nLastname\nSex\nAge\nCategory\nSurvived\n\n\n\n1\nSweden\nARVID KALLE\nAADLI\nM\n62\nP\nNo\n\n\n2\nEstonia\nLEA\nAALISTE\nF\n22\nC\nNo\n\n\n3\nEstonia\nAIRI\nAAVASTE\nF\n21\nC\nNo\n\n\n4\nSweden\nJURI\nAAVIK\nM\n53\nC\nNo\n\n\n5\nSweden\nBRITTA ELISABET\nAHLSTROM\nF\n55\nP\nNo\n\n\n6\nSweden\nGERD INGA MAGNHILD\nAHLSTROM\nF\n71\nP\nNo\n\n\n7\nSweden\nHJALMAR\nAHLSTROM\nM\n60\nP\nNo\n\n\n8\nEstonia\nPILLE\nAHMAN\nF\n18\nP\nNo\n\n\n9\nEstonia\nTORMI\nAINSALU\nM\n30\nC\nNo\n\n\n10\nSweden\nANNA MARIA\nALDRIN\nF\n63\nP\nNo"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#univariate-analysis",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#univariate-analysis",
    "title": "Predict Survivors of MS Estonia",
    "section": "Univariate Analysis",
    "text": "Univariate Analysis\n\n\nCountry\nSex\nAge\nCategory\nSurvived\n\n\n\n\nCodetable(estonia_passenger_list$Country) %&gt;% sort(decreasing = T) %&gt;% kbl()\n\n\n\nVar1\nFreq\n\n\n\nSweden\n550\n\n\nEstonia\n344\n\n\nLatvia\n28\n\n\nFinland\n16\n\n\nRussia\n14\n\n\nNorway\n9\n\n\nGermany\n8\n\n\nDenmark\n6\n\n\nLithuania\n4\n\n\nGreat Britain\n2\n\n\nMorocco\n2\n\n\nNetherlands\n2\n\n\nBelarus\n1\n\n\nCanada\n1\n\n\nFrance\n1\n\n\nNigeria\n1\n\n\n\n\n\n\n\n\nCodep&lt;-ggplot(estonia_passenger_list, aes(x=Sex, fill = Sex)) +\n  geom_bar() +\n  theme_minimal()\np\n\n\n\n\n\n\n\n\n\n\nCodetable(estonia_passenger_list$Category) %&gt;% sort(decreasing = T)\n\n\n  P   C \n796 193 \n\n\n\n\n\nCodetable(estonia_passenger_list$Survived) %&gt;% sort(decreasing = T)\n\n\n No Yes \n852 137 \n\nCodeestonia_passenger_list$Survived[estonia_passenger_list$Survived == 0] &lt;- \"No\"\nestonia_passenger_list$Survived[estonia_passenger_list$Survived == 1] &lt;- \"Yes\"\nestonia_passenger_list$Survived &lt;- factor(estonia_passenger_list$Survived)"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#bivariate-analysis",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#bivariate-analysis",
    "title": "Predict Survivors of MS Estonia",
    "section": "Bivariate Analysis",
    "text": "Bivariate Analysis\n\n\nCountry\nSex\nAge\nCategory"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#split-traintest-dataset",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#split-traintest-dataset",
    "title": "Predict Survivors of MS Estonia",
    "section": "Split train/test Dataset",
    "text": "Split train/test Dataset\n\nCode## Split train/test Dataset\n\nset.seed(123)# Create data split for train and test\nestonia_passenger_list_split &lt;- initial_split(estonia_passenger_list,\n                                prop = 0.75,\n                                strata = Survived)\n\n# Create training data\nestonia_ms_train &lt;- estonia_passenger_list_split %&gt;%\n                    training()\n\n# Create testing data\nestonia_ms_test &lt;- estonia_passenger_list_split %&gt;%\n                    testing()\n\n\n\n\nTrain dataset\nTest dataset\n\n\n\n\nCodehead(estonia_ms_train) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nPassengerId\nCountry\nFirstname\nLastname\nSex\nAge\nCategory\nSurvived\n\n\n\n2\nEstonia\nLEA\nAALISTE\nF\n22\nC\nNo\n\n\n4\nSweden\nJURI\nAAVIK\nM\n53\nC\nNo\n\n\n5\nSweden\nBRITTA ELISABET\nAHLSTROM\nF\n55\nP\nNo\n\n\n6\nSweden\nGERD INGA MAGNHILD\nAHLSTROM\nF\n71\nP\nNo\n\n\n7\nSweden\nHJALMAR\nAHLSTROM\nM\n60\nP\nNo\n\n\n8\nEstonia\nPILLE\nAHMAN\nF\n18\nP\nNo\n\n\n\n\n\n\n\n\nCodehead(estonia_ms_test) %&gt;%\n  kbl() %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nPassengerId\nCountry\nFirstname\nLastname\nSex\nAge\nCategory\nSurvived\n\n\n\n1\nSweden\nARVID KALLE\nAADLI\nM\n62\nP\nNo\n\n\n3\nEstonia\nAIRI\nAAVASTE\nF\n21\nC\nNo\n\n\n9\nEstonia\nTORMI\nAINSALU\nM\n30\nC\nNo\n\n\n12\nEstonia\nNELLI\nALEKSEEVA\nF\n61\nP\nNo\n\n\n17\nEstonia\nARMIDO\nALLAS\nM\n31\nP\nNo\n\n\n22\nEstonia\nPAUL\nANDERSON\nM\n32\nC\nYes"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#recipes",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#recipes",
    "title": "Predict Survivors of MS Estonia",
    "section": "Recipes",
    "text": "Recipes\n\nCodepreprocessing_recipe &lt;-\nrecipes::recipe(Survived ~ Sex + Age + Category, data = estonia_ms_train) %&gt;%\n recipes::step_other(all_nominal(), threshold = 0.01) %&gt;%\n recipes::step_nzv(all_nominal()) %&gt;%\n prep()"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#create-validation-set",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#create-validation-set",
    "title": "Predict Survivors of MS Estonia",
    "section": "Create Validation Set",
    "text": "Create Validation Set\n\nCodecv_folds &lt;- recipes::bake(\n  preprocessing_recipe,\n  new_data = estonia_ms_train) %&gt;%\n  rsample::vfold_cv(v = 5, strata = Survived)\n\n\n\nCodecv_folds\n\n#  5-fold cross-validation using stratification \n# A tibble: 5 × 2\n  splits            id   \n  &lt;list&gt;            &lt;chr&gt;\n1 &lt;split [592/149]&gt; Fold1\n2 &lt;split [592/149]&gt; Fold2\n3 &lt;split [593/148]&gt; Fold3\n4 &lt;split [593/148]&gt; Fold4\n5 &lt;split [594/147]&gt; Fold5"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#build-logistic-regression-model",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#build-logistic-regression-model",
    "title": "Predict Survivors of MS Estonia",
    "section": "Build Logistic Regression Model",
    "text": "Build Logistic Regression Model\n\nCodelightgbm_model&lt;- parsnip::boost_tree(\n mode = \"classification\",\n trees = 300,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %&gt;%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#hyperparameters-tuning",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#hyperparameters-tuning",
    "title": "Predict Survivors of MS Estonia",
    "section": "Hyperparameters tuning",
    "text": "Hyperparameters tuning\n\nCodelightgbm_params &lt;- dials::parameters(\n min_n(), # min data in leaf\n tree_depth(range = c(4,10)), # depth\n# In most cases, the optimal depth ranges from 4 to 10. \n# Values in the range from 6 to 10 are recommended. \n learn_rate() # learning rate\n)\n\n\n\nCodelightgbm_grid &lt;- dials::grid_max_entropy(\n lightgbm_params,\n size = 15)\n\nhead(lightgbm_grid) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n\n\n\n22\n7\n0.0712038\n\n\n10\n6\n0.0000000\n\n\n8\n10\n0.0000000\n\n\n17\n5\n0.0935415\n\n\n27\n9\n0.0000000\n\n\n16\n8\n0.0000023"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#build-workflow",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#build-workflow",
    "title": "Predict Survivors of MS Estonia",
    "section": "Build workflow",
    "text": "Build workflow\n\nCodelightgbm_workflow &lt;- workflows::workflow() %&gt;%\n add_model(lightgbm_model) %&gt;%\n add_formula(Survived ~ Sex + Age + Category)"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#fit",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#fit",
    "title": "Predict Survivors of MS Estonia",
    "section": "Fit",
    "text": "Fit\n\nCodelightgbm_tuned_model &lt;- tune::tune_grid(\n object = lightgbm_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = lightgbm_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#evaluate-model",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#evaluate-model",
    "title": "Predict Survivors of MS Estonia",
    "section": "Evaluate Model",
    "text": "Evaluate Model\n\nCodelightgbm_tuned_model %&gt;%\n  show_best(\"roc_auc\",n=5) %&gt;% \n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n39\n9\n0.0323695\nroc_auc\nbinary\n0.7682891\n5\n0.0311866\nPreprocessor1_Model15\n\n\n22\n7\n0.0712038\nroc_auc\nbinary\n0.7640906\n5\n0.0293165\nPreprocessor1_Model01\n\n\n17\n5\n0.0935415\nroc_auc\nbinary\n0.7593860\n5\n0.0280185\nPreprocessor1_Model04\n\n\n20\n5\n0.0000003\nroc_auc\nbinary\n0.7514037\n5\n0.0277534\nPreprocessor1_Model08\n\n\n37\n7\n0.0000000\nroc_auc\nbinary\n0.7506410\n5\n0.0234851\nPreprocessor1_Model14"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#last-fit",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#last-fit",
    "title": "Predict Survivors of MS Estonia",
    "section": "Last Fit",
    "text": "Last Fit\n\nCodelast_fit_lightgbm_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 300,\n min_n = 4,\n learn_rate = 5.9e-05,\n tree_depth = 4) %&gt;%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\n\nCodelast_fit_workflow &lt;- lightgbm_workflow %&gt;% \n  update_model(last_fit_lightgbm_model)\n\nlast_rf_fit &lt;- \n  last_fit_workflow %&gt;% \n  last_fit(estonia_passenger_list_split)\n\nlast_rf_fit %&gt;% \n  collect_metrics() %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\naccuracy\nbinary\n0.8588710\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.7591549\nPreprocessor1_Model1"
  },
  {
    "objectID": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#acknowledgements",
    "href": "english/2023-03-31-Predict-Survivors-of-MS-Estonia/2023-03-31-Predict-Survivors-of-MS-Estonia.html#acknowledgements",
    "title": "Predict Survivors of MS Estonia",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nImage by Gianluca from Pixabay"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html",
    "title": "EDA on Greek Parliament",
    "section": "",
    "text": "Introduction\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Dataset    2.4 Structure of Dataset    2.5 Recoding variables    2.6 Setting colors \n\n\nParliament over the years \n\n\nMost elected members of parliament \n\n\nMost elected members by party    5.1 KKE    5.2 ND    5.3 PASOK    5.4 SYRIZA \n\n\nMost elected members per constituency    6.1 Attica    6.2 Central Greece    6.3 Central Macedonia    6.4 Crete    6.5 Eastern Macedonia and Thrace    6.6 Epirus    6.7 Ionian Islands    6.8 North Aegean    6.9 Peloponnese    6.10 South Aegean    6.11 Thessaly    6.12 Western Greece    6.13 Western Macedonia \n\nAcknowledgements\n\nReferences"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-libraries",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-libraries",
    "title": "EDA on Greek Parliament",
    "section": "Import Libraries",
    "text": "Import Libraries\nFirst and foremost, we have to load our libraries.\n\nCode# General purpose R libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(reactable)\n\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggpol) \nlibrary(ggtext)\n\n# Other settings\noptions(digits=2) # print only 2 decimals"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-dataset",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#import-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading R libraries, then I will load my data.\n\nCodeparliament &lt;- read_csv(\"data/greek_parliament.csv\")"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#preview-dataset",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#preview-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nCodepreview_dataset = head(parliament, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\nTable 1: Preview Dataset (first 6 rows)\n\nFullName\nParty\nConstituency\nTerm\n\n\n\nAgorastis Vasileios\nPA.SO.K. (Panhellenic Socialist Movement)\nLarissa\n3\n\n\nAkrita Sylva - Kaiti\nPA.SO.K. (Panhellenic Socialist Movement)\nAthens B\n3\n\n\nAkritidis Nikolaos\nPA.SO.K. (Panhellenic Socialist Movement)\nThessaloniki A\n3\n\n\nAkrivakis Alexandros\nPA.SO.K. (Panhellenic Socialist Movement)\nViotia\n3\n\n\nAlevras Ioannis\nPA.SO.K. (Panhellenic Socialist Movement)\nAthens A\n3\n\n\nAlexandris Efstathios (Stathis)\nPA.SO.K. (Panhellenic Socialist Movement)\nAthens B\n3\n\n\nAlexiadis Konstantinos\nPA.SO.K. (Panhellenic Socialist Movement)\nTrikala\n3\n\n\nAlexiou Thomas\nNEA DIMOKRATIA\nXanthi\n3\n\n\nAllamanis Stylianos\nNEA DIMOKRATIA\nKarditsa\n3\n\n\nAmanatidis Konstantinos\nPA.SO.K. (Panhellenic Socialist Movement)\nThessaloniki B\n3"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#structure-of-dataset",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#structure-of-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Structure of Dataset",
    "text": "Structure of Dataset\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nFull Name\n\nqualitative  (nominal)\nSurname and name of the member of parliament\n\n\nParty\n\nqualitative  (nominal)\nThe party on which the MP got elected\n\n\nConstituency\n\nqualitative  (nominal)\nMP got elected on this area\n\n\nTerm\n\nqualitative  (ordinal)\nPlenum term\n\n\n\nThus, my sample has 4 variables, of which 0 are quantitative and 4 are quantitative properties, of which 3 are nominal and the rest one (Term) is ordinal."
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#recoding-variables",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#recoding-variables",
    "title": "EDA on Greek Parliament",
    "section": "Recoding variables",
    "text": "Recoding variables\nParty names can vary from short to lengthy ones. The last ones are a problem for our analysis because their names can not fit to our visualisations. The table below is showing all the parties that have ever participated in parliament. Is is apparent that some parties have really long names.\n\nCodedata.frame(\n  Party = unique(parliament$Party),\n  Length = str_length(unique(parliament$Party))\n) %&gt;%\n  arrange(-Length) %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\n\nIn our case the parties with the longest name is AN.EL. and Democratic Coalition with 81 and 70 characters, respectively. On the contrary, the shortest party name is POL.A. with 6 characters.\n\nCode## Recoding parliament$Party\nparliament$Party[parliament$Party == \"ANEXARTITOI DIMOKRATIKOI VOULEFTES\"] &lt;- \"ADP\"\nparliament$Party[parliament$Party == \"ANEXARTITOI ELLINES (Independent Hellenes)\"] &lt;- \"ANEL\"\nparliament$Party[parliament$Party == \"ANEXARTITOI ELLINES (Independent Hellenes) National Patriotic Democratic Alliance\"]&lt;- \"ANEL\"\nparliament$Party[parliament$Party == \"Coalition of the Left and Progress\"] &lt;- \"SYRIZA\"\nparliament$Party[parliament$Party == \"Communist Party of Greece (Interior)\"] &lt;- \"KKE (interior)\"\nparliament$Party[parliament$Party == \"DEMOCRATIC COALITION (Panhellenic Socialist Movement Democratic Left )\"] &lt;- \"PASOK\"\nparliament$Party[parliament$Party == \"DHM.AR (Democratic Left)\"] &lt;- \"DHMAR\"\nparliament$Party[parliament$Party == \"DI.ANA.\"] &lt;- \"DIANA\"\nparliament$Party[parliament$Party == \"DI.K.KI.\"] &lt;- \"DIKKI\"\nparliament$Party[parliament$Party == \"INDEPENDENT\"] &lt;- \"INDEPENDENT\"\nparliament$Party[parliament$Party == \"KOMMOUNISTIKO KOMMA ELLADAS\"] &lt;- \"KKE\"\nparliament$Party[parliament$Party == \"LA.O.S.\"] &lt;- \"LAOS\"\nparliament$Party[parliament$Party == \"LAIKI ENOTITA\"] &lt;- \"LAE\"\nparliament$Party[parliament$Party == \"LAIKOS SYNDESMOS - CHRYSI AVGI (People’s Association – Golden Dawn)\"] &lt;- \"XA\"\nparliament$Party[parliament$Party == \"NEA DIMOKRATIA\"] &lt;- \"ND\"\nparliament$Party[parliament$Party == \"PA.SO.K. (Panhellenic Socialist Movement)\"] &lt;- \"PASOK\"\nparliament$Party[parliament$Party == \"POL.A.\"] &lt;- \"POLA\"\nparliament$Party[parliament$Party == \"SYNASPISMOS RIZOSPASTIKIS ARISTERAS\"] &lt;- \"SYRIZA\"\nparliament$Party[parliament$Party == \"TO POTAMI (The River)\"] &lt;- \"POTAMI\"\nparliament$Party[parliament$Party == \"ΟΟ.ΕΟ.\"] &lt;- \"ΟΟ.ΕΟ\""
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#setting-colors",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#setting-colors",
    "title": "EDA on Greek Parliament",
    "section": "Setting colors",
    "text": "Setting colors\nA few days after, I decided that there should be a consistency in the choice of colors. That’s the reason of this section. Thus, I will assign a dedicated hex color code to each party.\n\nCodekke_color = \"#FF6666\"\nnd_color = \"#0492c2\"\npasok_color = \"#95bb72\"\nsyriza_color = \"#e27bb1\""
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#kke",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#kke",
    "title": "EDA on Greek Parliament",
    "section": "KKE",
    "text": "KKE\n\nCodeparty_plot(\"KKE\", \"#FF6666\", times_elected_min = 5)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#nd",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#nd",
    "title": "EDA on Greek Parliament",
    "section": "ND",
    "text": "ND\n\nCodeparty_plot(\"ND\", \"#0492c2\", times_elected_min = 10)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#pasok",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#pasok",
    "title": "EDA on Greek Parliament",
    "section": "PASOK",
    "text": "PASOK\n\nCodeparty_plot(\"PASOK\", \"#95bb72\", times_elected_min = 10)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#syriza",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#syriza",
    "title": "EDA on Greek Parliament",
    "section": "SYRIZA",
    "text": "SYRIZA\n\nCodeparty_plot(\"SYRIZA\", \"#e27bb1\", times_elected_min = 5)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#state",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#state",
    "title": "EDA on Greek Parliament",
    "section": "State",
    "text": "State\n\nCodeconstituency_freqs(\"State\", 3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#attica",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#attica",
    "title": "EDA on Greek Parliament",
    "section": "Attica",
    "text": "Attica\n\n\nAthens A\nAthens B\nPiraeus A\nPiraeus B\nOf Attica (rest)\n\n\n\n\nCodeconstituency_freqs(\"Athens A\",5)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Athens B\",7)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Piraeus A\",5)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Piraeus B\",5)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Of Attica (rest)\",5)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-greece",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-greece",
    "title": "EDA on Greek Parliament",
    "section": "Central Greece",
    "text": "Central Greece\n\n\nViotia\nEvrytania\nFokida\nFthiotida\n\n\n\n\nCodeconstituency_freqs(\"Viotia\",5)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Evrytania\",2)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Fokida\",2)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Fthiotida\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-macedonia",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#central-macedonia",
    "title": "EDA on Greek Parliament",
    "section": "Central Macedonia",
    "text": "Central Macedonia\n\n\nThessaloniki A\nThessaloniki B\nKilkis\nPella\nPieria\nSerres\nHalkidiki\n\n\n\n\nCodeconstituency_freqs(\"Thessaloniki A\",6)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Thessaloniki B\",6)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Kilkis\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Pella\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Pieria\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Serres\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Halkidiki\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#crete",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#crete",
    "title": "EDA on Greek Parliament",
    "section": "Crete",
    "text": "Crete\n\n\nChania\nHeraklion\nLasithi\nRethymno\n\n\n\n\nCodeconstituency_freqs(\"Chania\",3)\n\n\n\n\n\n\n\nCode#constituency_freqs(\"Irakleio\",3)\n\n\n\n\n\nCodeconstituency_freqs(\"Lasithi\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Rethymno\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#eastern-macedonia-and-thrace",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#eastern-macedonia-and-thrace",
    "title": "EDA on Greek Parliament",
    "section": "Eastern Macedonia and Thrace",
    "text": "Eastern Macedonia and Thrace\n\n\nDrama\nEvros\nKavala\nXanthi\nRodopi\n\n\n\n\nCodeconstituency_freqs(\"Drama\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Evros\",4)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Kavala\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Xanthi\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Rodopi\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#epirus",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#epirus",
    "title": "EDA on Greek Parliament",
    "section": "Epirus",
    "text": "Epirus\n\n\nArta\nIoannina\nPreveza\nThesprotia\n\n\n\n\nCodeconstituency_freqs(\"Arta\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Ioannina\",4)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Preveza\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Thesprotia\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#ionian-islands",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#ionian-islands",
    "title": "EDA on Greek Parliament",
    "section": "Ionian Islands",
    "text": "Ionian Islands\n\n\nCorfu\nKefallonia\nLefkada\nZakynthos\n\n\n\n\nCodeconstituency_freqs(\"Corfu\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Kefallonia\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Lefkada\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Zakynthos\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#north-aegean",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#north-aegean",
    "title": "EDA on Greek Parliament",
    "section": "North Aegean",
    "text": "North Aegean\n\n\nChios\nLesvos\nSamos\n\n\n\n\nCodeconstituency_freqs(\"Chios\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Lesvos\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Samos\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#peloponnese",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#peloponnese",
    "title": "EDA on Greek Parliament",
    "section": "Peloponnese",
    "text": "Peloponnese\n\n\nArgolida\nArkadia\nKorinthia\nLakonia\nMessinia\n\n\n\n\nCodeconstituency_freqs(\"Argolida\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Arcadia\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Korinthia\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Lakonia\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Messinia\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#south-aegean",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#south-aegean",
    "title": "EDA on Greek Parliament",
    "section": "South Aegean",
    "text": "South Aegean\n\n\nDodecanese Islands\nCyclades\n\n\n\n\nCodeconstituency_freqs(\"Dodecanese Islands\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Cyclades\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#thessaly",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#thessaly",
    "title": "EDA on Greek Parliament",
    "section": "Thessaly",
    "text": "Thessaly\n\n\nKarditsa\nLarissa\nMagnesia\nTrikala\n\n\n\n\nCodeconstituency_freqs(\"Karditsa\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Larissa\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Magnesia\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Trikala\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-greece",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-greece",
    "title": "EDA on Greek Parliament",
    "section": "Western Greece",
    "text": "Western Greece\n\n\nAchaia\nAitoloakarnania\nIleia\n\n\n\n\nCodeconstituency_freqs(\"Achaia\",3)\n\n\n\n\n\n\n\nCode#constituency_freqs(\"Aitoloakarnania\",3)\n\n\n\n\n\nCodeconstituency_freqs(\"Ileia\",3)"
  },
  {
    "objectID": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-macedonia",
    "href": "english/2022-10-10-EDA-Greek-Parliament/2022-10-10-EDA-Greek-Parliament.html#western-macedonia",
    "title": "EDA on Greek Parliament",
    "section": "Western Macedonia",
    "text": "Western Macedonia\n\n\nFlorina\nGrevena\nKastoria\nKozani\n\n\n\n\nCodeconstituency_freqs(\"Florina\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Grevena\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Kastoria\",3)\n\n\n\n\n\n\n\nCodeconstituency_freqs(\"Kozani\",3)"
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html",
    "title": "Verify your commits !",
    "section": "",
    "text": "It’s not a long time ago that I have started to use Git. I am constantly discovering new things. All this time I was reading articles, posts on Stackoverflow etc. One day I saw a Verified badge on someones’ repository commit history.\nThen the first questions arised.\n\n“What is that ?”  “Why I don’t have it ?”  “Do I need that ?”\n\n\n\n\n\n\n\nSSH vs GitHub for commit\n\n\n\nIn reality, when you have make a commit via your GitHub account your commit is indeed marked as verified but the majority of the users is working locally, thus they have set SSH. Those are in need to set up GPG in order to sign their commits and push their changes."
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#introduction",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#introduction",
    "title": "Verify your commits !",
    "section": "",
    "text": "It’s not a long time ago that I have started to use Git. I am constantly discovering new things. All this time I was reading articles, posts on Stackoverflow etc. One day I saw a Verified badge on someones’ repository commit history.\nThen the first questions arised.\n\n“What is that ?”  “Why I don’t have it ?”  “Do I need that ?”\n\n\n\n\n\n\n\nSSH vs GitHub for commit\n\n\n\nIn reality, when you have make a commit via your GitHub account your commit is indeed marked as verified but the majority of the users is working locally, thus they have set SSH. Those are in need to set up GPG in order to sign their commits and push their changes."
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#what-if-i-do-not-verify",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#what-if-i-do-not-verify",
    "title": "Verify your commits !",
    "section": "What if I do not verify",
    "text": "What if I do not verify"
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#create-pgp-key",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#create-pgp-key",
    "title": "Verify your commits !",
    "section": "Create PGP key",
    "text": "Create PGP key\nGitHub has a wonderful explanation , so I won’t bother you to say the same things. You can see their guide here\nFor brevity, I will make a TL;DR version :\ngpg --full-generate-key\n# Accept defaults\n# Give no-reply email\n# Passphrase\n\n\n#print GPG Key ID\ngpg --list-secret-keys --keyid-format=long\n# the alphanumeric after / is ID\n\n# print GPG key\ngpg --armor --export GPG_key_ID"
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#signing-your-commits",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#signing-your-commits",
    "title": "Verify your commits !",
    "section": "Signing your commits",
    "text": "Signing your commits\nAfter that you can continue your usual workflow with Git with just a little change. Now you have to sign your commits. To do that you have to set the option -S as follows :\ngit commit -S -m \"Edit something\"\nThen, you will be prompted to a new window in order to complete the password of your GPG key. And here it is, my first verified commit :\n\n\n\nVerified Commit on GitHub\n\n\nLet’s take a closer look :\n\n\n\nVerified Commit on GitHub\n\n\nBut there is more. On GitHub settings (Settings &gt; SSH and GPG keys) there is also the option to warn others if a commit is not signed. If I enable it :\n\n\n\nSettings for unsigned commits\n\n\nthen it marks all my unsigned commits (before and after the change) as unverified, as a warning to others. I guess it’s good if someones’ intention is to use only signed commits.\n\n\n\nSettings for unsigned commits"
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#to-sum-up",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#to-sum-up",
    "title": "Verify your commits !",
    "section": "To sum up",
    "text": "To sum up\nIn GitHub, Commit = Sign + Commit\nLocally,  - bash git commit -m \"...\" = Commit  - bash git commit -S -m \"...\" = Sign + Commit"
  },
  {
    "objectID": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#sources",
    "href": "english/2022-10-03-Verified-Commits/2022-10-03-Verified-Commits.html#sources",
    "title": "Verify your commits !",
    "section": "Sources",
    "text": "Sources\n\nGithub Documentation Page for GPG keys\nAdding a GPG key to your GitHub account"
  },
  {
    "objectID": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html",
    "href": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html",
    "title": "Kaggle’s Greek Community",
    "section": "",
    "text": "Kaggle is one of the most well-known communities of data analysts/scientists with over 10 million active users (Heads or Tails, 2020). Besides that, Kaggle offers an abundance of functionalities (Notebooks), information (through Discussions between users) and Competitions. It is worth noting that there are other similar communities but they cannot compare to the full functionality of Kaggle. For example, DrivenData could be considered an alternative for participating in ML competitions, but it neither provides the possibility to create notebooks nor has a large number of users.\nKaggle Machine Learning & Data Science Survey is an annual survey conducted by Kaggle. The platform asks its users to analyze users’ data in the context of a competition. In this notebook, I conduct an analysis based on 2021’s survey in order to compare Greek data analysts with the rest of the world."
  },
  {
    "objectID": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#import-libraries",
    "href": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#import-libraries",
    "title": "Kaggle’s Greek Community",
    "section": "Import libraries",
    "text": "Import libraries\nThis notebook will definitely make some charts, so the ggplot2 package is necessary. Also, having variables with too many values (e.g. country of each Kaggle user) is an indication of using tables, and for this the reactablefmtr package will help to get a nice result.\n\n# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(forcats)\nlibrary(gridExtra)\n\n# Tables\nlibrary(kableExtra)\nlibrary(reactablefmtr)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\nlibrary(showtext)\nlibrary(sysfonts) # System / Google fonts\n\n# Other R packages\nlibrary(fontawesome)\n#library(htmltools) # for building div/links\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)\n\n## Load fonts\n\n# font_families_google() ## see list with available Google fonts\n\nfont_add_google(name = \"Lilita One\", family = \"title\", db_cache = F)\nfont_add_google(name = \"Ysabeau Office\", family = \"subtitle\", db_cache = F)"
  },
  {
    "objectID": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#import-data",
    "href": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#import-data",
    "title": "Kaggle’s Greek Community",
    "section": "Import data",
    "text": "Import data\nUsing read.csv() from readr package, I import my dataset and I name it as kaggle_2021. The dataset includes in the first line the question which is not required for my data analysis, so I exclude it from my dataset.\n\nkaggle_2021 = read_csv(\"data/kaggle_survey_2021.csv\")\n\n# Delete second line\nkaggle_2021 = kaggle_2021[-c(1),]"
  },
  {
    "objectID": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#prepare-data",
    "href": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#prepare-data",
    "title": "Kaggle’s Greek Community",
    "section": "Prepare Data",
    "text": "Prepare Data\nSince my analysis is based on Greek users, I split the dataset into two parts. One part includes exclusively Greek users and all the rest another. Thus, we can observe any peculiarities or similarities with broader Kaggle’s userbase.\n\n# Recoding Q2 variable\n\nkaggle_2021$Q2 = kaggle_2021$Q2 %&gt;%\n  fct_recode(\n    \"Other\" = \"Nonbinary\",\n    \"Other\" = \"Prefer not to say\",\n    \"Other\" = \"Prefer to self-describe\"\n  )\n\n## Recoding kaggle_2021$Q3\n\nkaggle_2021$Q3 &lt;- kaggle_2021$Q3 %&gt;%\n  fct_recode(\n    \"Hong Kong\" = \"Hong Kong (S.A.R.)\",\n    \"Other\" = \"I do not wish to disclose my location\",\n    \"Iran\" = \"Iran, Islamic Republic of...\",\n    \"UAE\" = \"United Arab Emirates\",\n    \"UK\" = \"United Kingdom of Great Britain and Northern Ireland\",\n    \"USA\" = \"United States of America\",\n    \"Vietnam\" = \"Viet Nam\"\n  )\n\n## Recoding kaggle_2021$Q6\nkaggle_2021$Q6 &lt;- kaggle_2021$Q6 %&gt;%\n  fct_recode(\n    \"0 years\" = \"I have never written code\"\n  )\n\n## Recoding kaggle_2021$Q4\nkaggle_2021$Q4 &lt;- kaggle_2021$Q4 %&gt;%\n  fct_recode(\n    \"Bachelor\" = \"Bachelor’s degree\",\n    \"PhD\" = \"Doctoral degree\",\n    \"Other\" = \"I prefer not to answer\",\n    \"Master\" = \"Master’s degree\",\n    \"No\" = \"No formal education past high school\",\n    \"ProfDoc\" = \"Professional doctorate\",\n    \"UniNoDegree\" = \"Some college/university study without earning a bachelor’s degree\"\n  )\n\nkaggle_2021$Q4 &lt;- kaggle_2021$Q4 %&gt;%\n  fct_relevel(\n    \"No\", \"UniNoDegree\", \"Bachelor\", \"Master\", \"PhD\", \"ProfDoc\",\n    \"Other\"\n  )\n\n\nkaggle_2021_compare = kaggle_2021 %&gt;%\n  mutate(Q3 = if_else(Q3 != \"Greece\", \"Other\", Q3))"
  },
  {
    "objectID": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html",
    "href": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "",
    "text": "When someone starts with Machine Learning he usually starts to build some simple models as logistic regression, naive Bayes, linear regression etc. And those alone are already enough for most use cases, as their simplicity is productivity-friendly and comes up with adequate accuracy. However, in enterprise level, accuracy can be important for a lot of reasons. Gradient Boosting Machines are some algorithms which outperform the aforementioned methods and are not complex enough to use them. Of course, before we build the model with (e.g. tidymodels) we have to install them.\n\n\n\nError - Missing LightGBM install\n\n\nThus, on this article I gather all that information.\n\n\n\nInstallation Guides\nSource\n\n\n\n\nLightGBM\nLink\n\n\nCatBoost\nLink\n\n\nXGBoost\nLink"
  },
  {
    "objectID": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#introduction",
    "href": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#introduction",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "",
    "text": "When someone starts with Machine Learning he usually starts to build some simple models as logistic regression, naive Bayes, linear regression etc. And those alone are already enough for most use cases, as their simplicity is productivity-friendly and comes up with adequate accuracy. However, in enterprise level, accuracy can be important for a lot of reasons. Gradient Boosting Machines are some algorithms which outperform the aforementioned methods and are not complex enough to use them. Of course, before we build the model with (e.g. tidymodels) we have to install them.\n\n\n\nError - Missing LightGBM install\n\n\nThus, on this article I gather all that information.\n\n\n\nInstallation Guides\nSource\n\n\n\n\nLightGBM\nLink\n\n\nCatBoost\nLink\n\n\nXGBoost\nLink"
  },
  {
    "objectID": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#lightgbm",
    "href": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#lightgbm",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "LightGBM",
    "text": "LightGBM\n\nOption 1. Install R Package\nIf you are reading this blog, the most possible scenario in that you are using R too. The most easy way to install the corresponding R package :\n\n\nR code\n\nstart_time_lightgbm &lt;- Sys.time()\ninstall.packages(\"lightgbm\", repos = \"https://cran.r-project.org\")\nend_time_lightgbm &lt;- Sys.time()\n\n\n\nOption 2. CMAKE\nThe LightGBM documentation are referring to this method of installation.\n\n\nTerminal\n\nsudo apt install cmake\n\n\n\nTerminal\n\ngit clone --recursive https://github.com/microsoft/LightGBM\ncd LightGBM\nmkdir build\ncd build\ncmake ..\nmake -j4"
  },
  {
    "objectID": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#catboost",
    "href": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#catboost",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "CatBoost",
    "text": "CatBoost\nTheir realeases.\n\n\nR code\n\ninstall.packages(\"devtools\")\n\nOn my occassion, when I tried to install devtools had an error status. According to my error status I had to add packages libharfbuzz-dev and libfribidi-dev. After that, my devtools installation completed without errors.\n\n\n\nR code\n\nstart_time_catboost &lt;- Sys.time()\ndevtools::install_url(\"https://github.com/catboost/catboost/releases/download/v1.1.1/catboost-R-Linux-1.1.1.tgz\"[, INSTALL_opts = c(\"--no-multiarch\", \"--no-test-load\")])\nend_time_catboost &lt;- Sys.time()"
  },
  {
    "objectID": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#xgboost",
    "href": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#xgboost",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "XGBoost",
    "text": "XGBoost\n\n\nR code\n\nstart_time_xgboost &lt;- Sys.time()\ninstall.packages(\"xgboost\")\nend_time_xgboost &lt;- Sys.time()"
  },
  {
    "objectID": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#summary",
    "href": "english/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/2022-11-13-Install-LightGBM-CatBoost-Ubuntu.html#summary",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "Summary",
    "text": "Summary\n\n\n\nML Model\nMethod\nInstallation time\n\n\n\n\nLightGBM\nR package\n7.79 min.\n\n\nCatBoost\nR package (w/o devtools)\n2.1 min.\n\n\nXGBoost\nR package\n6.16 min."
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html",
    "title": "Forecasting Unemployment in Greece",
    "section": "",
    "text": "Introduction \n\n\nPrerequisites    2.1 Import Libraries    2.2 Import Dataset    2.3 Preview Datasset    2.4 Dataset Structure    2.5 Time Series Preprocessing \n\n\nMissing Values \n\n\nDescriptive Statistics \n\n\nExamine Stationarity    5.1 Definition of stationarity    5.2 Examine Stationarity Graphically    5.3 Examine Stationarity with Statistical Tests      5.3.1 ADF test      5.3.2 PP test      5.3.3 KPSS test \n\n\nIdentify Model \n\n\nBuild Time Series Model \n\n\nCompare Models \n\n\nForecast Future Unemployment    9.1 ARIMA (0,2,1) forecasts    9.2 ARIMA (9,2,1) forecasts \n\nResults"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#background",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#background",
    "title": "Forecasting Unemployment in Greece",
    "section": "Background",
    "text": "Background"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series",
    "title": "Forecasting Unemployment in Greece",
    "section": "Time series",
    "text": "Time series"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#procedure",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#procedure",
    "title": "Forecasting Unemployment in Greece",
    "section": "Procedure",
    "text": "Procedure"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#short-answer",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#short-answer",
    "title": "Forecasting Unemployment in Greece",
    "section": "Short Answer",
    "text": "Short Answer\nIf you are in a hurry, I predicted that unemployment on Greece is expected to further reduce. It will range between 10% - 13% in February, 2023."
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-libraries",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-libraries",
    "title": "Forecasting Unemployment in Greece",
    "section": "Import Libraries",
    "text": "Import Libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, François, Henry, Müller, & Vaughan, 2023). The kableExtra (Zhu, 2021) package was used to print the results in table format, while the flextable (Gohel & Skintzos, 2022) package was used to print the results of the Dickey-Fuller and KPSS tests.\nThen, due to the nature of the data (time series) it was deemed necessary to use relevant libraries such as lubridate(Spinu, Grolemund, & Wickham, 2021), tseries(Trapletti & Hornik, 2022) & forecast(R. Hyndman et al., 2022) packages.\nFinally, the ggplot2 (Wickham, Chang, et al., 2022) package was used to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nCode# General purpose R libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(kableExtra)\nlibrary(flextable)\n\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Time Series \n\nlibrary(lubridate)\nlibrary(tseries)\nlibrary(forecast)\n\n# Other settings\noptions(digits=2) # print only 2 decimals"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-dataset",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#import-dataset",
    "title": "Forecasting Unemployment in Greece",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading the libraries I am able to use the commands of the readr package to import my data. My data is in .csv format, so I’ll use the read_csv() command (Wickham, Hester, et al., 2022) to import them.\nAdditionally, I choose not to include EA-19 values (as I investigate Greece’s unemployment).\n\nCodeunemployment &lt;- read_csv(\"data/unemployment.csv\") %&gt;%\n  select(LOCATION, TIME, Value) %&gt;% filter(LOCATION != \"EA19\")"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#preview-dataset",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#preview-dataset",
    "title": "Forecasting Unemployment in Greece",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nCode#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_dataset = head(unemployment, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\nLOCATION\nTIME\nValue\n\n\n\nGRC\n1998-04\n11\n\n\nGRC\n1998-05\n11\n\n\nGRC\n1998-06\n11\n\n\nGRC\n1998-07\n11\n\n\nGRC\n1998-08\n11\n\n\nGRC\n1998-09\n11\n\n\nGRC\n1998-10\n11\n\n\nGRC\n1998-11\n11\n\n\nGRC\n1998-12\n11\n\n\nGRC\n1999-01\n11"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#dataset-structure",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#dataset-structure",
    "title": "Forecasting Unemployment in Greece",
    "section": "Dataset Structure",
    "text": "Dataset Structure\nOur dataset is consisted by 3 variables (columns). More specifically, concerning my variables, are as follows :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nLOCATION\n\nqualitative  (nominal)\nSpecific country’s statistics\n\n\nTIME\n\nqualitative  (ordinal)\nMonth of the reported data\n\n\nValue\n\nquantitative  (continuous)\nUnemployment at the given Time and Country\n\n\n\nThus, my sample has 3 variables, of which 2 are qualitative and 1 is quantitative property."
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series-preprocessing",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#time-series-preprocessing",
    "title": "Forecasting Unemployment in Greece",
    "section": "Time Series Preprocessing",
    "text": "Time Series Preprocessing\nThe TIME variable needs to be a Date variable which is not fulfilled on our case.\n\nCodesapply(unemployment, class) %&gt;% kbl() %&gt;% kable_styling(full_width = F, position = \"center\")\n\n\n\n\nx\n\n\n\nLOCATION\ncharacter\n\n\nTIME\ncharacter\n\n\nValue\nnumeric\n\n\n\n\n\nSo, above I see that I have dates in a format “YYYY-MM” (Year - Month) and they are considered as characters. With the help of lubridate package I will convert my time series on a Date format.\n\nCodeunemployment$TIME &lt;- lubridate::ym(unemployment$TIME)\n\n\nAnd let’s check again :\n\nCodesapply(unemployment, class) %&gt;% kbl() %&gt;% kable_styling(full_width = F, position = \"center\")\n\n\n\n\nx\n\n\n\nLOCATION\ncharacter\n\n\nTIME\nDate\n\n\nValue\nnumeric\n\n\n\n\n\nAnd now I got the Date format. I am able to continue my analysis."
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#definition-of-stationarity",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#definition-of-stationarity",
    "title": "Forecasting Unemployment in Greece",
    "section": "Definition of stationarity",
    "text": "Definition of stationarity\nAn important concept in studying time series is stationarity. A time series is called stationary (“Applied Time Series Analysis,” n.d.) if: \n\n\nE(X_t) = \\text{constant} \n\nVar(X_t) = \\text{constant} \nCov(X_t, X_s) = \\text{constant}"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-graphically",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-graphically",
    "title": "Forecasting Unemployment in Greece",
    "section": "Examine Stationarity Graphically",
    "text": "Examine Stationarity Graphically\n\n\nLevel\nFirst Diff.\nSecond Diff.\n\n\n\nIt is apparent that there is a big variation on the values of unemployment. This time series is not stationary and the differencing is justified.\n\nCodeplot(grc_unemployment$Value,type = \"l\")\n\n\n\n\n\n\nHere we can see a big improvement in comparison with original data. I have some concerns about points close to 150 (mildly upwards trend) and 250 (outlier).\n\nCodegrc_unemployment_diff1 &lt;- diff(grc_unemployment$Value, differences = 1)\n\nplot(grc_unemployment_diff1,type = \"l\")\n\n\n\n\n\n\nGiven the concerns of above, I made also a second difference plot. It seems to solve the problem on points close to 150.\n\nCodegrc_unemployment_diff2&lt;- diff(grc_unemployment$Value, differences = 2)\n\nplot(grc_unemployment_diff2, type = \"l\")"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-with-statistical-tests",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#examine-stationarity-with-statistical-tests",
    "title": "Forecasting Unemployment in Greece",
    "section": "Examine Stationarity with Statistical tests",
    "text": "Examine Stationarity with Statistical tests\nThe graphical interpretation of stationarity can be beneficial for a quick assessment on topic of stationarity. However it can be considered a subjective metric, which leads on a non consistent decision (someone may consider the second figure as stationary and some others not.\nThankfully, there are some statistical tests which can help us on our decisions. Some commonly used are :\n\n\nAugmented Dickey-Fuller (ADF) test\n\nPhillips- Perron (PP) test\n\nKwiatkowski-Phillips-Schmidt-Shin (KPSS) test\n\nSummary\n\nCodesummary_stationarity_results &lt;- data.frame(\n                             \"Type\" = c(\"levels\", \"Diff(GRC)\", \"Diff2(GRC)\"),\n                             \"ADF test\" = c(\"Non Stationary\", \"Stationary\", \"Stationary\"),\n                              \"PP test\" = c(\"Non Stationary\", \"Stationary\", \"Stationary\"),\n                             \"KPSS test\" =c(\"Non Stationary\", \"Non Stationary\", \"Stationary\")\n)\n\n\nsummary_stationarity_results  %&gt;% kbl() %&gt;% kable_styling()\n\n\n\nType\nADF.test\nPP.test\nKPSS.test\n\n\n\nlevels\nNon Stationary\nNon Stationary\nNon Stationary\n\n\nDiff(GRC)\nStationary\nStationary\nNon Stationary\n\n\nDiff2(GRC)\nStationary\nStationary\nStationary\n\n\n\n\n\nADF test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is not stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is a unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nCodeadf.test(grc_unemployment$Value) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-0.9\n0.9485 \n6.0\nAugmented Dickey-Fuller Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nΣυνεπώς, είναι προφανές από τα αποτελέσματα του στατιστικού ελέγχου Dickey Fuller ότι η χρονοσειρά μου δεν είναι στάσιμη. Θα πρέπει να εφαρμόσω τον έλεγχο Dickey-Fuller στις δοαφορές.\n\nCodeadf.test(grc_unemployment_diff1) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-3.5\n0.0424 *\n6.0\nAugmented Dickey-Fuller Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nAnd finally the results for the second differences are :\n\nCodeadf.test(grc_unemployment_diff2) %&gt;% as_flextable()\n\nWarning in adf.test(grc_unemployment_diff2): p-value smaller than printed p-\nvalue\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-9.5\n0.0100 **\n6.0\nAugmented Dickey-Fuller Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nPP test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is not stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is a unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nCodepp.test(grc_unemployment$Value,) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n0.2\n0.9900 \n5.0\nPhillips-Perron Unit Root Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nCodepp.test(grc_unemployment_diff1) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-279.8\n0.0100 **\n5.0\nPhillips-Perron Unit Root Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nCodepp.test(grc_unemployment_diff2) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-337.1\n0.0100 **\n5.0\nPhillips-Perron Unit Root Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nKPSS test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is not  unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nCodekpss.test(grc_unemployment$Value,) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n2.5\n0.0100 **\n5.0\nKPSS Test for Level Stationarity\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nCodekpss.test(grc_unemployment_diff1) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n0.6\n0.0231 *\n5.0\nKPSS Test for Level Stationarity\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nCodekpss.test(grc_unemployment_diff2) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n0.0\n0.1000 .\n5.0\nKPSS Test for Level Stationarity\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-021-forecasts",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-021-forecasts",
    "title": "Forecasting Unemployment in Greece",
    "section": "ARIMA (0,2,1) forecasts",
    "text": "ARIMA (0,2,1) forecasts\n\nCodeforecast(auto_model,6) %&gt;% autoplot()\n\n\n\nCodeforecast(auto_model,6) %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nPoint Forecast\nLo 80\nHi 80\nLo 95\nHi 95\n\n\n\n294\n12\n11.5\n13\n11.2\n13\n\n\n295\n12\n11.1\n13\n10.7\n13\n\n\n296\n12\n10.7\n13\n10.2\n13\n\n\n297\n12\n10.3\n13\n9.7\n13\n\n\n298\n11\n10.0\n13\n9.2\n13\n\n\n299\n11\n9.6\n13\n8.8\n14"
  },
  {
    "objectID": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-921-forecasts",
    "href": "english/2022-10-22-Forecasting-Unemployment-Greece/2022-10-22-Unemployment-Greece.html#arima-921-forecasts",
    "title": "Forecasting Unemployment in Greece",
    "section": "ARIMA (9,2,1) forecasts",
    "text": "ARIMA (9,2,1) forecasts\n\nCodeforecast(arimaModel_3,6) %&gt;% autoplot()\n\n\n\nCodeforecast(arimaModel_3,6) %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nPoint Forecast\nLo 80\nHi 80\nLo 95\nHi 95\n\n\n\n294\n12\n11\n12\n11.1\n13\n\n\n295\n12\n11\n13\n10.9\n13\n\n\n296\n12\n11\n13\n10.7\n13\n\n\n297\n12\n11\n13\n10.1\n13\n\n\n298\n12\n10\n13\n9.8\n13\n\n\n299\n12\n10\n13\n9.4\n14"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello !",
    "section": "",
    "text": "I’m Stelios !\nCurrently, I am an undergraduate student of Statistics and Insurance Science at University of Piraeus.\nOn my website I will upload various posts closely related with R and Statistics.\nAlso you can have a look on my Shiny Apps."
  },
  {
    "objectID": "english.html",
    "href": "english.html",
    "title": "English Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nStatistics of Statistics Graduates\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nPDF\n\n\ntabulizer\n\n\n\n\nExtracting tabular data from PDF file, in order to explore facts about graduates of Statistics and Insurance Department in University of Piraeus\n\n\n\n\n\n\nJul 23, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nKaggle’s Greek Community\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nKaggle\n\n\n\n\nAn exploratory data analysis about Kaggle’s Greek community, based on its 2021 survey. A comparison with the rest DS community.\n\n\n\n\n\n\nMay 6, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Survivors of MS Estonia\n\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\nLogistic Regression\n\n\n\n\nBuild a logistic regression model to predict survivors of MS Estonia.\n\n\n\n\n\n\nMar 31, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Possible Interested Clients\n\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\n\n\nBuild a classification machine learning model (using LightGBM & XGBoost) in order to classify people based on their interest to have a term deposit or not.\n\n\n\n\n\n\nNov 24, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nInstall LightGBM and CatBoost on Ubuntu 22.04\n\n\n\n\n\n\n\nLinux\n\n\nLightGBM\n\n\nCatBoost\n\n\nXGBoost\n\n\n\n\nInstall high performance algorithms (LightGBM, CatBoost & XGBoost) on your Linux device\n\n\n\n\n\n\nNov 13, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nGit Series (Part I - Configuration)\n\n\n\n\n\n\n\nGit\n\n\n\n\nAn article that brings together some configuration setttings of Git. A beginner’s approach to Git.\n\n\n\n\n\n\nNov 4, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nForecasting Unemployment in Greece\n\n\n\n\n\n\n\nR\n\n\nTime Series\n\n\n\n\nMake a prediction about the future value of Greece’s unemployment using ARIMA model.\n\n\n\n\n\n\nOct 22, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nEDA on Greek Parliament\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\n\n\nLet’s explore the MPs that got elected the most over the years (1981-2019).\n\n\n\n\n\n\nOct 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nVerify your commits !\n\n\n\n\n\n\n\nGPG\n\n\nQuarto\n\n\n\n\nUsing GPG keys to add a signature to your GitHub commits\n\n\n\n\n\n\nOct 3, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nList of Quarto Websites\n\n\n\n\n\n\n\nQuarto\n\n\n\n\nA collection of websites built with Quarto. Includes links to websites and their respective repositories. Further additions are always welcome.\n\n\n\n\n\n\nAug 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nHello, World\n\n\n\n\n\n\n\nfirst article\n\n\n\n\nMy first article on my Quarto website.\n\n\n\n\n\n\nJul 27, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "",
    "text": "Σε αυτό το άρθρο θα ήθελα να συγκεντρώσω όλες αυτές τις διάσπαρτες πληροφορίες που υπάρχουν για τα τμήματα Στατιστικής στη χώρα μας. Θα αναλύσω ως επί το πλείστον πληροφορίες που μπορούν να βρεθούν στο διαδίκτυο σαν να είχα να συμπληρώσω μηχανογραφικό. Ωστόσο, σε κάθε περίπτωση σας αποτρέπω από το να επιλέξετε σχολή βασίζοντας την επιλογή σας σε μόνο αυτό το άρθρο.\nΣε αυτή τη κατηγορία εντάσσω απλά όσες σχολές σχετίζονται με τη Στατιστική. Τα τμήματα που θα συγκρίνω είναι τα εξής:\n\n\nΤμήμα Στατιστικής του Οικοκομικού Πανεπιστημίου Αθηνών\n\nΤμήμα Στατιστικής και Ασφαλιστικής Επιστήμης του Πανεπιστημίου Πειραιά\n\nΤμήμα Στατιστικής και Αναλογιστικών - Χρηματοοικονομικών Μαθηματικών του Πανεπιστημίου Αιγαίου\n\nTμήμα Στατιστικής και Ασφαλιστικής Επιστήμης του Πανεπιστημίου Δυτικής Μακεδονίας"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#εισαγωγή",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#εισαγωγή",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "",
    "text": "Σε αυτό το άρθρο θα ήθελα να συγκεντρώσω όλες αυτές τις διάσπαρτες πληροφορίες που υπάρχουν για τα τμήματα Στατιστικής στη χώρα μας. Θα αναλύσω ως επί το πλείστον πληροφορίες που μπορούν να βρεθούν στο διαδίκτυο σαν να είχα να συμπληρώσω μηχανογραφικό. Ωστόσο, σε κάθε περίπτωση σας αποτρέπω από το να επιλέξετε σχολή βασίζοντας την επιλογή σας σε μόνο αυτό το άρθρο.\nΣε αυτή τη κατηγορία εντάσσω απλά όσες σχολές σχετίζονται με τη Στατιστική. Τα τμήματα που θα συγκρίνω είναι τα εξής:\n\n\nΤμήμα Στατιστικής του Οικοκομικού Πανεπιστημίου Αθηνών\n\nΤμήμα Στατιστικής και Ασφαλιστικής Επιστήμης του Πανεπιστημίου Πειραιά\n\nΤμήμα Στατιστικής και Αναλογιστικών - Χρηματοοικονομικών Μαθηματικών του Πανεπιστημίου Αιγαίου\n\nTμήμα Στατιστικής και Ασφαλιστικής Επιστήμης του Πανεπιστημίου Δυτικής Μακεδονίας"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#βάση-εισαγωγής",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#βάση-εισαγωγής",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Βάση εισαγωγής",
    "text": "Βάση εισαγωγής\nΈνα πρώτο κριτήριο για αρκετούς είναι η βάση εισαγωγής. Αν και κατά τη γνώμη μου αυτός ο δείκτης δείχνει κατά πόσο είναι επιθυμητη αυτή η σχολή και όχι το κατά πόσο καλή ή κακή είναι αυτή. Παρακάτω, συγκέντρωσα ιστορικά στοιχεία βάσεων (από το 2013 μέχρι το 2022) από τις τέσσερις σχολές Στατιστικής και έκανα ένα απλό διάγραμμα. Σε αυτό φαίνεται ότι ιστορικά το τμήμα με τη μεγαλύτερη βάση είναι του ΟΠΑ (με μόνη εξαίρεση το 2015). Επιπλέον, τα υπόλοιπα δύο τμήματα Στατιστικής (Αιγαίου και Δυτικής Μακεδονίας) ταυτίζονται αρκετά ως προς τη βάση εισαγωγής τους.\n\ntmimata_statistikis = data.frame(\n  \"Year\" = rep(c(2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022),4),\n  \"University\" = c(rep(\"AUEB\",10), rep(\"UniPi\",10), rep(\"Aegean\",10), rep(\"UoWM\",10)),\n  \"Theseis\" = c(99, 112, 103, 99, 103, 104, 113, 102, 103, 101,\n                  189, 202, 198, 190, 198, 198, 216, 194, 154, 152, \n                  144, 137, 163, 156, 162, 178, 198, 171, 179, 165,\n                NA, NA, NA, NA, NA, NA, 268, 225, 316, 256),\n  \"Vasi\" = c(12788, 13277, 13488, 13158, 13511, 13354, 13337, 13425, 13316, 13828,\n               12666, 13270, 13795, 12703, 12543, 11967, 11710, 12100, 11673, 12460,\n               9618, 10636, 10574, 10471, 10692, 8525, 5148, 3925, 7797, 8425,\n               NA, NA, NA, NA, NA, NA, 4846, 3950, 7867, 7740)\n)\n\n\nggplot2::ggplot(data = tmimata_statistikis, aes(x = Year, y = Vasi, color= University)) +\n  geom_line() +\n  geom_point() +\n  geom_text_repel(data = tmimata_statistikis %&gt;% group_by(University) %&gt;% filter(Year == max(Year)), aes(x = Year, y = Vasi, label = Vasi)) +\n  scale_x_continuous(\"Έτος\", breaks = 2013:2022) +\n  labs(\n    title = \"&lt;b&gt;Βάσεις εισαγωγής σε τμήματα Στατιστικής&lt;/b&gt;\",\n    subtitle = \"Η βάση εισαγωγής είναι ο μικρότερος αριθμός μορίων - βαθμολογίας που πρέπει να συγκεντρώσει κάποιος &lt;br&gt; προκειμένου να εισαχθεί στη συγκεκριμένη σχολή. Διαχρονικά, οι σχολές με τη μεγαλύτερη βάση είναι του &lt;br&gt; &lt;b&gt;Οικονομικού Πανεπιστημίου Αθηνών&lt;/b&gt; και του &lt;b&gt;Πανεπιστημίου Πειραιά&lt;/b&gt;. Τέλος, παρατηρούμε ότι όλες &lt;br&gt; οι  σχολές Στατιστικής έχουν σχετικά χαμηλή βάση εισαγωγής.\",\n    caption = \"stesiam.com, 2023\",\n    x = \"Έτος\",\n    y = \"Βάση εισαγωγής\",\n    color = \"Πανεπιστήμιο\"\n  ) +\n  theme_classic() +\n  theme(\n     plot.title = element_markdown(family = \"clim\", size = 15),\n     plot.subtitle = element_markdown(family = \"mont\", size = 10, lineheight = 0.7),\n     plot.caption = element_markdown(family = \"mont\", size = 10),\n     axis.title = element_markdown(family = \"mont\", size = 12)\n)"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#θέσεις",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#θέσεις",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Θέσεις",
    "text": "Θέσεις\nΚάθε χρόνο το Υπουργείο Παιδείας ανακοινώνει τις διαθέσιμες θέσεις για κάθε σχολή και για κάθε κατηγορία εξεταζόμενων. Σε αυτή την ανάλυση ασχολούμαι με τους υποψήφιους των Γενικών Λυκείων που αποτελούν και τη συντριπτική πλειοψηφία των συμμετεχόντων. Με μία πρώτη ματιά παρατηρώ μία αντιστροφή των αποτελεσμάτων σε σύγκριση με τη βάση εισαγωγής. Δηλαδή, στις σχολές με την υψηλότερη βάση παρέχονται λιγότερες θέσεις.\n\nggplot2::ggplot(data = tmimata_statistikis, aes(x = Year, y = Theseis, color= University)) +\n  geom_line() +\n  geom_point() +\n  geom_text(data = tmimata_statistikis %&gt;% group_by(University) %&gt;% filter(Year == max(Year)), aes(x = Year, y = Theseis+7, label = Theseis)) +\n  scale_x_continuous(\"Έτος\", breaks = 2013:2022) +\n  labs(\n    title = \"&lt;b&gt;Θέσεις εισαγωγής σε τμήματα Στατιστικής (ΓΛ90)&lt;/b&gt;\",\n    subtitle = \"Η βάση εισαγωγής είναι ο μικρότερος αριθμός μορίων - βαθμολογίας που πρέπει να συγκεντρώσει κάποιος &lt;br&gt; προκειμένου να εισαχθεί στη συγκεκριμένη σχολή. Διαχρονικά, οι σχολές με τη μεγαλύτερη βάση είναι του &lt;br&gt; &lt;b&gt;Οικονομικού Πανεπιστημίου Αθηνών&lt;/b&gt; και του &lt;b&gt;Πανεπιστημίου Πειραιά&lt;/b&gt;. Τέλος, παρατηρούμε ότι όλες &lt;br&gt; οι  σχολές Στατιστικής έχουν σχετικά χαμηλή βάση εισαγωγής.\",\n    caption = \"stesiam.com, 2023\",\n    x = \"Έτος\",\n    y = \"Διαθέσιμες θέσεις\",\n    color = \"Πανεπιστήμιο\"\n  ) +\n  theme_classic() + \n   theme(\n     plot.title = element_markdown(family = \"clim\", size = 15),\n     plot.subtitle = element_markdown(family = \"mont\", size = 10, lineheight = 0.7),\n     plot.caption = element_markdown(family = \"mont\", size = 10),\n     axis.title = element_markdown(family = \"mont\", size = 12)\n)"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#εισακτέοι",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#εισακτέοι",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Εισακτέοι",
    "text": "Εισακτέοι\nΗ παροχή των θέσεων δεν συνεπάγεται πάντοτε και πλήρωση αυτών. Πολλές από αυτές μπορεί να μείνουν αδιάθετες λόγω χαμηλής ζήτησης. Κάτι που μπορεί να ενισχύσει το παραπάνω επιχείρημα είναι και η θεσμοθέτηση της βάσης εισαγωγής. Με αυτόν τον τρόπο δεν αρκεί απλά να πιάσεις τη βάση, αλλά και κάποια ελάχιστη βαθμολογία. Έτσι, ο αριθμός των εισακτέων μπορεί πλέον να διαφέρει σημαντικά σε τμήματα εκτός μεγάλων αστικών κέντρων (π.χ. Πανεπιστήμιο Αιγαίου, Πανεπιστήμιο Δυτικής Μακεδονίας - Γρεβενά)."
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#προϋποθέσεις-για-πτυχίο",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#προϋποθέσεις-για-πτυχίο",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Προϋποθέσεις για πτυχίο",
    "text": "Προϋποθέσεις για πτυχίο\nΚαι τα τέσσερα τμήματα προσφέρουν 4ετή φοίτηση και κάποιος ορίζεται ως πτυχιούχος με την απόκτηση 240 ECTS. Οι διαφορές τους ανάγονται κυρίως στο πλήθος των μαθημάτων και στο αν υπάρχει προϋπόθεση για πτυχιακή. Σημειώνεται ότι οι παραπάνω πληροφορίες βασίζονται στους πρόσφατους οδηγούς σπουδών των παραπάνω τμημάτων (2022-2023).\n\ndegree_requirements = data.frame(\n  \"University\" = c(\"AUEB\", \"UniPi2011\", \"UniPi2017\", \"Aegean\", \"UoWM\"),\n  \"Courses\" = c(32, 47, 40, 34, 48),\n  \"Comp\" = c(14, 31, 19, 18, 41),\n  \"Elective\" = c(18, 16, 21, 16, 7),\n  \"Ptixiaki\" = c(\"Yes\", \"No\", \"No\", \"Yes\", \"No\")\n)\n\n\nggplot(data = degree_requirements) +\n  geom_col(aes(x = reorder(University, - Courses), y = Courses)) +\n    geom_text(aes(x = reorder(University, - Courses), y = Courses + 2 , label = Courses)) +\n  labs(\n    title = \"&lt;b&gt;Προϋποθέσεις λήψης πτυχίου&lt;/b&gt;\",\n    subtitle = \"Κάθε τμήμα έχει αρκετά διαφορετικούς κανόνες για να θεωρήσει κάποιος ως πτυχιούχο. Παρατηρούμε μεγάλες διαφορές &lt;br&gt; ανάμεσα στα τμήματα με το τμήμα Στατιστικής της Δυτικής Μακεδονίας να έχει την μεγαλύτερη απαίτηση όσον &lt;br&gt; αφορά τον αριθμό μαθημάτων. Από την άλλη μερια'\",\n    caption = \"stesiam.com, 2023\",\n    x = \"Τμήμα\",\n    y = \"Μαθήματα για λήψη πτυχίου\"\n  ) +\n  theme_classic() +\n    theme(\n     plot.title = element_markdown(family = \"clim\", size = 15),\n     plot.subtitle = element_markdown(family = \"mont\", size = 10, lineheight = 0.7),\n     plot.caption = element_markdown(family = \"mont\", size = 10),\n     axis.title = element_markdown(family = \"mont\", size = 12),\n)"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#επιλεγόμενα-μαθήματα",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#επιλεγόμενα-μαθήματα",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Επιλεγόμενα μαθήματα",
    "text": "Επιλεγόμενα μαθήματα\nΠαραπάνω είδαμε σε πόσα μαθήματα θα πρέπει να εξεταστεί ένας σπουδαστής του αντίστοιχου τμήματος για να πάρει πτυχίο. Πόση ελευθερία υπάρχει σε κάθε τμήμα προκειμένου ο ίδιος ο φοιτητής να προσαρμόσει τις σπουδές του στις προτιμήσεις του και τα προσωπικά του ερευνητικά ενδιαφέρεοντα; Αυτό προσπάθησα να μελετήσω με την προσθήκη της μεταβλητής των ελευέθρων μαθημάτων και του ποσοστού που αποτελούν αυτά ως προς τα συνολικά μαθήματα.\n\ndegree_requirements %&gt;%\n  mutate(pct = Elective/Courses) %&gt;%\n  ggplot() +\n  geom_col(aes(x = reorder(University, - pct), y = pct)) +\n  geom_text(aes(x = reorder(University, - pct), y = pct + 0.03 , label = paste0(round(pct, 2), \" %\"))) +\n  labs(\n    title = \"&lt;b&gt;Ποσοστό ελεύθερων επιλογών&lt;/b&gt;\",\n    subtitle = \"Κάθε τμήμα δίνει διαφορετικό ποσοστό ελευθερίας στους σπουδαστές του όσον αφορά τη δομή του προγράμματος και τη &lt;br&gt; παρακολούθηση των μαθημάτων. Άλλα δίνουν περισσότερη ελευθερία στους φοιτητές ώστε να επιλέξουν &lt;br&gt; μαθήματα που τους ενδιαφέρουν και άλλα σε μικρότερο βαθμό.\",\n    caption = \"stesiam.com, 2023\",\n    x = \"Τμήμα\",\n    y = \"Ποσοστό ελεύθερων επιλογών\"\n  ) +\n  theme_classic() +\n    theme(\n     plot.title = element_markdown(family = \"clim\", size = 15),\n     plot.subtitle = element_markdown(family = \"mont\", size = 10, lineheight = 0.7),\n     plot.caption = element_markdown(family = \"mont\", size = 10),\n     axis.title = element_markdown(family = \"mont\", size = 12),\n)"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#άλλες-πληροφορίες",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#άλλες-πληροφορίες",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Άλλες πληροφορίες",
    "text": "Άλλες πληροφορίες\n\nothers = data.frame(\n  Uni = c(\"AUEB\", \"UniPi2011\",\"UniPi2017\", \"Aegean\", \"UoWM\"),\n  Diloseis = c(\"Ναι\", \"Όχι\", \"Όχι\", \"Όχι\", \"Όχι\"),\n  Alysides = c(\"Ναι\", \"Όχι\", \"Όχι\", \"Όχι\", \"Όχι\"),\n  Ptyxiaki = c(\"Προαιρετική\", \"Όχι\", \"Όχι\",\"Προαιρετική\", \"Όχι\"),\n  Vathmos = c(\"Αριθμητικός μέσος\", \"Σταθμικός μέσος\", \"Αριθμητικός μέσος\", \"Σταθμικός μέσος\", \"Αριθμητικός μέσος\")\n)\n\n\nreactable::reactable(others,\n                     columns = list(\n    Uni  = colDef(name = \"Τμήμα\"),\n    Diloseis = colDef(name = \"Όριο δηλώσεων\", \n                      style = function(value) {\n      if (value == \"Όχι\") {\n        color &lt;- \"#008000\"\n      }  else {\n        color &lt;- \"#e00000\"\n      }\n      list(color = color, fontWeight = \"bold\")\n    }\n),\n    Alysides = colDef(name = \"Αλυσίδες μαθημάτων\",\n                      style = function(value) {\n      if (value == \"Όχι\") {\n        color &lt;- \"#008000\"\n      }  else {\n        color &lt;- \"#e00000\"\n      }\n      list(color = color, fontWeight = \"bold\")\n    }\n  ),\n    Ptyxiaki = colDef(name = \"Πτυχιακή\",\n                      style = function(value) {\n      if (value == \"Όχι\") {\n        color &lt;- \"#008000\"\n      }  else {\n        color &lt;- \"#e8c010\"\n      }\n      list(color = color, fontWeight = \"bold\")\n    }),\n    Vathmos =  colDef(name = \"Υπολογισμός βαθμού\")\n  ))"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#χάρτης",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#χάρτης",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Χάρτης",
    "text": "Χάρτης\nΤέλος, θα είχε ενδιαφέρον να εξασκήσω τις ικανότητές μου στη δημιουργία χαρτών με την R. Συνήθως χρησιμοποιώ Shapefiles για να έχω μία βάση (στη προκειμένη περίπτωση τα όρια της Ελλάδας), ωστόσο αυτή τη φορά αποφάσισα να χρησιμοποιήσω το πακέτο rnaturalearth. Αξίζει να σημειωθεί ότι απαιτούνται και τα πακέτα rnaturalearthdata και rnaturalhires.\n\nuni_coord = data.frame(\n  uni = c(\"ΠαΠει\", \"Αιγαίου\", \"ΟΠΑ\", \"Δυτικής Μακεδονίας\"),\n  long = c(23.6529793, 26.5664138,23.7300928, 21.4565181),\n  lat = c(37.9416013, 39.0851185, 37.9940201, 40.1197471),\n  img = rep(c(\"images/UniPi.png\"), 4)\n)\n\ngrc = ne_countries(country = \"greece\", \n                   type = \"countries\", \n                   scale = 'large',\n                   returnclass = \"sf\")\n\nggplot(data = grc) +\n  geom_sf() +\n  geom_point(data = uni_coord, aes(x = long, y = lat)) +\n  geom_label_repel(data = uni_coord, aes(x = long, y = lat, label = uni)) +\n  labs(\n    title = \"&lt;b&gt;Τμήματα Στατιστικής στην Ελλάδα&lt;/b&gt;\",\n    subtitle = \"Στην Ελλάδα υπάρχουν συνολικά 4 τμήματα Στατιστικής.\",\n    caption = \"stesiam.com, 2023\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_void() +\n    theme(\n     plot.title = element_markdown(family = \"clim\", size = 15),\n     plot.subtitle = element_markdown(family = \"mont\", size = 10, lineheight = 0.7),\n     plot.caption = element_markdown(family = \"mont\", size = 10),\n     axis.title = element_markdown(family = \"mont\", size = 12),\n     text = element_text(family = \"mont\", size = 10)\n)"
  },
  {
    "objectID": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#επίλογος",
    "href": "greek/2023-06-20-Studies-in-Statistics-Greek/2023-06-20-Studies-in-Statistics-Greek.html#επίλογος",
    "title": "Σπουδές Στατιστικής στην Ελλάδα",
    "section": "Επίλογος",
    "text": "Επίλογος\nΗ προσωπική μου άποψη είναι ότι το τμήμα Στατιστικής του Αιγαίου είναι μία πολύ δελεαστική επιλογή. Παρουσιάζεται (το τονίζω αυτό, παρουσιάζεται) ως ένα σοβαρό τμήμα με έναν σύγχρονο οδηγό σπουδών (λίγα μαθήματα που αντισταθμίζεται με τον ανάλογο φόρτο εργασίας). Το συγκεκριμένο τμήμα κατά τη γνώμη μου αδικείται από τη βάση που έχει. Αν είχα την επιλογή να διαλέξω δίχως να λάβω υπόψιν το οικονομικό κριτήριο (κόστος ενοικίου κτλ.) θα ήταν η πρώτη μου επιλογή. Βέβαια, αυτή η επιλογή όπως έγραψα και στην αρχή βασίζεται αποκλειστικά σε πράγματα που θα έβρισκα στο διαδίκτυο και απλά τα μάζεψα σε ένα άρθρο. Υπάρχουν και άλλα πράγματα που έχουν σημαντικότατο ρόλο, όπως οι διδάσκοντες, το επίπεδο μαθήματος, τήρηση κανονισμών, εγκαταστάσεις, προσβασιμότητα και άλλα που δυστυχώς θα τα μάθετε κατόπιν εορτής."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "All posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nStatistics of Statistics Graduates\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nPDF\n\n\ntabulizer\n\n\n\n\nExtracting tabular data from PDF file, in order to explore facts about graduates of Statistics and Insurance Department in University of Piraeus\n\n\n\n\n\n\nJul 23, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nΠρόσβαση στο API του data.gov.gr\n\n\n\n\n\n\n\nR\n\n\nAPI\n\n\n\n\nΈνας απλός οδηγός χρήσης του API του data.gov.gr, ώστε να λαμβάνετε τη ροή δεδομένων με τη χρήση της R.\n\n\n\n\n\n\nJul 4, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nΣπουδές Στατιστικής στην Ελλάδα\n\n\n\n\n\n\n\nΣπουδές\n\n\n\n\nΣυγκρίνω τις δημόσιες σχολές στατιστικής στην Ελλάδα και συγκρίνω τα βασικά τους στοιχεία με βάση τους οδηγούς σπουδών τους.\n\n\n\n\n\n\nJun 20, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nKaggle’s Greek Community\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nKaggle\n\n\n\n\nAn exploratory data analysis about Kaggle’s Greek community, based on its 2021 survey. A comparison with the rest DS community.\n\n\n\n\n\n\nMay 6, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Survivors of MS Estonia\n\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\nLogistic Regression\n\n\n\n\nBuild a logistic regression model to predict survivors of MS Estonia.\n\n\n\n\n\n\nMar 31, 2023\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nPredict Possible Interested Clients\n\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\n\n\nBuild a classification machine learning model (using LightGBM & XGBoost) in order to classify people based on their interest to have a term deposit or not.\n\n\n\n\n\n\nNov 24, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nInstall LightGBM and CatBoost on Ubuntu 22.04\n\n\n\n\n\n\n\nLinux\n\n\nLightGBM\n\n\nCatBoost\n\n\nXGBoost\n\n\n\n\nInstall high performance algorithms (LightGBM, CatBoost & XGBoost) on your Linux device\n\n\n\n\n\n\nNov 13, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nGit Series (Part I - Configuration)\n\n\n\n\n\n\n\nGit\n\n\n\n\nAn article that brings together some configuration setttings of Git. A beginner’s approach to Git.\n\n\n\n\n\n\nNov 4, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nΣυγκεντρωμένο υλικό για την R στα ελληνικά\n\n\n\n\n\n\n\nR\n\n\n\n\nΜία λίστα (που θα ανανεώνεται συνεχώς) με υλικό που υπάρχει διαθέσιμο στο διαδίκτυο (δωρεάν) σχετικά με την R\n\n\n\n\n\n\nOct 23, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nForecasting Unemployment in Greece\n\n\n\n\n\n\n\nR\n\n\nTime Series\n\n\n\n\nMake a prediction about the future value of Greece’s unemployment using ARIMA model.\n\n\n\n\n\n\nOct 22, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nEDA on Greek Parliament\n\n\n\n\n\n\n\nR\n\n\nEDA\n\n\n\n\nLet’s explore the MPs that got elected the most over the years (1981-2019).\n\n\n\n\n\n\nOct 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nVerify your commits !\n\n\n\n\n\n\n\nGPG\n\n\nQuarto\n\n\n\n\nUsing GPG keys to add a signature to your GitHub commits\n\n\n\n\n\n\nOct 3, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nList of Quarto Websites\n\n\n\n\n\n\n\nQuarto\n\n\n\n\nA collection of websites built with Quarto. Includes links to websites and their respective repositories. Further additions are always welcome.\n\n\n\n\n\n\nAug 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n  \n\n\n\n\nHello, World\n\n\n\n\n\n\n\nfirst article\n\n\n\n\nMy first article on my Quarto website.\n\n\n\n\n\n\nJul 27, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#python-users",
    "href": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#python-users",
    "title": "Kaggle’s Greek Community",
    "section": "Python users",
    "text": "Python users"
  },
  {
    "objectID": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#r-users",
    "href": "english/2023-05-06-Kaggle-Greek-Community/2023-05-06-Kaggle-Greek-Community.html#r-users",
    "title": "Kaggle’s Greek Community",
    "section": "R users",
    "text": "R users"
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#references",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#references",
    "title": "Statistics of Statistics Graduates",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#admitted-students",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#admitted-students",
    "title": "Statistics of Statistics Graduates",
    "section": "Admitted students",
    "text": "Admitted students\nSo, in Greece there is 1 standard way to be admitted to a university. Although there are 3 more ways which require some certain conditions. I will try to explain them as simple as possible.\nMain Exams\nOnce a year, third-year high school students from all over Greece take exams on the same subjects at the same time. The exams are known as Panhellenic Exams. Until today, it’s one of the few things in Greece that as its integrity is not disputed, as the papers of students are getting graded by teachers from other areas. However, it has also faced considerable criticism for the pressure it places on students. In my opinion a fair one as everything in your life is depending on these exams… If you fail you should wait to retake them next year.\nTypically the exams are being held between the second half of May and the first week of June. The students’ grades are getting published approximately either the end of June or the first days of July. Then you are completing a list on which you are declare which departments you are interested to. On the end of July the minimum grades to be admitted for each department are announced. Those can fluctuate significantly every year as they are depending on both students’ performance on the Exams and the difficulty of the exams.\nIn a nutchell, the departments from big cities like Attica (Athens, Piraeus) and Thessaloniki have the biggest demand and so the minimum grades for those are higher from the rest ones. For example, the Statistics Department in Piraeus had a minimum grade of 11700 in 2019 (for simplicity consider it like 11.7/20). The corresponding department of Statistics in University of Aegean the same year had a minimum grade of 5100 (5.1/20) (yes, that’s not a typo). Well there are many reasons behind that, as the continuance of austerity in Greece, but in general that’s the pattern.\nNot so fun fact but when I made my list of preference for studies, Statistics in Piraeus was something like 15th place, so I guess my fate was that. Okay and a little bit of anxiety. :)\nTransfer\nAs I wrote earlier there are some exceptions. First of all the Admission by Transfer is referring to transfer your place in one department with one similar-study in other city. There are many criteria mainly based on your income. For example, a student admitted on Statistics on University of Aegean could be admitted on Statistics Department on Piraeus (i.e. in case his/her family hasn’t enough income).\nThese seats are limited.\nEntry Exams\nIn case you have already graduated a Bachelor programme then you are able to give Entry Exams on your department of choice, instead of the nightmare of Panhellenic Exams.\n\nadmitted_students = statistics_tables[[1]] %&gt;%\n  .[-1,] %&gt;%\n  setNames(c(\"Year\", \"Main_exams\", \"Transfer\", \"Entry_exams\", \"Other\", \"Total\"))\n\n\nadmitted_students$Main_exams = admitted_students$Main_exams %&gt;% as.integer()\nadmitted_students$Transfer= admitted_students$Transfer %&gt;% as.integer()\nadmitted_students$Entry_exams = admitted_students$Entry_exams %&gt;% as.integer()\nadmitted_students$Other = admitted_students$Other %&gt;% as.integer()\nadmitted_students$Pct_Non_Main = (admitted_students$Main_exams/admitted_students$Total) %&gt;% as.double()\nrownames(admitted_students) = 1:nrow(admitted_students)\n\n\n\nadmitted_students = admitted_students %&gt;% \n  pivot_longer(\n    cols = !Year, \n    names_to = \"Admission_Type\", \n    values_to = \"count\"\n  )\n\nadmitted_students = admitted_students %&gt;%\n  dplyr::filter(Admission_Type == \"Pct_Non_Main\" &\n                !(Year %in% c(\"2020-2121\",\"2021-2022\", \"2022-2023\"))) %&gt;%\n  mutate(perc = round((1 - count)*100, digits = 2),\n         perc100 = 100-perc) %&gt;%\n  dplyr::select(c(-Admission_Type, -count)) %&gt;%\n  tidyr::pivot_longer(., cols = !Year,values_to = \"Obs\") %&gt;%\n  dplyr::rename(\n    \n  )\n\nadmitted_students %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\n\nI would like to examine the percentage of students who have been admitted by the other 3 ways over the years.\n\nggplot(data = admitted_students, aes(x = \"\", y = Obs, fill = name)) +\n  geom_bar(stat=\"identity\", width=1) +\n  facet_wrap(~Year) +\n  coord_polar(\"y\", start=0) +\n  labs(\n    title = \"Proportion of Admissions through Panhellenic Exams\",\n    subtitle = glue(\"It seems that &lt;span style = 'color:#619CFF; font-weight: bold'&gt;Panhellenic Exams&lt;/span&gt; is the prevalent way to be admitted to Statistics &lt;br&gt; Department. Although that was an expected result. It is interesting to study &lt;br&gt; the proportion over the years. The most extraordinary result is in 2011 when almost &lt;br&gt;  everyone came through Panhellenic Exams.\"),\n    caption = \"**Data:** Study Guide of Statistics and Insurance Science &lt;br&gt; \n    stesiam, 2023\"\n  ) +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_markdown(family = \"lobster\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"economica\"),\n    plot.caption = element_markdown(family = \"economica\")\n  )\n\n\n\n\n\n# admitted_students %&gt;%\n#   filter(Admission_Type %in% c(\"Main_exams\", \"Total\")) %&gt;%\n#   ggplot2::ggplot(., aes(x = Year, y = count, color = Admission_Type , group = Admission_Type)) +\n#   geom_line() +\n#   labs(\n#     title = \"Admitted students\",\n#     subtitle = \"Admitted students over the years (2003-2023) at Department of Statistics and Insurance Science of &lt;br&gt; University of Piraeus. A significant drop in admissions occured in 2021 which is maily caused by the &lt;br&gt; introduction of grade requirements to be admitted to specific departments.\",\n#     caption = \"stesiam, 2023\",\n#     x = \"Academic Year\",\n#     y = \"Students\",\n#     color = \"Type of Admission\"\n#   ) +\n#   theme_classic() +\n#   theme(\n#     plot.title = element_markdown(family = \"lobster\", face=\"bold\"),\n#     plot.subtitle = element_markdown(family = \"economica\"),\n#     plot.caption = element_markdown(family = \"economica\"),\n#     axis.text.x = element_text(face=\"bold\", angle=90)\n#   )"
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#master-programmes",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#master-programmes",
    "title": "Statistics of Statistics Graduates",
    "section": "Master Programmes",
    "text": "Master Programmes\nOur department has two Master options.\n\nApplied Statistics\nActuarial Science and Risk Management\n\n\nstatistics_tables[[1]]\n\n           X Εισαγωγικές Μετεγγραφές Κατατακτήριες      Άλλες Σύνολο\n1              εξετάσεις                           κατηγορίες     NA\n2  2003-2004         183          15             1         17    216\n3  2004-2005         181          21             1         16    219\n4  2005-2006         186          11             1         16    214\n5  2006-2007         186          27             1          9    223\n6  2007-2008         185          38             2         18    243\n7  2008-2009         170          44             1         12    253\n8  2009-2010         170          60             0         14    244\n9  2010-2011         175          47             4         24    250\n10 2011-2012         198           0             0          3    201\n11 2012-2013         206          14             2         15    237\n12 2013-2014         205          20             2         48    275\n13 2014-2015         219          48             1          4    272\n14 2015-2016         212          29             1          4    246\n15 2016-2017         212          30             4          0    246\n16 2017-2018         209          41             1          1    252\n17 2018-2019         189          11             1          5    206\n18 2019-2020         228          55             2          7    292\n19 2020-2121         234         -16             1          5    224\n20 2021-2022         134         -2*             -          1    133\n21 2022-2023         168         -1*            **          3    170\n\n\n\nmsc_students = statistics_tables[[2]] %&gt;%\n  setNames(c(\"AcademicYear\", \"BSc\", \"MSc (AppliedStat)\", \"MSc (Actuar)\", \"PhD\")) %&gt;%\n  .[-1,]\n\nrownames(msc_students) = 1:nrow(msc_students)\n\nmsc_students = msc_students %&gt;%\n  mutate_at(c(\"BSc\", \"MSc (AppliedStat)\", \"MSc (Actuar)\", \"PhD\"), as.numeric) %&gt;%\n  mutate(pct = round((PhD/BSc)*100, 2))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `MSc (Actuar) = .Primitive(\"as.double\")(`MSc (Actuar)`)`.\nCaused by warning:\n! NAs introduced by coercion\n\nmsc_students %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\n\n\nggplot(msc_students, aes(x = AcademicYear, y = pct, group = 1)) +\n  geom_line() +\n  labs(\n    title = \"Ratio of PhD students/ Undergraduates\",\n    subtitle = \"The decrease \",\n    caption = \"stesiam, 2023\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_markdown(family = \"serif\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"serif\"),\n    plot.caption = element_markdown(family = \"serif\"),\n    axis.text.x = element_text(face=\"bold\", angle=90)\n  )\n\n\n\n\n\ntidy_students = msc_students %&gt;%\n  select(!pct) %&gt;%\n  tidyr::pivot_longer(., cols = !c(AcademicYear), values_to = \"count\")\n\nggplot(tidy_students, aes(x = AcademicYear, y = count, fill = name)) +\n  geom_col() +\n  guides(fill = guide_legend(reverse = TRUE)) +\n  labs(\n    title = \"Ratio of PhD students/ Undergraduates\",\n    subtitle = \"The decrease \",\n    caption = \"stesiam, 2023\",\n    x = \"\",\n    y = \"\"\n  ) +\n  theme_classic() +\n  theme(\n    plot.title = element_markdown(family = \"serif\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"serif\"),\n    plot.caption = element_markdown(family = \"serif\"),\n    axis.text.x = element_text(face=\"bold\", angle=90)\n  )\n\nWarning: Removed 4 rows containing missing values (position_stack)."
  },
  {
    "objectID": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#master-students",
    "href": "english/2023-07-23-Graduates-of-Statistics/2023-07-23-Graduates-of-Statistics.html#master-students",
    "title": "Statistics of Statistics Graduates",
    "section": "Master Students",
    "text": "Master Students\n\nstatistics_tables[[3]] %&gt;%\n  select(c(1,2)) %&gt;%\n  setNames(c(\"Year\", \"S\")) %&gt;%\n  .[-c(1,2),] %&gt;%\n  separate(S, c('Admitted', 'Graduated')) %&gt;%\n  na.omit() %&gt;%\n  mutate(Ratio = round(as.numeric(Graduated)/as.numeric(Admitted), 2)) %&gt;%\n  select(Year, Ratio) %&gt;%\n  ggplot(.) +\n  geom_line(aes(x = Year, y = Ratio, group = 1))+\n  theme_classic()\n\nWarning: Expected 2 pieces. Missing pieces filled with `NA` in 21 rows [1, 3,\n5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, ...]."
  }
]