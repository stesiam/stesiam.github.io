[
  {
    "objectID": "material/index.html",
    "href": "material/index.html",
    "title": "Material",
    "section": "",
    "text": "Title\nType\nSize\nSource\n\n\n\n\n\nSummary of Distributions\n\n44.8 KB\nRepo URL\n\n\n\nBefore my First Stats Lecture\n\n248 KB\nRepo URL"
  },
  {
    "objectID": "material/index.html#posters",
    "href": "material/index.html#posters",
    "title": "Material",
    "section": "",
    "text": "Title\nType\nSize\nSource\n\n\n\n\n\nSummary of Distributions\n\n44.8 KB\nRepo URL\n\n\n\nBefore my First Stats Lecture\n\n248 KB\nRepo URL"
  },
  {
    "objectID": "material/index.html#assignments-in-greek",
    "href": "material/index.html#assignments-in-greek",
    "title": "Material",
    "section": "Assignments (in greek)",
    "text": "Assignments (in greek)\n\n\n  \n    \n      \n    \n    Sampling Assignment\n    Semester assignment on which I solve exercises about SRS, SSRW, Systematic and Cluster Sampling\n  \n  \n      \n        141\n        \n        \n        \n      \n  \n\n\n  \n    \n      \n    \n    Analysis of Variance\n    Exercises appliying One-way and Two-way ANOVA\n  \n  \n      \n        54\n        \n        \n        \n      \n  \n\n\n  \n    \n      \n    \n    Statistical Programs II\n    Application of statistical tests (normality, correlation etc.) using Rstats.\n  \n  \n      \n        44\n        \n        \n        \n      \n  \n\n\n  \n    \n      \n    \n    Non Parametric Statistics\n    A collection of solved assignments testing normality, differences between 2/3 samples (t-test, Kruskal etc.)\n  \n  \n      \n        92"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello üëã, I‚Äôm Stelios!",
    "section": "",
    "text": "I am an undergraduate student of Statistics and Insurance Science at University of Piraeus. On my website I upload various posts closely related with Statistics and . Also, you can have a look on my Shiny Apps and my visualizations."
  },
  {
    "objectID": "posts/2022-11-04-Git-Commands/index.html",
    "href": "posts/2022-11-04-Git-Commands/index.html",
    "title": "Git Series (Part I - Configuration)",
    "section": "",
    "text": "A Version Control System (VCS) is a way to manage and track code changes. As we build an application, we add functions, change frontend features, fix bugs. We will need to edit the code many times. So we need a way to manage these changes. The tracking of every change to our code is the key point of VCS.\n\n\nWorkflow without Version Control\n\nSome popular Version Control Software are the following :\n\nGit\nApache Subversion (SVN)\nMercurial\nBazaar\n\nHaving seen what a VCS is, it would be interesting to see which one is the most widely used. In order to study which VCS is the most popular, I pulled data from Google Trends.\n\nShow the code  ggplot(data = trends_vcs_tidy, aes(x= Month, y = counts)) +\n  geom_line(aes(color = VCS)) +\n  labs(title = \"Trends on Version Control Systems\",\n              subtitle = \"Compare trends of Git and SVN (Subversion) from 2004 to 2022\",\n              caption = \"Data source: Google Trends\") +\n  theme_classic()\n\n\n\n\n\n\n\nThe figure above makes clear the dominance of Git as a version control tool. Also, we notice that Subversion (SVN) was quite popular and a capable competitor of Git until 2010. After that period there is a continuous decline in SVN‚Äôs interest and the exact opposite for Git. Today, in 2022, the difference is chaotic between them.\n\n\nWhy should I use VCS ?\n\n\nEasy transition between versions\nMore productive, Time saver if a version produces error\nEnables cooperation with other developers (especially with a hosting service like GitHub).\n\n\nOk. There are some good points. But where is the catch ?\n\n\nWe are adding a new tool to our workflow (Git)\nKind of steep learning curve.\n\nWe have mentioned some of the most important programs for managing the code of an application. Of course, there are not a few times when we want to save the progress of our application somewhere else to enable developers communicate their code commits to each other. The solution is some code hosting services. The best known are GitHub, GitLab and Bitbucket. Finally, in case none of the options outlined earlier satisfy us, there is also the self-host solution. For example, if I had concerns about the terms of the above services, I could host Gitea on my own server or even to rent a cloud server. That way I would have my own ‚ÄúGitHub‚Äù, without depending on a third party service."
  },
  {
    "objectID": "posts/2022-11-04-Git-Commands/index.html#introduction",
    "href": "posts/2022-11-04-Git-Commands/index.html#introduction",
    "title": "Git Series (Part I - Configuration)",
    "section": "",
    "text": "A Version Control System (VCS) is a way to manage and track code changes. As we build an application, we add functions, change frontend features, fix bugs. We will need to edit the code many times. So we need a way to manage these changes. The tracking of every change to our code is the key point of VCS.\n\n\nWorkflow without Version Control\n\nSome popular Version Control Software are the following :\n\nGit\nApache Subversion (SVN)\nMercurial\nBazaar\n\nHaving seen what a VCS is, it would be interesting to see which one is the most widely used. In order to study which VCS is the most popular, I pulled data from Google Trends.\n\nShow the code  ggplot(data = trends_vcs_tidy, aes(x= Month, y = counts)) +\n  geom_line(aes(color = VCS)) +\n  labs(title = \"Trends on Version Control Systems\",\n              subtitle = \"Compare trends of Git and SVN (Subversion) from 2004 to 2022\",\n              caption = \"Data source: Google Trends\") +\n  theme_classic()\n\n\n\n\n\n\n\nThe figure above makes clear the dominance of Git as a version control tool. Also, we notice that Subversion (SVN) was quite popular and a capable competitor of Git until 2010. After that period there is a continuous decline in SVN‚Äôs interest and the exact opposite for Git. Today, in 2022, the difference is chaotic between them.\n\n\nWhy should I use VCS ?\n\n\nEasy transition between versions\nMore productive, Time saver if a version produces error\nEnables cooperation with other developers (especially with a hosting service like GitHub).\n\n\nOk. There are some good points. But where is the catch ?\n\n\nWe are adding a new tool to our workflow (Git)\nKind of steep learning curve.\n\nWe have mentioned some of the most important programs for managing the code of an application. Of course, there are not a few times when we want to save the progress of our application somewhere else to enable developers communicate their code commits to each other. The solution is some code hosting services. The best known are GitHub, GitLab and Bitbucket. Finally, in case none of the options outlined earlier satisfy us, there is also the self-host solution. For example, if I had concerns about the terms of the above services, I could host Gitea on my own server or even to rent a cloud server. That way I would have my own ‚ÄúGitHub‚Äù, without depending on a third party service."
  },
  {
    "objectID": "posts/2022-11-04-Git-Commands/index.html#git-settings",
    "href": "posts/2022-11-04-Git-Commands/index.html#git-settings",
    "title": "Git Series (Part I - Configuration)",
    "section": "Git settings",
    "text": "Git settings\nSet up Name & Email\nSo, you decided to start Git without setting Name and Email?\nYou may think of it again. In case you try to commit without setting a Name and email. Git will not commit your changes, without prior setting those.\n\n\nTerminal\n\ngit config --global user.name \"YourName\"\ngit config --global user.email your_email\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are planning to host your repository on GitHub, you may want to hide your casual email. In that case GitHub offers a noreply email for this purpose. You can read more here.\n\n\nSet editor\nA part that I considered a little bit hard is editing Git commits. By default, Ubuntu has installed Vim, so this was my first editor for my commits. I think this choice is good if you are writing short commit messages or you are acquainted with Vim options/shortcuts. In case you are in a hurry, the use of an alterantive (most familiar) IDE is justified.\n\n\nTerminal\n\ngit config --global core.editor \"editor_name\"\n\nMost notable is Visual Studio Code, which is the most popular IDE, according to recent Stackoveflow‚Äôs survey.\n\n\nEditor\nCommand\n\n\n\nAtom\ngit config ‚Äìglobal core.editor ‚Äúatom ‚Äìwait‚Äù\n\n\nVisual Studio Code\ngit config ‚Äìglobal core.editor ‚Äúcode ‚Äìwait‚Äù\n\n\nDefault branch name to main\nIn October of 2020, GitHub announced that will change the default name of initial branch from master to main. \n\nThe default branch name for new repositories is now main. GitHub.blog - October 1,2020\n\nTherefore, it would be good to make this change in our local environment as well, as follows :\n\n\nTerminal\n\ngit config --global init.defaultBranch main\n\nMerge method\nOne change that is not exactly necessary but helps me is to change the defaults regarding merge. Let‚Äôs say that I want to add a new feature in my application. Most of the times I will make a branch on which I will start developing my new feature. When I implement this function and I‚Äôm ready to merge my changes into the main code there are two situations.\n1. There are commits to main branch \nThe predefined action is to merge. The branch is visible. Our setting has not any effect on this case.\n2. There are no commits to main branch\nThe predefined action of Git is to take the feature branch and paste it on the top of main branch. By making the setting above I am telling Git to keep the branch and react like the first case. The branch is visible again.\nWith simple words, I am forcing Git to keep branch, regardless of changes to main branch.\n\n\nTerminal\n\ngit config --global merge.ff false\n\nAuto-sign your commits\nIn a previous article we saw how to sign our commits as well as the reasons for doing so. In short, we made a PGP key which we added to our GitHub account. From that moment to sign my commits I had to write git commit -S -m \"something\", instead of git commit -m \"something\". Of course, that method is a little bit problematic. It is a little bit longer, little different in comparison to what I am used to type and most importantly I may forget some times to sign it manually. The last one happened to me A LOT. Thankfully, there is a way to be carefree about that anymore. I can set git config in a way that my commits will be signed automatically.\n\n\n\n\n\n\nWarning\n\n\n\nIf you do not have already a GPG key, you can have a look in this guide in order to generate one. Also, depending your hosting platform for your code, you can link your GPG with your account : \n\n\nGitHub and GPG keys \n\n\nBitBucket and GPG keys \n\nGitLab and GPG keys\n\n\n\n\n\nTerminal\n\ngpg --list-secret-keys --keyid-format LONG\ngit config user.signingkey key_id\ngit config commit.gpgsign true\n\nCheck your settings\nMaking the above settings, we can have a summary of those with the corresponding command:\n\n\nTerminal\n\ngit config --list\n\nHere is the output on my machine :\n\n\nOutput of git-config command\n\nThe image above sums up the settings of Git. Although, each user has different needs and for that reason it would be good in case you want to learn more about git config to see their documentation page."
  },
  {
    "objectID": "posts/2022-11-04-Git-Commands/index.html#to-sum-up",
    "href": "posts/2022-11-04-Git-Commands/index.html#to-sum-up",
    "title": "Git Series (Part I - Configuration)",
    "section": "To sum up",
    "text": "To sum up\nA summary of the commands we used to configure Git :\n\n\nTerminal\n\ngit config --global user.name \"YourName\"\ngit config --global user.email your_email\ngit config --global core.editor \"editor_name\"\ngit config --global init.defaultBranch main\ngit config --global merge.ff false\n\n# Add PGP key to your commits\n\ngpg --list-secret-keys --keyid-format LONG\ngit config user.signingkey key_id\ngit config commit.gpgsign true\n\n# check git config settings\n\ngit config --list --show-origin\n\nOf course you can access your git config file on your Home directory (at least on Ubuntu installation).\n\n\n\n\n\n\nWarning\n\n\n\nNote that the .gitconfig file, which contains our settings, may not be visible in the Home directory. In general, files whose names begin with a period are not displayed. However, if everything has been done correctly, it‚Äôs probably there. For example, in Ubuntu you should choose to show hidden files.\n\n\nIn case you open that file you will see probably something like the above :"
  },
  {
    "objectID": "posts/2022-11-04-Git-Commands/index.html#acknowledgements",
    "href": "posts/2022-11-04-Git-Commands/index.html#acknowledgements",
    "title": "Git Series (Part I - Configuration)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nImage by Daniel Skovran from Pixabay"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html",
    "title": "Predict Possible Interested Clients",
    "section": "",
    "text": "On this article, I will make a ML model, in order to predict the costumers of a bank that are interested on having a term deposit. To achieve this goal I will use some Boosting algorithms (XGBoost and LightGBM). The data is from UCI website (Dua & Graff, 2017) and the dataset that I worked with is ‚ÄúBank Marketing‚Äù (Moro, Cortez, & Rita, 2014).\nBut first let‚Äôs explain some things.\n\nWhat is a term deposit ?\n\nGenerally, we are saving our money in a bank account but we are promising to not withdraw them for a specific amount of time.\n\nAnd why someone to do that ?\n\nIt is apparent that term deposits have a major disadvantage over regular ones in terms of capital availability. Of course, people will not have motive to do that without anything in return. For that reason, the banks usually offer higher interest for that kind of accounts. For example, Piraeus Bank (a bank in Greece) offers double interest rate on term deposits compared to regular ones.\nSo, we can assume that there will be a serious interest for that product mostly on people with significant amount of savings (&gt;1000) and do not have large, extraordinary expenses (loan, kids, etc.)."
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#import-libraries",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#import-libraries",
    "title": "Predict Possible Interested Clients",
    "section": "Import libraries",
    "text": "Import libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, Fran√ßois, Henry, M√ºller, & Vaughan, 2023). The kableExtra (Zhu, 2021) package was used to print the results in table format. Concerning general purpose R libraries, I also used gridExtra in order to show ggplot items side to side.\nOn its basis this analysis is about to predict if someone is interested or not to have a term deposit. Thus, we need to build a ML model. The all-in-one solution package tidymodels is crucial to this. Although, there are some concerns about our data (imbalanced predicted value and our implementation of LightGBM. Thankfully, these are solved by bonsai and treesnip packages, respectively.\nFinally, the ggplot2 (Wickham et al., 2024) package was used to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nShow the code# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(kableExtra)\nlibrary(gridExtra)\n\n# Build ML models\nlibrary(tidymodels)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Other R packages\nlibrary(fontawesome)\n\n\n# Build ML models\n\nlibrary(tidymodels)\nlibrary(bonsai)\nlibrary(themis)\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#import-dataset",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#import-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading R libraries, then I will load my data. The initial source of my dataset has various versions of the same dataset. I will use the smaller one, as the fitting process on Boosting algorithms it is more time consuming in comparison with other methods (e.g.¬†Logistic Regression, k-Nearest Neighbours etc.).\n\nShow the codebank_dataset &lt;- read_delim(\"bank_dataset_files/bank.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\nbank_dataset = bank_dataset %&gt;% tibble::rowid_to_column(\"ID\")"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#preview-dataset",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#preview-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Preview dataset",
    "text": "Preview dataset\nHere we can see a small chunk of my dataset (first 10 rows / observations) just to understand the dataset‚Äôs structure and type of variables.\n\nShow the code#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_bank_dataset = head(bank_dataset, 10)\nkbl(preview_bank_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\nID\nage\njob\nmarital\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nday\nmonth\nduration\ncampaign\npdays\nprevious\npoutcome\ny\n\n\n\n1\n30\nunemployed\nmarried\nprimary\nno\n1787\nno\nno\ncellular\n19\noct\n79\n1\n-1\n0\nunknown\nno\n\n\n2\n33\nservices\nmarried\nsecondary\nno\n4789\nyes\nyes\ncellular\n11\nmay\n220\n1\n339\n4\nfailure\nno\n\n\n3\n35\nmanagement\nsingle\ntertiary\nno\n1350\nyes\nno\ncellular\n16\napr\n185\n1\n330\n1\nfailure\nno\n\n\n4\n30\nmanagement\nmarried\ntertiary\nno\n1476\nyes\nyes\nunknown\n3\njun\n199\n4\n-1\n0\nunknown\nno\n\n\n5\n59\nblue-collar\nmarried\nsecondary\nno\n0\nyes\nno\nunknown\n5\nmay\n226\n1\n-1\n0\nunknown\nno\n\n\n6\n35\nmanagement\nsingle\ntertiary\nno\n747\nno\nno\ncellular\n23\nfeb\n141\n2\n176\n3\nfailure\nno\n\n\n7\n36\nself-employed\nmarried\ntertiary\nno\n307\nyes\nno\ncellular\n14\nmay\n341\n1\n330\n2\nother\nno\n\n\n8\n39\ntechnician\nmarried\nsecondary\nno\n147\nyes\nno\ncellular\n6\nmay\n151\n2\n-1\n0\nunknown\nno\n\n\n9\n41\nentrepreneur\nmarried\ntertiary\nno\n221\nyes\nno\nunknown\n14\nmay\n57\n2\n-1\n0\nunknown\nno\n\n\n10\n43\nservices\nmarried\nprimary\nno\n-88\nyes\nyes\ncellular\n17\napr\n313\n1\n147\n2\nfailure\nno"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#dataset-structure",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#dataset-structure",
    "title": "Predict Possible Interested Clients",
    "section": "Dataset structure",
    "text": "Dataset structure\nBefore we do any analysis we have to define what kind of data we have available. We can assess this type of information by looking on the values of each variable. Generally, we can classify our variables, depending their values, as follows :\n\n\nShow the codegraph TD;\n  A(Type of variables) --&gt; B(Quantitative)\n  A(Type of variables) --&gt; C(Qualitative)\n  B --&gt; D(Discrete)\n  B --&gt; E(Continuous)\n  C --&gt; J(Nominal)\n  C --&gt; G(Ordinal)\n\n\n\n\ngraph TD;\n  A(Type of variables) --&gt; B(Quantitative)\n  A(Type of variables) --&gt; C(Qualitative)\n  B --&gt; D(Discrete)\n  B --&gt; E(Continuous)\n  C --&gt; J(Nominal)\n  C --&gt; G(Ordinal)\n\n\n\n\n\n\n\nOur dataset is consisted by 18 variables (columns) and 4521 observations (rows). More specifically, concerning my variables, are as follows :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nAge\n\nquantitative  (continuous)\nThe age of the respondent\n\n\nJob\n\nqualitative  (nominal)\nThe sector of employment of the respondent\n\n\nMarital\n\nqualitative  (nominal)\nThe marital status of the respondent\n\n\nEducation\n\nqualitative  (ordinal)\nThe higher education level that the respondent has ever reached\n\n\nDefault\n\nqualitative  (nominal)\nhas credit in default?\n\n\nBalance\n\nquantitative  (continuous)\nAverage yearly balance, in euros\n\n\nHousing\n\nqualitative  (nominal)\nHas housing loan?\n\n\nLoan\n\nqualitative  (nominal)\nHas personal loan?\n\n\nContact\n\nqualitative  (nominal)\nContact communication type\n\n\nMonth\n\nqualitative  (ordinal)\nLast contact day of the month\n\n\nDuration\n\nquantitative  (continuous)\nLast contact duration, in seconds (numeric)\n\n\nCampaign\nquantitative\nNumber of contacts performed during this campaign and for this client\n\n\npdays\nquantitative\nNumber of days that passed by after the client was last contacted from a previous campaign\n\n\npprevious\nquantitative\nNumber of contacts performed before this campaign and for this client\n\n\npoutcome\n\nqualitative (nominal)\nOutcome of the previous marketing campaign\n\n\nDeposit\n\nqualitative  (nominal)\nHas the client subscribed a term deposit?\n\n\n\nThus, my sample has 18 variables, of which 7 are quantitative and 10 are quantitative properties, of which 8 are nominal and the rest ones (Education, Month) are ordinal.\n\nShow the codebank_dataset$y = as.factor(bank_dataset$y)"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#custom-functions",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#custom-functions",
    "title": "Predict Possible Interested Clients",
    "section": "Custom functions",
    "text": "Custom functions\n\nSo, I have a basic idea about my data. Can we start analyzing our data?\n\nIt depends. If you want to do a simple analysis then yes. Although most of the times this is not the case. Probably there is the need for repetitive actions. In order to not repeat ourselves we need to define some actions, prior to our analysis.\nOn this occasion, I found beneficial the definition of a function for qualitative data.\n\nShow the codeunivariate_qualitative = function(variable, title_plot){\ntable = bank_dataset %&gt;%\n    select(variable) %&gt;%\n    table() %&gt;%\n    prop.table() %&gt;%\n    as.data.frame() %&gt;%\n    magrittr::set_colnames(c(\"Var1\", \"Freq\"))\n  \nplot =  ggplot(data = table, aes(x = fct_reorder(Var1,Freq, .desc = T), fill=Var1, y = Freq)) + \n     geom_bar(stat = \"identity\")+\n     scale_fill_hue(c = 40) +\n     geom_text(aes(label = sprintf(\"%.2f %%\", Freq*100),  stat=\"identity\",\n        vjust = -.1)) +\n     labs(\n       title = title_plot,\n       caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n       x = \"Response\",\n       y = \"Observations\"\n        ) +\n     theme_classic() +\n     theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5),)\n  \nreturn(plot)\n}\n\n\nI will do the same for univariate numeric data.\n\nShow the codeuniv_quanti = function(variable_sel){\n  ggplot(bank_dataset, aes(x = variable_sel )) +\n  geom_histogram(x = variable_sel, stat = \"count\") +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Age Distribution of Respondents\",\n    caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Age of Respondent\",\n    y = \"Observations\"\n  ) +\n  theme_classic() + \n  theme(\n    plot.caption = element_markdown(lineheight = 1.2),\n    plot.title = element_text(hjust = 0.5))\n}"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#missing-values",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#missing-values",
    "title": "Predict Possible Interested Clients",
    "section": "Missing Values",
    "text": "Missing Values\n\nShow the codehow_many_nas = sum(is.na(bank_dataset))\n\n\nOn this dataset there are 0 missing values, in total. So, there is no need for imputation."
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#univariate-analysis",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#univariate-analysis",
    "title": "Predict Possible Interested Clients",
    "section": "Univariate analysis",
    "text": "Univariate analysis\nQualitative variables\n\n\nJob\nMarital status\nEducation\nDefault\nHousing\nLoan\nContact\nMonth\npoutcome\nDeposit\n\n\n\n\nShow the codeunivariate_qualitative(\"job\", \"Job of Respondent\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"marital\", \"Marital Status of the respondent\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"education\", \"Educational Backgroung\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"default\", \"Has credit in default ?\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"housing\", \"Has housing loan?\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"loan\", \"Has personal loan ?\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"contact\", \"Type of Contact\")\n\n\n\n\n\n\n\n\n\n\nShow the codeoptions(digits =2)\n\nperc_month = table(bank_dataset$month) %&gt;%\n  prop.table() %&gt;%\n  sort(decreasing = T) %&gt;%\n  as.data.frame()\n\nnum_month = table(bank_dataset$month) %&gt;%\n  sort(decreasing = T) %&gt;%\n  as.data.frame()\n\nperc_month %&gt;%\n    ggplot(aes(x = factor(Var1, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), y = Freq)) + \n  geom_bar(stat = \"identity\")+\n  scale_fill_hue(c = 40) +\n  geom_text(aes(label = sprintf(\"%.2f\", Freq*100),  stat=\"identity\",\n        vjust = -.25)) +\n  labs(\n    title = \"Calls per month\",\n    caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"poutcome\", \"Outcome of previous approach\")\n\n\n\n\n\n\n\n\n\n\nShow the codeunivariate_qualitative(\"y\", \"How many people made a deposit account ?\")\n\n\n\n\n\n\n\n\n\n\nQuantitative variables\n\n\nAge\nBalance\nDuration\nCampaign\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x = age )) +\n  geom_bar() +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Age Distribution of Respondents\",\n    caption = \"Bank Marketing Dataset from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Age of Respondent\",\n    y = \"Observations\"\n  ) +\n  theme_classic() + \n  theme(\n    plot.caption = element_markdown(lineheight = 1.2),\n    plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\nShow the code# NOTE : In order to make HTML tags to work I need to specify element on theme command.\n\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x=balance)) + \n  geom_histogram(bins = 20) +\n  scale_fill_hue(c = 40) +\n  labs(\n    title = \"Average yearly balance\",\n    caption = \" Bank Marketing Data Set from &lt;b&gt;UCI&lt;/b&gt;\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x=duration, fill=duration)) + \n  geom_histogram( ) +\n  scale_fill_hue(c = 40) +\n  theme_bw() +\n  labs(\n    title = \"How many people made a deposit account ?\",\n    caption = \"Data from the 1974 Motor Trend US magazine.\",\n    x = \"Response\",\n    y = \"Observations\"\n  ) +\n  theme_classic() +\n  theme(legend.position = \"none\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, aes(x= campaign, fill=campaign )) + \n  geom_bar() +\n  scale_fill_hue(c = 40) +\n  theme_bw() +\n  labs(\n    title = \"Number of Approaches to a specific person\",\n    x = \"# of Approaches\",\n    y = \"Observations\"\n  ) + \n  theme_classic()"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#bivariate-analysis",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#bivariate-analysis",
    "title": "Predict Possible Interested Clients",
    "section": "Bivariate analysis",
    "text": "Bivariate analysis\nOn the previous section I learned a lot about my dataset. Now, I have to reveal relationships between my variables. Visualizing those relationships will make it even easier to explain our results. In order to make the right plots on the right occasions I used the book ‚ÄúDatavis with R‚Äù (Chapter 4 : Bivariate Graphs).\nQualitative variables\n\n\nJob\nMarital status\nEducation\nDefault\nHousing\nLoan\nContact\nMonth\npoutcome\n\n\n\n\nShow the codeplotjob &lt;- bank_dataset %&gt;%\n  group_by(job, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct))\n\nplot_job = ggplot(plotjob, \n       aes(x = fct_reorder(job, pct),\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Job of Respondent by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\nplot_job\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_marital1 &lt;- ggplot(bank_dataset, \n       aes(x = marital, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n       geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplotmarital &lt;- bank_dataset %&gt;%\n  group_by(marital, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct))\n\nplot_marital2 = ggplot(plotmarital, \n       aes(x = marital,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Marital Status by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nShow the codegridExtra::grid.arrange(plot_marital1, plot_marital2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_education1 &lt;- ggplot(bank_dataset, \n       aes(x = education, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n       geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_education2 = bank_dataset %&gt;%\n  group_by(education, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = education,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Educational Background by Interest to Term Deposit\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nShow the codegridExtra::grid.arrange(plot_education1, plot_education2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_default1 &lt;- ggplot(bank_dataset, \n       aes(x = default, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_default2 = bank_dataset %&gt;%\n  group_by(default, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = default,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Has credit in default ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'default'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_default1, plot_default2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_housing1 &lt;- ggplot(bank_dataset, \n       aes(x = housing, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_housing2 = bank_dataset %&gt;%\n  group_by(housing, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = housing,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Drive Train\",\n       x = \"Class\",\n       title = \"Has housing loan ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'housing'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_housing1, plot_housing2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_loan1 &lt;- ggplot(bank_dataset, \n       aes(x = loan, \n           fill = y)) + \n      scale_fill_hue(c = 40) +\n      theme_bw() +\n      geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_loan2 = bank_dataset %&gt;%\n  group_by(loan, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = loan,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Has personal loan ?\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'loan'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_loan1, plot_loan2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_contact1 &lt;- ggplot(bank_dataset, \n       aes(x = contact, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_contact2 = bank_dataset %&gt;%\n  group_by(contact, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n    ggplot(aes(x = contact,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Forms of contact\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n`summarise()` has grouped output by 'contact'. You can override using the\n`.groups` argument.\n\n\n\nShow the codegridExtra::grid.arrange(plot_contact1, plot_contact2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_month1 &lt;- ggplot(bank_dataset, \n       aes(x = factor(month, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_month2 &lt;- ggplot(bank_dataset, \n       aes(x = factor(month, level = c('jan', 'feb', 'mar', 'apr','may','jun','jul','aug','sep', 'oct', 'nov', 'dec')), fill = y)) + \n       geom_bar(position = \"fill\") +\n  scale_fill_brewer(palette = \"Set2\") +\n  theme_minimal()\n\n\n\nShow the codegridExtra::grid.arrange(plot_month1, plot_month2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nShow the codeplot_poutcome1 &lt;- ggplot(bank_dataset, \n       aes(x = poutcome, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_bar(position = position_dodge(preserve = \"single\"))\n\n\n\nShow the codeplot_poutcome2 = bank_dataset %&gt;%\n  group_by(poutcome, y) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(pct = n/sum(n),\n         lbl = scales::percent(pct)) %&gt;%\n   ggplot(aes(x = poutcome,\n           y = pct,\n           fill = y)) + \n  geom_bar(stat = \"identity\",\n           position = \"fill\") +\n  geom_text(aes(label = lbl), \n            size = 3, \n            position = position_stack(vjust = 0.5)) +\n  scale_fill_brewer(palette = \"Set2\") +\n  labs(y = \"Percent\", \n       fill = \"Interested\",\n       x = \"Class\",\n       title = \"Previous Campaign outcome\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 30, vjust = 0.5),\n        plot.caption = element_markdown(lineheight = 1.2),\n        plot.title = element_text(hjust = 0.5))\n\n\n\nShow the codegridExtra::grid.arrange(plot_poutcome1, plot_poutcome2, nrow =1)\n\n\n\n\n\n\n\n\n\n\nQuantitative variables\n\n\nAge\nBalance\nDuration\nCampaign\n\n\n\n\nShow the codebank_dataset %&gt;%\nggplot(aes(x=y, y=age, fill=y)) +\n  geom_boxplot() +\n  scale_fill_hue(c = 40) +\n  theme_classic() +\n  labs(\n     title = \"Age & Desire of Bank Deposit Account\" \n  )\n\n\n\n\n\n\n\n\n\n\nShow the codeplot1 = bank_dataset[bank_dataset$balance &lt; 15000, ] %&gt;%\nggplot(aes(x = balance, \n           fill = y)) + \n        scale_fill_hue(c = 40) +\n        theme_bw() +\n  geom_histogram(bins=15)\n\nplot1\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, \n       aes(x = duration, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\nShow the codeggplot(bank_dataset, \n       aes(x = campaign, \n           fill = y)) + \n       scale_fill_hue(c = 40) +\n       theme_bw() +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#split-traintest-dataset",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#split-traintest-dataset",
    "title": "Predict Possible Interested Clients",
    "section": "Split train/test dataset",
    "text": "Split train/test dataset\nOur first step is to split our dataset on 2 parts. Each of those will be used for a different purpose. The first part‚Äôs (train dataset) purpose is to build our model. The other part (test dataset) will be used to evaluate our model‚Äôs performance.\n\nShow the codeset.seed(123)\nbank_dataset_split &lt;- initial_split(bank_dataset,\n                                prop = 0.75,\n                                strata = y)\n\n# Create training data\nbank_train &lt;- bank_dataset_split %&gt;%\n                    training()\n\n# Create testing data\nbank_test &lt;- bank_dataset_split %&gt;%\n                    testing()\n\n\n\n\nTrain dataset\nTest dataset\n\n\n\n\nShow the codehead(bank_train) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nID\nage\njob\nmarital\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nday\nmonth\nduration\ncampaign\npdays\nprevious\npoutcome\ny\n\n\n\n1\n30\nunemployed\nmarried\nprimary\nno\n1787\nno\nno\ncellular\n19\noct\n79\n1\n-1\n0\nunknown\nno\n\n\n2\n33\nservices\nmarried\nsecondary\nno\n4789\nyes\nyes\ncellular\n11\nmay\n220\n1\n339\n4\nfailure\nno\n\n\n4\n30\nmanagement\nmarried\ntertiary\nno\n1476\nyes\nyes\nunknown\n3\njun\n199\n4\n-1\n0\nunknown\nno\n\n\n5\n59\nblue-collar\nmarried\nsecondary\nno\n0\nyes\nno\nunknown\n5\nmay\n226\n1\n-1\n0\nunknown\nno\n\n\n7\n36\nself-employed\nmarried\ntertiary\nno\n307\nyes\nno\ncellular\n14\nmay\n341\n1\n330\n2\nother\nno\n\n\n8\n39\ntechnician\nmarried\nsecondary\nno\n147\nyes\nno\ncellular\n6\nmay\n151\n2\n-1\n0\nunknown\nno\n\n\n\n\n\n\n\n\nShow the codehead(bank_test) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nID\nage\njob\nmarital\neducation\ndefault\nbalance\nhousing\nloan\ncontact\nday\nmonth\nduration\ncampaign\npdays\nprevious\npoutcome\ny\n\n\n\n3\n35\nmanagement\nsingle\ntertiary\nno\n1350\nyes\nno\ncellular\n16\napr\n185\n1\n330\n1\nfailure\nno\n\n\n6\n35\nmanagement\nsingle\ntertiary\nno\n747\nno\nno\ncellular\n23\nfeb\n141\n2\n176\n3\nfailure\nno\n\n\n15\n31\nblue-collar\nmarried\nsecondary\nno\n360\nyes\nyes\ncellular\n29\njan\n89\n1\n241\n1\nfailure\nno\n\n\n23\n44\nservices\nsingle\nsecondary\nno\n106\nno\nno\nunknown\n12\njun\n109\n2\n-1\n0\nunknown\nno\n\n\n51\n45\nblue-collar\ndivorced\nprimary\nno\n844\nno\nno\nunknown\n5\njun\n1018\n3\n-1\n0\nunknown\nyes\n\n\n52\n37\ntechnician\nsingle\nsecondary\nno\n228\nyes\nno\ncellular\n20\naug\n1740\n2\n-1\n0\nunknown\nno"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#recipes",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#recipes",
    "title": "Predict Possible Interested Clients",
    "section": "Recipes",
    "text": "Recipes\nAn important part in the process of model building is preprocessing. Depending of model type and data structure, I have to do the necessary changes. The tidymodels offers some ready-made preprocessing functions which make the whole process piece of cake.\nIn instance, the dataset I am working right now has imbalanced response variable (term deposit interest). For that reason, I used the recipe step_smote() from themis package.\n\nShow the codebank_recipe &lt;- recipes::recipe(y~., \n                               data = bank_train) %&gt;%\n  step_rm(poutcome, ID) %&gt;%\n  step_corr(all_numeric(), threshold = 0.75) %&gt;%\n  step_dummy(all_nominal(), -all_outcomes()) %&gt;% prep() %&gt;%\n  step_smote(y) %&gt;%\n  prep()\n\n\nLet‚Äôs preview our dataset after applying our recipes :\n\nShow the codebank_recipe %&gt;%\n  prep() %&gt;%\n  juice() %&gt;%\n  head() %&gt;%\n  kbl() %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\nTable¬†1: Dataset after recipes\n\n\n\n\nage\nbalance\nday\nduration\ncampaign\npdays\nprevious\njob_blue.collar\njob_entrepreneur\njob_housemaid\njob_management\njob_retired\njob_self.employed\njob_services\njob_student\njob_technician\njob_unemployed\njob_unknown\nmarital_married\nmarital_single\neducation_secondary\neducation_tertiary\neducation_unknown\ndefault_yes\nhousing_yes\nloan_yes\ncontact_telephone\ncontact_unknown\nmonth_aug\nmonth_dec\nmonth_feb\nmonth_jan\nmonth_jul\nmonth_jun\nmonth_mar\nmonth_may\nmonth_nov\nmonth_oct\nmonth_sep\ny\n\n\n\n30\n1787\n19\n79\n1\n-1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\nno\n\n\n33\n4789\n11\n220\n1\n339\n4\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno\n\n\n30\n1476\n3\n199\n4\n-1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1\n1\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\nno\n\n\n59\n0\n5\n226\n1\n-1\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno\n\n\n36\n307\n14\n341\n1\n330\n2\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno\n\n\n39\n147\n6\n151\n2\n-1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\nno"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#create-validation-set",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#create-validation-set",
    "title": "Predict Possible Interested Clients",
    "section": "Create validation set",
    "text": "Create validation set\n\nSo, how good is the model? Not so fast‚Ä¶\n\nWe could actually build the model and evaluate its performance. The problem with that approach is the sample.\n\nShow the codecv_folds &lt;- recipes::bake(\n  bank_recipe,\n  new_data = bank_train) %&gt;%\n  rsample::vfold_cv(v = 5, strata = y)"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#specify-models",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#specify-models",
    "title": "Predict Possible Interested Clients",
    "section": "Specify models",
    "text": "Specify models\nNext, parsnip helps us to specify our models. Initially, I will define a LightGBM model,\n\nShow the codelightgbm_model&lt;- parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %&gt;%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\nand an XGBoost one.\n\nShow the codexgboost_model&lt;- parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = tune(),\n learn_rate = tune(),\n tree_depth = tune()) %&gt;%\n set_engine(\"xgboost\")"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#hyperparameters-tuning",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#hyperparameters-tuning",
    "title": "Predict Possible Interested Clients",
    "section": "Hyperparameters tuning",
    "text": "Hyperparameters tuning\nNow, we are specifying the hyperpaterers‚Äô values and a grid to check which combination of those are performing better according to our desired metric (in our case ROC). This has to be done for both, LightGBM\n\nShow the codelightgbm_params &lt;- dials::parameters(\n min_n(),\n tree_depth(range = c(4,10)),\n learn_rate() # learning rate\n)\n\n\n\nShow the codelightgbm_grid &lt;- dials::grid_max_entropy(\n lightgbm_params,\n size = 10)\n\nhead(lightgbm_grid) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n\n\n\n3\n5\n0.00\n\n\n3\n7\n0.00\n\n\n11\n10\n0.00\n\n\n33\n4\n0.08\n\n\n10\n5\n0.01\n\n\n31\n9\n0.00\n\n\n\n\n\nand XGBoost.\n\nShow the codexgboost_params &lt;- dials::parameters(\n min_n(),\n tree_depth(range = c(4,10)),\n learn_rate() # learning rate\n)\n\n\n\nShow the codexgboost_grid &lt;- dials::grid_max_entropy(\n  xgboost_params,\n  size = 10\n)\n\nhead(xgboost_grid) %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n\n\n\n5\n6\n0.00\n\n\n4\n8\n0.00\n\n\n37\n9\n0.00\n\n\n2\n5\n0.00\n\n\n21\n9\n0.01\n\n\n21\n5\n0.05"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#fit-resamples",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#fit-resamples",
    "title": "Predict Possible Interested Clients",
    "section": "Fit resamples",
    "text": "Fit resamples\n\nShow the code# build workflow for LightGBM\n\nlightgbm_workflow &lt;- workflows::workflow() %&gt;%\n add_model(lightgbm_model) %&gt;%\n add_formula(y ~.)\n\n\n\nShow the code# build workflow for XGBoost\n\nxgboost_workflow &lt;- workflows::workflow() %&gt;%\n  add_model(xgboost_model) %&gt;%\n  add_formula(y~.)\n\n\nFinally, we can build the LightGBM model by combining :\n\nThe workflows we set it up above\nThe resamples\nGrid of values (hyperparameters)\nMetric based on which we will evaluate our model‚Äôs performance\n\n\nShow the codestart_time_lightgbm &lt;- Sys.time()\n\nlightgbm_tuned_model &lt;- tune::tune_grid(\n object = lightgbm_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = lightgbm_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)\n\nend_time_lightgbm &lt;- Sys.time()\n\ntime_lightgbm = difftime(end_time_lightgbm,start_time_lightgbm,units = \"secs\")\n\n\nSimilarly, for XGBoost.\n\nShow the codestart_time_xgboost &lt;- Sys.time()\n\nxgboost_tuned_model &lt;- tune::tune_grid(\n object = xgboost_workflow,\n resamples = cv_folds,\n metrics = metric_set(roc_auc, accuracy),\n grid = xgboost_grid,\n control = tune::control_grid(verbose = FALSE) # set this to TRUE to see\n # in what step of the process you are. But that doesn't look that well in\n # a blog.\n)\n\nend_time_xgboost &lt;- Sys.time()\n\ntime_xgboost= difftime(end_time_xgboost,start_time_xgboost,units = \"secs\")"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#evaluate-model",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#evaluate-model",
    "title": "Predict Possible Interested Clients",
    "section": "Evaluate model",
    "text": "Evaluate model\nOur first results based on resamples for LightGBM\n\nShow the codelightgbm_tuned_model %&gt;%\n  show_best(\"roc_auc\",n=5) %&gt;% \n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n33\n4\n0.08\nroc_auc\nbinary\n0.90\n5\n0.01\nPreprocessor1_Model04\n\n\n16\n10\n0.06\nroc_auc\nbinary\n0.90\n5\n0.01\nPreprocessor1_Model10\n\n\n10\n5\n0.01\nroc_auc\nbinary\n0.89\n5\n0.01\nPreprocessor1_Model05\n\n\n34\n10\n0.00\nroc_auc\nbinary\n0.86\n5\n0.01\nPreprocessor1_Model07\n\n\n29\n6\n0.00\nroc_auc\nbinary\n0.86\n5\n0.01\nPreprocessor1_Model09\n\n\n\n\n\nand XGBoost\n\nShow the codexgboost_tuned_model %&gt;%\n  show_best(\"roc_auc\",n=5) %&gt;% \n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\nmin_n\ntree_depth\nlearn_rate\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n21\n5\n0.05\nroc_auc\nbinary\n0.88\n5\n0.01\nPreprocessor1_Model06\n\n\n21\n9\n0.01\nroc_auc\nbinary\n0.85\n5\n0.01\nPreprocessor1_Model05\n\n\n5\n6\n0.00\nroc_auc\nbinary\n0.84\n5\n0.01\nPreprocessor1_Model01\n\n\n40\n5\n0.00\nroc_auc\nbinary\n0.83\n5\n0.01\nPreprocessor1_Model08\n\n\n19\n7\n0.00\nroc_auc\nbinary\n0.83\n5\n0.01\nPreprocessor1_Model07"
  },
  {
    "objectID": "posts/2022-11-24-Predict-Possible-Clients/index.html#last-fit",
    "href": "posts/2022-11-24-Predict-Possible-Clients/index.html#last-fit",
    "title": "Predict Possible Interested Clients",
    "section": "Last fit",
    "text": "Last fit\nBy now we can assess which is the best combination of values. Given those I will assess my model‚Äôs performance on unknown (to my model) data. LightGBM model has 0.8469 ROC-value\n\nShow the codelast_fit_lightgbm_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = 33,\n learn_rate = 0.0787,\n tree_depth = 4) %&gt;%\nset_engine(\"lightgbm\", loss_function = \"squarederror\")\n\n\n\nShow the codeoptions(digits = 4)\n\nlast_fit_workflow &lt;- lightgbm_workflow %&gt;% \n  update_model(last_fit_lightgbm_model)\n\nlast_lightgbm_fit &lt;- \n  last_fit_workflow %&gt;% \n  last_fit(bank_dataset_split)\n\n! train/test split: preprocessor 1/1, model 1/1: NAs introduced by coercion\n\n\n! train/test split: preprocessor 1/1, model 1/1 (predictions): NAs introduced by coercion\n\nShow the codelast_lightgbm_fit %&gt;% \n  collect_metrics() %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\naccuracy\nbinary\n0.8833\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8471\nPreprocessor1_Model1\n\n\n\n\n\nand XGBoost, 0.8736.\n\nShow the codelast_fit_xgboost_model = parsnip::boost_tree(\n mode = \"classification\",\n trees = 100,\n min_n = 21,\n learn_rate = 0.0472,\n tree_depth = 5) %&gt;%\nset_engine(\"xgboost\")\n\n\n\nShow the codeoptions(digits = 4)\n\nlast_fit_xgboost_workflow &lt;- xgboost_workflow %&gt;% \n  update_model(last_fit_xgboost_model)\n\nlast_xgboost_fit &lt;- \n  last_fit_xgboost_workflow %&gt;% \n  last_fit(bank_dataset_split)\n\nlast_xgboost_fit %&gt;% \n  collect_metrics() %&gt;%\n  kbl(toprule = T,align = 'c',booktabs = T)  %&gt;%\n  kable_styling(full_width = F, position = \"center\", html_font = \"Cambria\") \n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\naccuracy\nbinary\n0.8921\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.8693\nPreprocessor1_Model1"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "Statistics of Statistics‚Äô Graduates\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nPDF\n\n\ntabulizer\n\n\n\nExtracting tabular data from PDF file, in order to explore facts about graduates of Statistics and Insurance Department in University of Piraeus \n\n\n\n\n\nJul 23, 2023\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nKaggle‚Äôs Greek Community\n\n\n\n\n\n\nR\n\n\nEDA\n\n\nKaggle\n\n\n\nAn exploratory data analysis about Kaggle‚Äôs Greek community, based on its 2021 survey. A comparison with the rest DS community. \n\n\n\n\n\nMay 6, 2023\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nPredict Possible Interested Clients\n\n\n\n\n\n\nR\n\n\nClassification\n\n\nTidymodels\n\n\n\nBuild a classification machine learning model (using LightGBM & XGBoost) in order to classify people based on their interest to have a term deposit or not. \n\n\n\n\n\nNov 24, 2022\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nInstall LightGBM and CatBoost on Ubuntu 22.04\n\n\n\n\n\n\nLinux\n\n\nLightGBM\n\n\nCatBoost\n\n\nXGBoost\n\n\n\nInstall high performance algorithms (LightGBM, CatBoost & XGBoost) on your Linux device\n\n\n\n\n\nNov 13, 2022\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nGit Series (Part I - Configuration)\n\n\n\n\n\n\nGit\n\n\n\nAn article that brings together some configuration setttings of Git. A beginner‚Äôs approach to Git.\n\n\n\n\n\nNov 4, 2022\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nForecasting Unemployment in Greece\n\n\n\n\n\n\nR\n\n\nTime Series\n\n\n\nMake a prediction about the future value of Greece‚Äôs unemployment using ARIMA model. \n\n\n\n\n\nOct 22, 2022\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nEDA on Greek Parliament\n\n\n\n\n\n\nR\n\n\nEDA\n\n\n\nLet‚Äôs explore the MPs that got elected the most over the years (1981-2019). \n\n\n\n\n\nOct 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nList of Quarto Websites\n\n\n\n\n\n\nQuarto\n\n\n\nA collection of websites built with Quarto. Includes links to websites and their respective repositories. Further additions are always welcome.\n\n\n\n\n\nAug 10, 2022\n\n\nstesiam\n\n\n\n\n\n\n\n\n\n\n\n\nHello, World\n\n\n\n\n\n\nfirst article\n\n\n\nMy very first article in my personal site which is built using Quarto! \n\n\n\n\n\nJul 27, 2022\n\n\nstesiam\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "",
    "text": "Note\n\n\n\nFrequent updates should be expected until this note be erased.\n\n\nThe recent study guide includes data about the graduates and their average grade of graduation over the years. First and foremost the data we are interested in are included in table form (which is good üòÄ) but it is part of a pdf file (which is not good üò¢). Thankfully, tabulizer is the solution to this kind of problems, as it one of its various features is to extract tabular data from pdf files."
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#introduction",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#introduction",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "",
    "text": "Note\n\n\n\nFrequent updates should be expected until this note be erased.\n\n\nThe recent study guide includes data about the graduates and their average grade of graduation over the years. First and foremost the data we are interested in are included in table form (which is good üòÄ) but it is part of a pdf file (which is not good üò¢). Thankfully, tabulizer is the solution to this kind of problems, as it one of its various features is to extract tabular data from pdf files."
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#load-packages",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#load-packages",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Load Packages",
    "text": "Load Packages\nAs I will extract tables from a pdf file, I will definitely need tabulizer package. Unfortunately, I was not able to install the specific package, as I was getting an error similar to this one. This issue seems to be related to rJava package and this comment solved the issue. After installing rJava, I was able to install successfully tabulizer as below:\n\n# remotes::install_github(c(\"ropensci/tabulizerjars\", \"ropensci/tabulizer\"))\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nlibrary(ggplot2)\nlibrary(ggtext)\nlibrary(glue)\nlibrary(showtext)\nlibrary(packcircles)\n#library(ggcirclepack)\nlibrary(sysfonts)\nlibrary(hrbrthemes)  #theme_ipsum_rs\nlibrary(waffle)\n\n\nlibrary(reactable)\n\nlibrary(rJava)\nlibrary(tabulizer)\nlibrary(pdftools)\n\n\nfont_add_google(\"Lobster\", \"lobster\")\nfont_add_google(\"Lato\", \"economica\")\nfont_add_google(\"Creepster\", \"Creepster\")\nfont_add_google(\"Oswald\", \"Oswald\")\nfont_add_google(\"Ubuntu Condensed\", \"uc\")\n\nsysfonts::font_add('fb', '_extensions/quarto-ext/fontawesome/assets/webfonts/fa-brands-400.ttf')\nsysfonts::font_add('fs', '_extensions/quarto-ext/fontawesome/assets/webfonts/fa-solid-900.ttf')\n\nshowtext_auto()\nshowtext::showtext_opts(dpi = 300)"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#extract-data",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#extract-data",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Extract Data",
    "text": "Extract Data\nThe study guide gives a general description of the university, as well as the prerequisites for a degree and a detailed description of each course. In total, the guide is a little bit less than 200 pages! Of course we don‚Äôt need My main source of data is the Department‚Äôs study guide. The most recent one (2022) has data on admissions, graduations etc., since 2004. The study guide gives a general description of the university, as well as the prerequisites for a degree and a detailed description of each course. In total, the guide is a little bit less than 200 pages! Of course we don‚Äôt need everything in there. I am just interested on the tables of the last pages, so I will extract those pages first from the original pdf.\n\n# url = \"https://www.unipi.gr/faculty/mbouts/anak/OS_22_23.pdf\"\n# \n# download.file(url, \n#               destfile = \"sg22.pdf\",\n#               method = \"wget\",\n#               extra = \"--no-check-certificate\")\n\npdf_subset('sg22.pdf',\n  pages = 186:190,  output = \"subset.pdf\")\n\n[1] \"/home/stelios/stesiam.github.io/posts/2023-07-23-Graduates-of-Statistics/subset.pdf\"\n\n\nSo, we extracted the pages which we are interested in. Let‚Äôs take a look at them:\n\n\nThankfully, tabulizer comes with a very handy function to extract all the tables from a PDF file. Yeap, I know the original study guide is written in greek but don‚Äôt worry that‚Äôs just to take a basic understanding of how the pdf and the tables look. I will translate the column names when I will work with the data. But look at the bright side. At least we will get a notebook with ggplot2 visualizations as an alternative of those Excel graphs :)\n\nstatistics_tables &lt;- extract_tables(\n    file   = \"subset.pdf\", \n    method = \"decide\", \n    output = \"data.frame\")\n\nExtracting the tables from splitted PDF I get a list of 5 tables with my data. It‚Äôs amazing that in a matter of seconds I get all the information in a format ready for analysis. If I were to write them the traditional way (copy-paste) it would definitely take me an hour."
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#admitted-students",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#admitted-students",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Admitted students",
    "text": "Admitted students\nSo, in Greece there is 1 standard way to be admitted to a university. Although there are 3 more ways which require some certain conditions. I will try to explain them as simple as possible.\nMain Exams\nOnce a year, third-year high school students from all over Greece take exams on the same subjects at the same time. The exams are known as Panhellenic Exams. Until today, it‚Äôs one of the few things in Greece that as its integrity is not disputed, as the papers of students are getting graded by teachers from other areas. However, it has also faced considerable criticism for the pressure it places on students. In my opinion a fair one as everything in your life is depending on these exams‚Ä¶ If you fail you should wait to retake them next year.\nTypically the exams are being held between the second half of May and the first week of June. The students‚Äô grades are getting published approximately either the end of June or the first days of July. Then you are completing a list on which you are declare which departments you are interested to. On the end of July the minimum grades to be admitted for each department are announced. Those can fluctuate significantly every year as they are depending on both students‚Äô performance on the Exams and the difficulty of the exams.\nIn a nutchell, the departments from big cities like Attica (Athens, Piraeus) and Thessaloniki have the biggest demand and so the minimum grades for those are higher from the rest ones. For example, the Statistics Department in Piraeus had a minimum grade of 11700 in 2019 (for simplicity consider it like 11.7/20). The corresponding department of Statistics in University of Aegean the same year had a minimum grade of 5100 (5.1/20) (yes, that‚Äôs not a typo). Well there are many reasons behind that, as the continuance of austerity in Greece, but in general that‚Äôs the pattern.\nNot so fun fact but when I made my list of preference for studies, Statistics in Piraeus was something like 15th place, so I guess my fate was that. Okay and a little bit of anxiety. :)\nTransfer\nAs I wrote earlier there are some exceptions. First of all the Admission by Transfer is referring to transfer your place in one department with one similar-study in other city. There are many criteria mainly based on your income. For example, a student admitted on Statistics on University of Aegean could be admitted on Statistics Department on Piraeus (i.e.¬†in case his/her family hasn‚Äôt enough income).\nThese seats are limited.\nEntry Exams\nIn case you have already graduated a Bachelor programme then you are able to give Entry Exams on your department of choice, instead of the nightmare of Panhellenic Exams.\n\nadmitted_students = statistics_tables[[1]] %&gt;%\n  .[-1,] %&gt;%\n  setNames(c(\"Year\", \"Main_exams\", \"Transfer\", \"Entry_exams\", \"Other\", \"Total\"))\n\n\nadmitted_students$Main_exams = admitted_students$Main_exams %&gt;% as.integer()\nadmitted_students$Transfer= admitted_students$Transfer %&gt;% as.integer()\nadmitted_students$Entry_exams = admitted_students$Entry_exams %&gt;% as.integer()\nadmitted_students$Other = admitted_students$Other %&gt;% as.integer()\nadmitted_students$Pct_Non_Main = (admitted_students$Main_exams/admitted_students$Total) %&gt;% as.double()\nrownames(admitted_students) = 1:nrow(admitted_students)\n\n\n\nadmitted_students = admitted_students %&gt;% \n  pivot_longer(\n    cols = !Year, \n    names_to = \"Admission_Type\", \n    values_to = \"count\"\n  )\n\nadmitted_students = admitted_students %&gt;%\n  dplyr::filter(Admission_Type == \"Pct_Non_Main\" &\n                !(Year %in% c(\"2020-2121\",\"2021-2022\", \"2022-2023\"))) %&gt;%\n  mutate(perc = round((1 - count)*100, digits = 2),\n         perc100 = 100-perc) %&gt;%\n  dplyr::select(c(-Admission_Type, -count)) %&gt;%\n  tidyr::pivot_longer(., cols = !Year,values_to = \"Obs\") %&gt;%\n  dplyr::rename(\n    \n  )\n\nadmitted_students %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\nI would like to examine the percentage of students who have been admitted by the other 3 ways over the years.\n\ncaption_text = glue(\"&lt;b&gt; Data: &lt;/b&gt; Study Guide of Statistics and Insurance Science &lt;br&gt;&lt;span style='font-family:fb;'  &gt;&#xf09b;&lt;/span&gt; &lt;b&gt;stesiam&lt;/b&gt;, 2024\")\n\nadmitted_students1 =\n admitted_students %&gt;%\ngroup_by(Year) %&gt;%\nmutate(lab.ypos = cumsum(Obs) - 0.5*Obs)\n\nggplot(data = admitted_students1, aes(x = \"\", y = Obs, fill = name)) +\n  geom_bar(stat=\"identity\", width=1) +\n  geom_richtext(aes(y = lab.ypos, label = ifelse(name == \"perc100\", paste0(round(Obs), \"%\"), \"\")), color = \"white\", fontface = \"bold\",\n      fill = NA, label.color = NA)+\n  facet_wrap(~Year, nrow = 3) +\n  coord_polar(\"y\", start=0) +\n  labs(\n    title = \"Proportion of Admissions through Panhellenic Exams\",\n    subtitle = glue(\"It seems that &lt;span style = 'color:#619CFF; font-weight: bold'&gt;Panhellenic Exams&lt;/span&gt; is the prevalent way to be admitted to Statistics &lt;br&gt; Department. Although that was an expected result. It is interesting to study &lt;br&gt; the proportion over the years. The most extraordinary result is in 2011 when almost &lt;br&gt;  everyone came through Panhellenic Exams.\"),\n    caption = caption_text\n  ) +\n  theme_void(base_size = 12) +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_markdown(family = \"lobster\", face=\"bold\"),\n    plot.subtitle = element_markdown(family = \"economica\", \n                                      margin = margin(t=5,b=5)),\n    plot.caption = element_markdown(family = \"economica\",\n                                    lineheight = 1.2)\n  )\n\n\n\n\n\n\nFigure¬†1: Admitted Undergrads through Panhellnic Exams"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#student-population",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#student-population",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Student Population",
    "text": "Student Population\n\nA = statistics_tables[[2]] %&gt;%\n  setNames(c(\"Year\", \"BSc\", \"MScAppliedStat\", \"MScActuar\", \"PhD\")) %&gt;%\n  .[-1,] %&gt;%\n  mutate_at(., vars(-Year), as.integer) %&gt;%\n  tidyr::pivot_longer(., cols = !Year, values_to = \"Obs\")\n \nd = A %&gt;% \n  dplyr::filter(name == \"BSc\" & (Year == \"2003-2004\" | Year == \"2022-2023\"))\n\ne = A %&gt;% dplyr::filter(name == \"BSc\") %&gt;% dplyr::filter(.,Obs == max(Obs) | Obs == min(Obs)) %&gt;%\n  .$Year\n\nsub = glue(\"Last 20 years the undergraduates have been increased\n           by &lt;span style = 'color:orange; font-weight: bold'&gt;{d$Obs[2] - d$Obs[1]}&lt;/span&gt; ({round(((d$Obs[2] - d$Obs[1])/d$Obs[1])*100, digits = 2)} %). &lt;br&gt;The highest number of undergrads is observed at the academic term of &lt;span style = 'color:red; font-weight: bold'&gt;{e[1]}&lt;/span&gt; &lt;br&gt; and the lowest at &lt;span style = 'color:#0a5c36; font-weight: bold'&gt;{e[2]}&lt;/span&gt;\" ) \n\nA %&gt;%\n  dplyr::filter(name == \"BSc\") %&gt;%\n  ggplot(., aes(x = Year, y = Obs, group = \"1\")) +\n  ylim(2000, 3500) +\n  geom_line(color = \"white\") +\n  labs(title = \"Number of Undergraduate Students\",\n       x = \"Academic Year\",\n       y = \"Undergraduate Students\",\n       caption = caption_text,\n       subtitle = sub) +\n  geom_point(data= A %&gt;% dplyr::filter(name == \"BSc\") %&gt;% dplyr::filter(.,Obs == max(Obs)), aes(x = Year, y = Obs), color = \"red3\") +\n  geom_point(data= A %&gt;% dplyr::filter(name == \"BSc\") %&gt;% dplyr::filter(.,Obs == min(Obs)), aes(x = Year, y = Obs), color = \"green4\") +\n  geom_point(data = A %&gt;% dplyr::filter(Year == \"2003-2004\" | Year == \"2022-2023\") %&gt;% dplyr::filter(name == \"BSc\"), color = \"orange\") +\n  geom_text(data= A %&gt;% dplyr::filter(Year == \"2003-2004\" | Year == \"2022-2023\") %&gt;% dplyr::filter(name == \"BSc\"),aes(x = Year, y = Obs+200, label = Obs), color = \"orange\", fontface = \"bold\", size = 4) +\n  theme_minimal(base_size = 12) +\n  theme(axis.text.x = element_text(angle = 60,color = \"white\"),\n        axis.text.y = element_text(color = \"white\"),\n        axis.title = element_text(color = \"white\"),\n        panel.grid = element_blank(),\n        plot.title = element_text(family = \"Oswald\", hjust = 0.5),\n        plot.title.position = \"plot\",\n        plot.subtitle = element_markdown(family = \"Oswald\",\n                                     margin = margin(l = 10, r = 10),\n                                     lineheight = 1.2, hjust = 0.5),\n        plot.caption = element_markdown(family = \"Oswald\", size = 10,\n                                    lineheight = 1.2),\n        plot.background = element_rect(fill = \"black\", color = \"black\"),\n        panel.background = element_rect(fill = \"black\", color = \"black\"),\n        text = element_text(color = \"white\")\n  )"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#phd-students-ratio",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#phd-students-ratio",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "PhD Students Ratio",
    "text": "PhD Students Ratio\n\n# statistics_tables[[3]] %&gt;%\n#   setNames(c(\"Year\", \"MSc_AppliedStats\", \"MSc_Actuar\")) %&gt;%\n#   slice(-c(1:2))\n\n\nms_phd_students = statistics_tables[[2]] %&gt;%\n  setNames(c(\"AcademicYear\", \"BSc\", \"MSc (AppliedStat)\", \"MSc (Actuar)\", \"PhD\")) %&gt;%\n  .[-1,]\n\nrownames(ms_phd_students) = 1:nrow(ms_phd_students)\n\nms_phd_students = ms_phd_students %&gt;%\n  mutate_at(c(\"BSc\", \"MSc (AppliedStat)\", \"MSc (Actuar)\", \"PhD\"), as.numeric) %&gt;%\n  mutate(pct = round((PhD/BSc)*100, 2)) %&gt;%\n  mutate(AcademicYear = stringr::str_remove(AcademicYear, \"-.*\"))\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `MSc (Actuar) = .Primitive(\"as.double\")(`MSc (Actuar)`)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\nlibrary(ggpattern)\nlibrary(MetBrewer)\nbg_gradient &lt;- grid::linearGradient(colours = rev(MetBrewer::met.brewer(\"Pillement\")[5:6]))\nspline.d &lt;- as.data.frame(spline(ms_phd_students$AcademicYear, ms_phd_students$pct))\nggplot(spline.d, aes(x = x, y = y, group = 1))  +\n  ggpattern::geom_area_pattern(\n                               pattern = \"gradient\", \n                               fill = \"#00000000\",\n                               pattern_fill  = \"#00000000\",\n                               pattern_fill2 = \"#80C02080\") +\n  labs(\n    title = \"Ratio of PhD students per Hundreds of Undergraduates\",\n    subtitle = \"The decrease \",\n    caption = caption_text\n  ) +\n  geom_text(data = spline.d %&gt;% dplyr::filter(y == min(y) | y == max(y)),aes(label = round(y,digits = 2), y = y+0.05), fontface = \"bold\", family = \"uc\", nudge_y =0.1, size = 2) +\n  scale_y_continuous(expand = c(0, 0), limits = c(0, NA)) + \n  theme_minimal(base_size = 5) +\n  theme(legend.position = \"none\",\n        plot.title.position = \"plot\",\n        plot.title = element_markdown(family = \"lobster\", face=\"bold\",\n        hjust = 0.5),\n        plot.subtitle = element_markdown(family = \"economica\", \n                                      margin = margin(t=5,b=5, r=10, l = 10),\n                                      hjust = 0.5,\n                                      lineheight = 1.2),\n        plot.caption = element_markdown(family = \"economica\",\n                                    lineheight = 1.2),\n        axis.title = element_blank()\n        )"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#structure-of-students",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#structure-of-students",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Structure of Students",
    "text": "Structure of Students\n\nB = statistics_tables[[2]] %&gt;%\n  setNames(c(\"Year\", \"BSc_students\", \"MScStudentsA\", \"MScStudentsB\", \"PhD\")) %&gt;%\n  .[-1,] %&gt;%\n mutate_at(., vars(-Year), as.integer) %&gt;%\n mutate(\n   MScStudentsB = tidyr::replace_na(MScStudentsB, 0),\n   MSc_Students = MScStudentsA + MScStudentsB\n ) %&gt;%\n  dplyr::select(-c(\"MScStudentsA\", \"MScStudentsB\")) %&gt;%\n  relocate(., MSc_Students, .after = \"BSc_students\") %&gt;%\n  mutate(\n    total = BSc_students + MSc_Students + PhD,\n    BSc_students = BSc_students/total,\n    MSc_Students = MSc_Students/total,\n    PhD = PhD/total\n  ) %&gt;%\n  mutate_at(vars(!c(Year, total)), ~round(.*100, 2)) %&gt;%\n  dplyr::select(c(-total)) %&gt;%\n  tidyr::pivot_longer(., cols = !c(Year), values_to = \"Obs\")\n\nWarning: There was 1 warning in `mutate()`.\n‚Ñπ In argument: `MScStudentsB = .Primitive(\"as.integer\")(MScStudentsB)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\nB %&gt;%\ndplyr::filter(Year == \"2021-2022\") %&gt;%\nggplot(., aes(label=name, values=round(Obs))) +\ngeom_pictogram(n_rows = 10,\n               flip = TRUE,\n               make_proportional = TRUE, \n               family = \"fs\", size = 5, \n               aes(color = name)) +\n  scale_label_pictogram(\n    name = NULL,\n    values = c(\n      \"BSc_students\" = \"graduation-cap\", \n      \"MSc_Students\" = \"graduation-cap\", \n      \"PhD\" = \"graduation-cap\"\n    )\n  ) +\nscale_color_manual(\n    name = NULL,\n    values = c(\n      BSc_students = \"#a40000\",\n      MSc_Students = \"#c68958\", \n      PhD = \"black\"\n    )\n  ) +\n  labs(\n      title = \"Students' Ratio by Degree\",\n      subtitle = \"**&lt;span style = 'color:#a40000; font-weight: bold'&gt;Undergraduates&lt;/span&gt;** are about the 95% of the total student population of our Dept. &lt;br&gt; Next we have **&lt;span style = 'color:#c68958; font-weight: bold'&gt;Postgraduates&lt;/span&gt;** are the 5% and **&lt;span style = 'color:black; font-weight: bold'&gt;PhD&lt;/span&gt;** candidates are just 0.5%.\",\n      caption = caption_text\n  ) +\n  coord_equal() +\n  theme_ipsum_rc(grid=\"\") +\n  theme_enhance_waffle() +\n  theme(legend.position = \"none\",\n        plot.title.position = \"plot\",\n        plot.title = element_markdown(family = \"lobster\", face=\"bold\",\n        hjust = 0.5),\n        plot.subtitle = element_markdown(family = \"economica\", \n                                      margin = margin(t=5,b=5, r=10, l = 10),\n                                      hjust = 0.5, size = 10,\n                                      lineheight = 1.2),\n        plot.caption = element_markdown(family = \"economica\",\n                                    lineheight = 1.2))"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#graduation-rate",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#graduation-rate",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Graduation Rate",
    "text": "Graduation Rate"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#graduates-graduation-grade",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#graduates-graduation-grade",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Graduates & Graduation Grade",
    "text": "Graduates & Graduation Grade\nI hope you are still here because for the end I hold the best part. Finally, how did we perform? The study guide gives a distribution\n\nextractGraduatesAndGrades = statistics_tables[[4]] %&gt;%\n  setNames(c(\"Year\", \"[5.0 - 6)\", \"[6, 7)\", \"[7-8.5)\", \"[8.5-10]\", \"AVG_Grade\")) %&gt;%\n  slice(-c(1:4))  %&gt;%\n  mutate(across(\"AVG_Grade\"), separate(.,AVG_Grade, into = c(\"AVG_Grade\", \"Graduates\"),sep = \"\\\\(\")) %&gt;%\n  select(c(\"Year\", \"AVG_Grade\", \"Graduates\")) %&gt;%\n  mutate(\n    \"Graduates\" =  stringr::str_remove_all(Graduates, \"\\\\)\")\n  ) %&gt;%\n  mutate(\n    AVG_Grade = stringr::str_replace_all(AVG_Grade, \",\", \".\")\n  ) %&gt;%\n  mutate_at(vars(\"AVG_Grade\", \"Graduates\"), as.numeric)\n\n\ndata = extractGraduatesAndGrades %&gt;%\n  mutate(\n    AVG_Group = ifelse(AVG_Grade &gt;= mean(AVG_Grade), \"over\", \"under\")\n  ) %&gt;%\n  mutate(\n    Year = stringr::str_remove_all(Year, \"-.*\")\n  )\n\npacking &lt;- circleProgressiveLayout(data$Graduates, sizetype='area')\ndata &lt;- cbind(data, packing)\ndata &lt;- data |&gt; \n  rename(xcirc = x, \n         ycirc = y, \n         radius_circ = radius) |&gt; \n  tibble::rowid_to_column('id')\n# Calculate the 50 vertices points for each circle\ndat.gg &lt;- circleLayoutVertices(packing, npoints=50)\nfinal_data &lt;- left_join(data, dat.gg, by = join_by(id))\n\n\nggplot(data = final_data) + \n  geom_polygon(aes(x, \n                   y, \n                   group = Year,\n                   fill = AVG_Group), \n               colour = \"white\", \n               # alpha = 0.7\n               ) +\n  scale_fill_manual(values = c(\"under\"=\"#ff6366\",\"over\" = \"#0D6E6E\"))+\n  geom_richtext(aes(xcirc, \n                ycirc,\n                size = Graduates,\n                label = glue(\"{Year}\")),\n            family = 'uc', \n            fontface = 'bold',\n            fill = NA, label.color = NA) +\n  labs(title = \"Graduates and Graduation Grade per Year\",\n       subtitle = \"On this bubble chart we visualized the total graduates per Academic Year &lt;br&gt; depending on the size of the circle. Funrthermore, the color of the circle &lt;br&gt; notes if the average grade of graduation of that specific year is **&lt;span style = 'color: #0D6E6E'&gt;over&lt;/span&gt;** or &lt;br&gt;**&lt;span style = 'color: #ff6366'&gt;under&lt;/span&gt;** the historical average graduation grade.\",\n       x = NULL,\n       y = NULL,\n       caption = caption_text) +\n  coord_equal() +\n  theme_void(base_size = 10) +\n  theme(\n      legend.position = \"none\",\n      plot.subtitle = element_markdown(family = \"serif\"),\n      plot.caption = element_markdown(lineheight = 1.2)\n  )"
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#online-vs-on-campus-exams",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#online-vs-on-campus-exams",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Online vs On-campus Exams",
    "text": "Online vs On-campus Exams\nDue to pandemic COVID-19, Greek government suspended the operation of schools (elementary, high school, universities) on Tuesday 10 March 2020. Some days later imposed lockdown measures. That period our department organized online lectures and organized online exams for the majority of the courses on Spring Semester and on the September (retake exams). Long story short that lasted for at least 2 years."
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#students-graduated-in-6-years",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#students-graduated-in-6-years",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Students Graduated in 6 Years",
    "text": "Students Graduated in 6 Years\nLast but not least, maybe the most nervewrecking statistic is that one. Just for clarification, our studies have a duaration of four years. Although the majority will not successfully finish their degree even in 6 Years. This is important as currently has been voted the time-limit on BSc studies. We have 6 years to complete our studies otherwise we will not take the degree. In the next years, the best case scenario is that 60% of my collegeaus who were about to graduate will not get their degree."
  },
  {
    "objectID": "posts/2023-07-23-Graduates-of-Statistics/index.html#acknowledgements",
    "href": "posts/2023-07-23-Graduates-of-Statistics/index.html#acknowledgements",
    "title": "Statistics of Statistics‚Äô Graduates",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nDataset based on recent study guide recent study guide of Department of Statistics and Insurance Science of the University of Piraeus.\nImage by Victoria Loveland from Pixabay"
  },
  {
    "objectID": "posts/2022-07-27-hello/index.html",
    "href": "posts/2022-07-27-hello/index.html",
    "title": "Hello, World",
    "section": "",
    "text": "Finally, I made my site using Quarto and hosted it via  GitHub Pages.\nIt was a month ago, that I decided to start building my website. Initially, I was experimenting with other frameworks (e.g., Hugo with the help of blogdown, Distill), which were pretty good, but Quarto fulfilled my needs. The reasons for my decision are going to be discussed in a new article.\n\n\n\n\n\n\n\n\n\n\n\n(a) Distill logo\n\n\n\n\n\n\n\n\n\n\n\n(b) Blogdown logo\n\n\n\n\n\n\n\nFigure¬†1: Packages to make a website in R (before Quarto)"
  },
  {
    "objectID": "posts/2022-07-27-hello/index.html#acknowledgments",
    "href": "posts/2022-07-27-hello/index.html#acknowledgments",
    "title": "Hello, World",
    "section": "Acknowledgments",
    "text": "Acknowledgments\n\nImage by R. E. Beck from Pixabay"
  },
  {
    "objectID": "gallery/index.html",
    "href": "gallery/index.html",
    "title": "Gallery",
    "section": "",
    "text": "See Code"
  },
  {
    "objectID": "gallery/index.html#day-chart-challenge",
    "href": "gallery/index.html#day-chart-challenge",
    "title": "Gallery",
    "section": "",
    "text": "See Code"
  },
  {
    "objectID": "gallery/index.html#tidy-tuesday",
    "href": "gallery/index.html#tidy-tuesday",
    "title": "Gallery",
    "section": "Tidy Tuesday",
    "text": "Tidy Tuesday\n See Code"
  },
  {
    "objectID": "gallery/index.html#day-map-challenge",
    "href": "gallery/index.html#day-map-challenge",
    "title": "Gallery",
    "section": "30 Day Map Challenge",
    "text": "30 Day Map Challenge\n See Code\n\n\n\n\n\nPublic Music Schools in Greece\n\n\n\n\n\n\n\nRailway Network of Greece\n\n\n\n\n\n\n\nRegions of Greece\n\n\n\n\n\n\n\nPharmacies in Greece\n\n\n\n\n\n\n\nPorts in Ukraine\n\n\n\n\n\n\n\nLuxembourg‚Äôs City Bus Transportation\n\n\n\n\n\n\n\nPopulation in Europe\n\n\n\n\n\n\n\nPublic Buildings, Lamia city\n\n\n\n\n\n\n\nStarmap of Athens\n\n\n\n\n\n\n\nWildfire in Euboea"
  },
  {
    "objectID": "gallery/index.html#greece-in-figures",
    "href": "gallery/index.html#greece-in-figures",
    "title": "Gallery",
    "section": "Greece in Figures",
    "text": "Greece in Figures\n See Code\n\n\n\n\n\nPharmacies in Greece\n\n\n\n\n\n\n\nGDP per capita\n\n\n\n\n\n\n\nDentists per Region\n\n\n\n\n\n\n\nHeating Oil Consumption\n\n\n\n\n\n\n\nElectricity consumption, 2012\n\n\n\n\n\n\n\nHousehold Size, 2021"
  },
  {
    "objectID": "gallery/index.html#eu-in-figures",
    "href": "gallery/index.html#eu-in-figures",
    "title": "Gallery",
    "section": "EU in Figures",
    "text": "EU in Figures\n See Code\n\n\n\n\n\nUnemployment, 2022\n\n\n\n\n\n\n\nR&D, 2021"
  },
  {
    "objectID": "gallery/index.html#other-visualizations",
    "href": "gallery/index.html#other-visualizations",
    "title": "Gallery",
    "section": "Other Visualizations",
    "text": "Other Visualizations\n\n\n\n\n\nMost elected MPs\n\n\n\n\n\n\n\nWomen Participation in DS\n\n\n\n\n\n\n\nAge Distribution (GR & Rest of World)\n\n\n\n\n\n\n\nGit vs SVN\n\n\n\n\n\n\n\nStatistics Graduates per Year\n\n\n\n\n\n\n\nAdmissions through Panhellenic Exams\n\n\n\n\n\n\n\nStructure of Student Population\n\n\n\n\n\n\n\nMinimum Admission Grade\n\n\n\n\n\n\n\nAdmission Seats on each Statistics Department\n\n\n\n\n\n\n\nPercentage of Electives"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html",
    "title": "EDA on Greek Parliament",
    "section": "",
    "text": "And here we go‚Ä¶\nThis is the first notebook on my website and I‚Äôd like to be a little special. I didn‚Äôt want to just take a ready-made dataset and apply a machine learning technique (I will do this in the next articles). So, I decided to make my own with the help of hellenic‚Äôs parliament website.\nThe Greek political scene has particularly preoccupied global public opinion in recent years, due to the Greek economic crisis. A part of it was spent on the reasons that caused it. The causes of the Greek crisis are many and a point of contention to this day. In this article we will deal essentially with one of the points of criticism. The election of the same persons.\nWith this notebook I will try to analyze whether this claim is valid by counting how many times someone has been elected to the Greek parliament. In addition, I will study the obsession with the same persons at the party level, but also at the local level (constituencies)."
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#import-libraries",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#import-libraries",
    "title": "EDA on Greek Parliament",
    "section": "Import Libraries",
    "text": "Import Libraries\nFirst and foremost, we have to load our libraries.\n\nShow the code# General purpose R libraries\nlibrary(tidyverse)\nlibrary(kableExtra)\nlibrary(reactable)\nlibrary(highcharter)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggpol) \nlibrary(ggtext)\n\n# Other settings\noptions(digits=2) # print only 2 decimals"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#import-dataset",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#import-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading R libraries, then I will load my data.\n\nShow the codeparliament &lt;- read_csv(\"data/greek_parliament.csv\")"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#preview-dataset",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#preview-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nShow the codepreview_dataset = head(parliament, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\nTable¬†1: Preview Dataset (first 6 rows)\n\n\n\n\n\nFullName\nParty\nConstituency\nTerm\n\n\n\nAgorastis Vasileios\nPA.SO.K. (Panhellenic Socialist Movement)\nLarissa\n3\n\n\nAkrita Sylva - Kaiti\nPA.SO.K. (Panhellenic Socialist Movement)\nAthens B\n3\n\n\nAkritidis Nikolaos\nPA.SO.K. (Panhellenic Socialist Movement)\nThessaloniki A\n3\n\n\nAkrivakis Alexandros\nPA.SO.K. (Panhellenic Socialist Movement)\nViotia\n3\n\n\nAlevras Ioannis\nPA.SO.K. (Panhellenic Socialist Movement)\nAthens A\n3\n\n\nAlexandris Efstathios (Stathis)\nPA.SO.K. (Panhellenic Socialist Movement)\nAthens B\n3\n\n\nAlexiadis Konstantinos\nPA.SO.K. (Panhellenic Socialist Movement)\nTrikala\n3\n\n\nAlexiou Thomas\nNEA DIMOKRATIA\nXanthi\n3\n\n\nAllamanis Stylianos\nNEA DIMOKRATIA\nKarditsa\n3\n\n\nAmanatidis Konstantinos\nPA.SO.K. (Panhellenic Socialist Movement)\nThessaloniki B\n3"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#structure-of-dataset",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#structure-of-dataset",
    "title": "EDA on Greek Parliament",
    "section": "Structure of Dataset",
    "text": "Structure of Dataset\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nFull Name\n\nqualitative  (nominal)\nSurname and name of the member of parliament\n\n\nParty\n\nqualitative  (nominal)\nThe party on which the MP got elected\n\n\nConstituency\n\nqualitative  (nominal)\nMP got elected on this area\n\n\nTerm\n\nqualitative  (ordinal)\nPlenum term\n\n\n\nThus, my sample has 4 variables, of which 0 are quantitative and 4 are quantitative properties, of which 3 are nominal and the rest one (Term) is ordinal."
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#recoding-variables",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#recoding-variables",
    "title": "EDA on Greek Parliament",
    "section": "Recoding variables",
    "text": "Recoding variables\nParty names can vary from short to lengthy ones. The last ones are a problem for our analysis because their names can not fit to our visualisations. The table below is showing all the parties that have ever participated in parliament. Is is apparent that some parties have really long names.\n\nShow the codedata.frame(\n  Party = unique(parliament$Party),\n  Length = str_length(unique(parliament$Party))\n) %&gt;%\n  arrange(-Length) %&gt;%\n  reactable(\n    defaultPageSize = 5\n  )\n\n\n\n\n\nIn our case the parties with the longest name is AN.EL. and Democratic Coalition with 81 and 70 characters, respectively. On the contrary, the shortest party name is POL.A. with 6 characters.\n\nShow the code## Recoding parliament$Party\nparliament$Party[parliament$Party == \"ANEXARTITOI DIMOKRATIKOI VOULEFTES\"] &lt;- \"ADP\"\nparliament$Party[parliament$Party == \"ANEXARTITOI ELLINES (Independent Hellenes)\"] &lt;- \"ANEL\"\nparliament$Party[parliament$Party == \"ANEXARTITOI ELLINES (Independent Hellenes) National Patriotic Democratic Alliance\"]&lt;- \"ANEL\"\nparliament$Party[parliament$Party == \"Coalition of the Left and Progress\"] &lt;- \"SYRIZA\"\nparliament$Party[parliament$Party == \"Communist Party of Greece (Interior)\"] &lt;- \"KKE (interior)\"\nparliament$Party[parliament$Party == \"DEMOCRATIC COALITION (Panhellenic Socialist Movement Democratic Left )\"] &lt;- \"PASOK\"\nparliament$Party[parliament$Party == \"DHM.AR (Democratic Left)\"] &lt;- \"DHMAR\"\nparliament$Party[parliament$Party == \"DI.ANA.\"] &lt;- \"DIANA\"\nparliament$Party[parliament$Party == \"DI.K.KI.\"] &lt;- \"DIKKI\"\nparliament$Party[parliament$Party == \"INDEPENDENT\"] &lt;- \"INDEPENDENT\"\nparliament$Party[parliament$Party == \"KOMMOUNISTIKO KOMMA ELLADAS\"] &lt;- \"KKE\"\nparliament$Party[parliament$Party == \"LA.O.S.\"] &lt;- \"LAOS\"\nparliament$Party[parliament$Party == \"LAIKI ENOTITA\"] &lt;- \"LAE\"\nparliament$Party[parliament$Party == \"LAIKOS SYNDESMOS - CHRYSI AVGI (People‚Äôs Association ‚Äì Golden Dawn)\"] &lt;- \"XA\"\nparliament$Party[parliament$Party == \"NEA DIMOKRATIA\"] &lt;- \"ND\"\nparliament$Party[parliament$Party == \"PA.SO.K. (Panhellenic Socialist Movement)\"] &lt;- \"PASOK\"\nparliament$Party[parliament$Party == \"POL.A.\"] &lt;- \"POLA\"\nparliament$Party[parliament$Party == \"SYNASPISMOS RIZOSPASTIKIS ARISTERAS\"] &lt;- \"SYRIZA\"\nparliament$Party[parliament$Party == \"TO POTAMI (The River)\"] &lt;- \"POTAMI\"\nparliament$Party[parliament$Party == \"ŒüŒü.ŒïŒü.\"] &lt;- \"ŒüŒü.ŒïŒü\""
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#setting-colors",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#setting-colors",
    "title": "EDA on Greek Parliament",
    "section": "Setting colors",
    "text": "Setting colors\nA few days after, I decided that there should be a consistency in the choice of colors. That‚Äôs the reason of this section. Thus, I will assign a dedicated hex color code to each party.\n\nShow the codeparties = data.frame(\n  Party = unique(parliament$Party)\n) |&gt;\n  mutate(Color = case_when(\n    Party == \"PASOK\" ~ \"#95bb72\",\n    Party == \"ND\" ~ \"#0492c2\",\n    Party == \"KKE\" ~ \"#FF6666\",\n    Party == \"SYRIZA\" ~ \"#e27bb1\",\n    Party == \"KKE (interior)\" ~ \"#FF3366\",\n    Party == \"INDEPENDENT\" ~ \"white\",\n    Party == \"DIANA\" ~ \"orange\",\n    TRUE ~ \"grey80\"\n  ))\n\nkke_color = \"#FF6666\"\nnd_color = \"#0492c2\"\npasok_color = \"#95bb72\"\nsyriza_color = \"#e27bb1\""
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#kke",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#kke",
    "title": "EDA on Greek Parliament",
    "section": "KKE",
    "text": "KKE\n\nShow the codeparty_plot(\"KKE\", \"#FF6666\", times_elected_min = 5)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#nd",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#nd",
    "title": "EDA on Greek Parliament",
    "section": "ND",
    "text": "ND\n\nShow the codeparty_plot(\"ND\", \"#0492c2\", times_elected_min = 10)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#pasok",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#pasok",
    "title": "EDA on Greek Parliament",
    "section": "PASOK",
    "text": "PASOK\n\nShow the codeparty_plot(\"PASOK\", \"#95bb72\", times_elected_min = 10)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#syriza",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#syriza",
    "title": "EDA on Greek Parliament",
    "section": "SYRIZA",
    "text": "SYRIZA\n\nShow the codeparty_plot(\"SYRIZA\", \"#e27bb1\", times_elected_min = 5)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#state",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#state",
    "title": "EDA on Greek Parliament",
    "section": "State",
    "text": "State\n\nShow the codeconstituency_freqs(\"State\", 3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#attica",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#attica",
    "title": "EDA on Greek Parliament",
    "section": "Attica",
    "text": "Attica\n\n\nAthens A\nAthens B\nPiraeus A\nPiraeus B\nOf Attica (rest)\n\n\n\n\nShow the codeconstituency_freqs(\"Athens A\",5)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Athens B\",7)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Piraeus A\",5)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Piraeus B\",5)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Of Attica (rest)\",5)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#central-greece",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#central-greece",
    "title": "EDA on Greek Parliament",
    "section": "Central Greece",
    "text": "Central Greece\n\n\nViotia\nEvrytania\nFokida\nFthiotida\n\n\n\n\nShow the codeconstituency_freqs(\"Viotia\",5)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Evrytania\",2)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Fokida\",2)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Fthiotida\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#central-macedonia",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#central-macedonia",
    "title": "EDA on Greek Parliament",
    "section": "Central Macedonia",
    "text": "Central Macedonia\n\n\nThessaloniki A\nThessaloniki B\nKilkis\nPella\nPieria\nSerres\nHalkidiki\n\n\n\n\nShow the codeconstituency_freqs(\"Thessaloniki A\",6)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Thessaloniki B\",6)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kilkis\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Pella\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Pieria\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Serres\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Halkidiki\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#crete",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#crete",
    "title": "EDA on Greek Parliament",
    "section": "Crete",
    "text": "Crete\n\n\nChania\nHeraklion\nLasithi\nRethymno\n\n\n\n\nShow the codeconstituency_freqs(\"Chania\",3)\n\n\n\n\n\n\n\n\n\n\nShow the code#constituency_freqs(\"Irakleio\",3)\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lasithi\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Rethymno\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#eastern-macedonia-and-thrace",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#eastern-macedonia-and-thrace",
    "title": "EDA on Greek Parliament",
    "section": "Eastern Macedonia and Thrace",
    "text": "Eastern Macedonia and Thrace\n\n\nDrama\nEvros\nKavala\nXanthi\nRodopi\n\n\n\n\nShow the codeconstituency_freqs(\"Drama\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Evros\",4)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kavala\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Xanthi\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Rodopi\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#epirus",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#epirus",
    "title": "EDA on Greek Parliament",
    "section": "Epirus",
    "text": "Epirus\n\n\nArta\nIoannina\nPreveza\nThesprotia\n\n\n\n\nShow the codeconstituency_freqs(\"Arta\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Ioannina\",4)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Preveza\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Thesprotia\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#ionian-islands",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#ionian-islands",
    "title": "EDA on Greek Parliament",
    "section": "Ionian Islands",
    "text": "Ionian Islands\n\n\nCorfu\nKefallonia\nLefkada\nZakynthos\n\n\n\n\nShow the codeconstituency_freqs(\"Corfu\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kefallonia\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lefkada\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Zakynthos\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#north-aegean",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#north-aegean",
    "title": "EDA on Greek Parliament",
    "section": "North Aegean",
    "text": "North Aegean\n\n\nChios\nLesvos\nSamos\n\n\n\n\nShow the codeconstituency_freqs(\"Chios\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lesvos\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Samos\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#peloponnese",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#peloponnese",
    "title": "EDA on Greek Parliament",
    "section": "Peloponnese",
    "text": "Peloponnese\n\n\nArgolida\nArkadia\nKorinthia\nLakonia\nMessinia\n\n\n\n\nShow the codeconstituency_freqs(\"Argolida\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Arcadia\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Korinthia\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Lakonia\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Messinia\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#south-aegean",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#south-aegean",
    "title": "EDA on Greek Parliament",
    "section": "South Aegean",
    "text": "South Aegean\n\n\nDodecanese Islands\nCyclades\n\n\n\n\nShow the codeconstituency_freqs(\"Dodecanese Islands\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Cyclades\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#thessaly",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#thessaly",
    "title": "EDA on Greek Parliament",
    "section": "Thessaly",
    "text": "Thessaly\n\n\nKarditsa\nLarissa\nMagnesia\nTrikala\n\n\n\n\nShow the codeconstituency_freqs(\"Karditsa\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Larissa\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Magnesia\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Trikala\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#western-greece",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#western-greece",
    "title": "EDA on Greek Parliament",
    "section": "Western Greece",
    "text": "Western Greece\n\n\nAchaia\nAitoloakarnania\nIleia\n\n\n\n\nShow the codeconstituency_freqs(\"Achaia\",3)\n\n\n\n\n\n\n\n\n\n\nShow the code#constituency_freqs(\"Aitoloakarnania\",3)\n\n\n\n\n\nShow the codeconstituency_freqs(\"Ileia\",3)"
  },
  {
    "objectID": "posts/2022-10-10-EDA-Greek-Parliament/index.html#western-macedonia",
    "href": "posts/2022-10-10-EDA-Greek-Parliament/index.html#western-macedonia",
    "title": "EDA on Greek Parliament",
    "section": "Western Macedonia",
    "text": "Western Macedonia\n\n\nFlorina\nGrevena\nKastoria\nKozani\n\n\n\n\nShow the codeconstituency_freqs(\"Florina\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Grevena\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kastoria\",3)\n\n\n\n\n\n\n\n\n\n\nShow the codeconstituency_freqs(\"Kozani\",3)"
  },
  {
    "objectID": "posts/2022-08-10-List-of-Quarto-Sites/index.html",
    "href": "posts/2022-08-10-List-of-Quarto-Sites/index.html",
    "title": "List of Quarto Websites",
    "section": "",
    "text": "Note\n\n\n\nI have decided to convert the article into a GitHub Repo\n\n\nAs of March of 2024, Quarto is the most starred project among its alternatives with 3.4k  stars compared to blogdown (1.7k ) and distill (400 ). Given the increased popularity of Quarto, I took the initiative to make a list of some sites that are using this framework. That way, users of other popular frameworks (e.g., distill, blogdown) will have the chance to see the features of a Quarto site. Furthermore, existing Quarto users can draw inspiration from other web pages.\n\n\n\n\n\nQuarto logo\n\n\nUnfortunately, it is certain that this list does not contain every Quarto website. However, you are welcome to comment yours in order to be added."
  },
  {
    "objectID": "posts/2022-08-10-List-of-Quarto-Sites/index.html#introduction",
    "href": "posts/2022-08-10-List-of-Quarto-Sites/index.html#introduction",
    "title": "List of Quarto Websites",
    "section": "",
    "text": "Note\n\n\n\nI have decided to convert the article into a GitHub Repo\n\n\nAs of March of 2024, Quarto is the most starred project among its alternatives with 3.4k  stars compared to blogdown (1.7k ) and distill (400 ). Given the increased popularity of Quarto, I took the initiative to make a list of some sites that are using this framework. That way, users of other popular frameworks (e.g., distill, blogdown) will have the chance to see the features of a Quarto site. Furthermore, existing Quarto users can draw inspiration from other web pages.\n\n\n\n\n\nQuarto logo\n\n\nUnfortunately, it is certain that this list does not contain every Quarto website. However, you are welcome to comment yours in order to be added."
  },
  {
    "objectID": "posts/2022-08-10-List-of-Quarto-Sites/index.html#inspiration",
    "href": "posts/2022-08-10-List-of-Quarto-Sites/index.html#inspiration",
    "title": "List of Quarto Websites",
    "section": "Inspiration",
    "text": "Inspiration\nA couple of years ago, I had the desire to create a portfolio website, and I tried out many options. Long story short, I ended up using Distill, and I really loved it because it offered a balance of simplicity and professionalism. Despite some minor issues with Distill (many of which are resolved by Quarto), I was extremely happy with the platform. However, I faced a challenge as I was not only an amateur R programmer but also lacked hands-on experience with HTML/CSS. Around the same time, I discovered a website that listed many Distill websites together. This compilation of websites provided several benefits for me:\n\n\n\n\n\nDistill logo\n\n\n\nUnderstand the limits of Distill package\nMotivation to look on others‚Äô websites and take some inspiration\nEasy access to implemented features and their respective code\n\nIn 2022, Quarto was announced and the things on website publishing with R changed a little bit. Many users have already considered the change to the new framework (based on the Distill sites listing above). Some others may are hesitant due to the fact that Quarto is new or they are not interested to read long documentation. Thus, I believe that a listing of Quarto websites is needed to make the framework more accessible to newer users and speed the implementation of features for existing ones.\n\n\n\n\n\nblogdown logo"
  },
  {
    "objectID": "posts/2022-08-10-List-of-Quarto-Sites/index.html#list-of-quarto-sites",
    "href": "posts/2022-08-10-List-of-Quarto-Sites/index.html#list-of-quarto-sites",
    "title": "List of Quarto Websites",
    "section": "List of Quarto Sites",
    "text": "List of Quarto Sites\nAn indicative list of websites using Quarto is as follows:\n\n\n\n\n\n\n\n\n ¬† User\n\n ¬† Website URL\n\n ¬† Repository\n\n\n\naeturell\naeturrell.com\nhome\n\n\nalexpghayes\nalexpghayes.com\nquarto-blog\n\n\nalmeidasilvaf\nalmeidasilvaf.github.io/\nalmeidasilvaf.github.io\n\n\nandreashandel\nandreashandel.com/\nandreashandelwebsite\n\n\nandrewheiss\nandrewheiss.com\nath-quarto\n\n\nandrewheiss\nnonprofitf22.classes.andrewheiss.com\nnonprofitf22.classes.andrewheiss.com\n\n\naster-hu\nasterhu.com/\nAsteroid_Blog\n\n\nbeatrizmilz\nbeamilz.com\nblog-en\n\n\nBioconductor\nbioconductor.github.io/biocblog/\nbiocblog\n\n\ncgoo4\nquantumjitter.com/\nquantumjitter\n\n\nCrumpLab\ncrumplab.com/\nCrumpLab.github.io\n\n\ncurrocam\ncurrocam.github.io/biocblog/\ncurrocam.github.io\n\n\ncynthiahqy\ncynthiahqy.com/\ndigital-garden\n\n\ndaxkellie\ndaxkellie.com\nwebsite-quarto\n\n\nddimmery\nddimmery.com\nquarto-website\n\n\ndjnavarro\nblog.djnavarro.net/\nquarto-blog\n\n\ndrganghe\ndrganghe.github.io\ndrganghe.github.io\n\n\nekholme\nericekholm.com/\nee-quarto-site\n\n\nEllaKaye\nellakaye.co.uk/\nellakaye.co.uk \n\n\nEmilHvitfeldt\nemilhvitfeldt.com\nemilhvitfeldt.com\n\n\nepiforecasts\nepiforecasts.io/\nepiforecasts.github.io\n\n\nfusionet24\nmyyearindata.com/\nmyyearindata \n\n\nivelasq\nivelasq.rbind.io\npipedream\n\n\nJavOrraca\njavierorracadeatcu.com/\nquarto-blog \n\n\njbkunst\njkunst.com/blog/\nblog\n\n\njessesadler\njessesadler.com\nquarto-blog\n\n\njeweljohnsonj\nsciquest.netlify.app//\nSciQuest\n\n\njhelvy\njhelvy.com\njhelvy_quarto\n\n\njoelnitta\njoelnitta.com\njoelnitta-home\n\n\njournalovi\njournalovi.org\njournalovi.github.io\n\n\njthomasmock\nTheMockup.blog\nthemockup-blog\n\n\nkathoffman\nkhstats.com/\nkhstats-quarto\n\n\nkelly-sovacool\nsovacool.dev//\nkelly-sovacool.github.io\n\n\nkurianbenoy\nkurianbenoy.com\nkurianbenoy-website\n\n\nmagsol\nmagsol.github.io/\nmagsol.github.io\n\n\nmarioangst\nmarioangst.com/en/\n‚Äì\n\n\nmarkusschanta\nblog.markus.schanta.at/\nblog\n\n\nmarvinschmitt\nmarvinschmitt.com/\nmarvinschmitt-dot-com\n\n\nmatherion\nbehaviorchange.eu/\npersonal-website\n\n\nmaxdrohde\nmaximilianrohde.com\nblog_quarto\n\n\nmcanouil\nmickael.canouil.fr/\nmickael.canouil.fr\n\n\nmdsumner\nhypertidy.org\nquarto-blog\n\n\nMeghansaha\nthetidytrekker.com/\nthetidytrekker-quarto\n\n\nmine-cetinkaya-rundel\nA Quarto tip a day\nquarto-tip-a-day\n\n\nmiriamheiss\nmiriamheiss.com/\nmiriam-blog\n\n\nmmhamdy\nhypothesis-space.netlify.app/\nHypothesis-Space\n\n\nnjlyon0\nnjlyon0.github.io\nnjlyon0.github.io\n\n\nnucleic-acid\njollydata.blog\nquarto-blog\n\n\nnumbats\nnumbat.space/\nnumbats-quarto-website\n\n\nOpenscapes\nopenscapes.github.io/quarto-website-tutorial/\nquarto-website-tutorial\n\n\npat-alt\npaltmeyer.com/\npat-alt.github.io\n\n\npaul-buerkner\npaul-buerkner.github.io/\npaul-buerkner.github.io\n\n\npkollenda\nphilippkollenda.com/\nWebsite\n\n\nPossible-Institute\npossible.institute\nwebsite\n\n\nquarto-dev\nquarto.org\nquarto-web\n\n\nrlbarter\nrebeccabarter.com\npersonal-website-quarto\n\n\nrobertmitchellv\nrobertmitchellv.com\nrobertmitchellv.github.io\n\n\nrobjhyndman\nrobjhyndman.com/\nrobjhyndman.com\n\n\nrsangole\nrsangole.netlify.app/\nblog\n\n\nsamanthacsik\nsamanthacsik.github.io/\nsamanthacsik.github.io\n\n\nseeM\nwasimlorgat.com\nblog\n\n\nshamindras\nshamindras.com\nss_personal_distill_blog\n\n\nsrvanderplas\nsrvanderplas.github.io/\nsrvanderplas.github.io\n\n\nStefanThoma\nstefanthoma.github.io/quarto-blog/\nquarto-blog\n\n\nstesiam\nstesiam.com\nstesiam.github.io\n\n\ntidymodels\ntidymodels.org\ntidymodels.org\n\n\nladerast\nladerast.github.io/\nladerast.github.io\n\n\nvbaliga\nvbaliga.github.io\nvbaliga.github.io\n\n\nwillingc\nwillingconsulting.com/\nwilling-consulting-2022\n\n\nzekiakyol\nzekiakyol.com/\npersonal-website"
  },
  {
    "objectID": "posts/2023-05-06-Kaggle-Greek-Community/index.html",
    "href": "posts/2023-05-06-Kaggle-Greek-Community/index.html",
    "title": "Kaggle‚Äôs Greek Community",
    "section": "",
    "text": "Kaggle is one of the most well-known communities of data analysts/scientists with over 10 million active users (Heads or Tails, 2020). Besides that, Kaggle offers an abundance of functionalities (Notebooks), information (through Discussions between users) and Competitions. It is worth noting that there are other similar communities but they cannot compare to the full functionality of Kaggle. For example, DrivenData could be considered an alternative for participating in ML competitions, but it neither provides the possibility to create notebooks nor has a large number of users.\nKaggle Machine Learning & Data Science Survey is an annual survey conducted by Kaggle. The platform asks its users to analyze users‚Äô data in the context of a competition. In this notebook, I conduct an analysis based on 2021‚Äôs survey in order to compare Greek data analysts with the rest of the world."
  },
  {
    "objectID": "posts/2023-05-06-Kaggle-Greek-Community/index.html#import-libraries",
    "href": "posts/2023-05-06-Kaggle-Greek-Community/index.html#import-libraries",
    "title": "Kaggle‚Äôs Greek Community",
    "section": "Import libraries",
    "text": "Import libraries\nThis notebook will definitely make some charts, so the ggplot2 package is necessary. Also, having variables with too many values (e.g.¬†country of each Kaggle user) is an indication of using tables, and for this the reactablefmtr package will help to get a nice result.\n\n# General purpose R libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(forcats)\nlibrary(gridExtra)\nlibrary(countrycode)\n\n# Tables\nlibrary(kableExtra)\nlibrary(reactablefmtr)\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\nlibrary(showtext)\nlibrary(sysfonts) # System / Google fonts\nlibrary(glue)\nlibrary(ggflags)\n\n# Other R packages\nlibrary(fontawesome)\n#library(htmltools) # for building div/links\n\n# Other settings\noptions(digits=4) # print only 4 decimals\noptions(warn = -1)\n\n## Load fonts\n\n# font_families_google() ## see list with available Google fonts\n\nfont_add_google(name = \"Lilita One\", family = \"title\", db_cache = F)\nfont_add_google(name = \"Ysabeau Office\", family = \"subtitle\", db_cache = F)\nfont_add_google(name = \"Spline Sans\", family = \"text\", db_cache = F)"
  },
  {
    "objectID": "posts/2023-05-06-Kaggle-Greek-Community/index.html#import-data",
    "href": "posts/2023-05-06-Kaggle-Greek-Community/index.html#import-data",
    "title": "Kaggle‚Äôs Greek Community",
    "section": "Import data",
    "text": "Import data\nUsing read.csv() from readr package, I import my dataset and I name it as kaggle_2021. The dataset includes in the first line the question which is not required for my data analysis, so I exclude it from my dataset.\n\nkaggle_2021 = read_csv(\"data/kaggle_survey_2021.csv\")\n\n# Delete second line\nkaggle_2021 = kaggle_2021[-c(1),]"
  },
  {
    "objectID": "posts/2023-05-06-Kaggle-Greek-Community/index.html#prepare-data",
    "href": "posts/2023-05-06-Kaggle-Greek-Community/index.html#prepare-data",
    "title": "Kaggle‚Äôs Greek Community",
    "section": "Prepare Data",
    "text": "Prepare Data\nSince my analysis is based on Greek users, I split the dataset into two parts. One part includes exclusively Greek users and all the rest another. Thus, we can observe any differences or similarities with broader Kaggle‚Äôs userbase.\n\n# Recoding Q2 variable\n\nkaggle_2021$Q2 = kaggle_2021$Q2 %&gt;%\n  fct_recode(\n    \"Other\" = \"Nonbinary\",\n    \"Other\" = \"Prefer not to say\",\n    \"Other\" = \"Prefer to self-describe\"\n  )\n\n## Recoding kaggle_2021$Q3\n\nkaggle_2021$Q3 &lt;- kaggle_2021$Q3 %&gt;%\n  fct_recode(\n    \"Hong Kong\" = \"Hong Kong (S.A.R.)\",\n    \"Other\" = \"I do not wish to disclose my location\",\n    \"Iran\" = \"Iran, Islamic Republic of...\",\n    \"UAE\" = \"United Arab Emirates\",\n    \"UK\" = \"United Kingdom of Great Britain and Northern Ireland\",\n    \"USA\" = \"United States of America\",\n    \"Vietnam\" = \"Viet Nam\"\n  )\n\n## Recoding kaggle_2021$Q6\nkaggle_2021$Q6 &lt;- kaggle_2021$Q6 %&gt;%\n  fct_recode(\n    \"0 years\" = \"I have never written code\"\n  )\n\n## Recoding kaggle_2021$Q4\nkaggle_2021$Q4 &lt;- kaggle_2021$Q4 %&gt;%\n  fct_recode(\n    \"Bachelor\" = \"Bachelor‚Äôs degree\",\n    \"PhD\" = \"Doctoral degree\",\n    \"Other\" = \"I prefer not to answer\",\n    \"Master\" = \"Master‚Äôs degree\",\n    \"No\" = \"No formal education past high school\",\n    \"ProfDoc\" = \"Professional doctorate\",\n    \"UniNoDegree\" = \"Some college/university study without earning a bachelor‚Äôs degree\"\n  )\n\nkaggle_2021$Q4 &lt;- kaggle_2021$Q4 %&gt;%\n  fct_relevel(\n    \"No\", \"UniNoDegree\", \"Bachelor\", \"Master\", \"PhD\", \"ProfDoc\",\n    \"Other\"\n  )\n\n\nkaggle_2021_compare = kaggle_2021 %&gt;%\n  mutate(Q3 = if_else(Q3 != \"Greece\", \"Other\", Q3))"
  },
  {
    "objectID": "posts/2023-05-06-Kaggle-Greek-Community/index.html#python-users",
    "href": "posts/2023-05-06-Kaggle-Greek-Community/index.html#python-users",
    "title": "Kaggle‚Äôs Greek Community",
    "section": "Python users",
    "text": "Python users"
  },
  {
    "objectID": "posts/2023-05-06-Kaggle-Greek-Community/index.html#r-users",
    "href": "posts/2023-05-06-Kaggle-Greek-Community/index.html#r-users",
    "title": "Kaggle‚Äôs Greek Community",
    "section": "R users",
    "text": "R users"
  },
  {
    "objectID": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html",
    "href": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "",
    "text": "When someone starts with Machine Learning he usually starts to build some simple models as logistic regression, naive Bayes, linear regression etc. And those alone are already enough for most use cases, as their simplicity is productivity-friendly and comes up with adequate accuracy. However, in enterprise level, accuracy can be important for a lot of reasons. Gradient Boosting Machines are some algorithms which outperform the aforementioned methods and are not complex enough to use them. Of course, before we build the model with (e.g.¬†tidymodels) we have to install them.\n\n\n\nError - Missing LightGBM install\n\n\nThus, on this article I gather all that information.\n\n\n\nInstallation Guides\nSource\n\n\n\n\nLightGBM\nLink\n\n\nCatBoost\nLink\n\n\nXGBoost\nLink"
  },
  {
    "objectID": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#introduction",
    "href": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#introduction",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "",
    "text": "When someone starts with Machine Learning he usually starts to build some simple models as logistic regression, naive Bayes, linear regression etc. And those alone are already enough for most use cases, as their simplicity is productivity-friendly and comes up with adequate accuracy. However, in enterprise level, accuracy can be important for a lot of reasons. Gradient Boosting Machines are some algorithms which outperform the aforementioned methods and are not complex enough to use them. Of course, before we build the model with (e.g.¬†tidymodels) we have to install them.\n\n\n\nError - Missing LightGBM install\n\n\nThus, on this article I gather all that information.\n\n\n\nInstallation Guides\nSource\n\n\n\n\nLightGBM\nLink\n\n\nCatBoost\nLink\n\n\nXGBoost\nLink"
  },
  {
    "objectID": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#lightgbm",
    "href": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#lightgbm",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "LightGBM",
    "text": "LightGBM\n\nOption 1. Install R Package\nIf you are reading this blog, the most possible scenario in that you are using R too. The most easy way to install the corresponding R package :\n\n\nR code\n\nstart_time_lightgbm &lt;- Sys.time()\ninstall.packages(\"lightgbm\", repos = \"https://cran.r-project.org\")\nend_time_lightgbm &lt;- Sys.time()\n\n\n\nOption 2. CMAKE\nThe LightGBM documentation are referring to this method of installation.\n\n\nTerminal\n\nsudo apt install cmake\n\n\n\nTerminal\n\ngit clone --recursive https://github.com/microsoft/LightGBM\ncd LightGBM\nmkdir build\ncd build\ncmake ..\nmake -j4"
  },
  {
    "objectID": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#catboost",
    "href": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#catboost",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "CatBoost",
    "text": "CatBoost\nTheir realeases.\n\n\nR code\n\ninstall.packages(\"devtools\")\n\nOn my occassion, when I tried to install devtools had an error status. According to my error status I had to add packages libharfbuzz-dev and libfribidi-dev. After that, my devtools installation completed without errors.\n\n\n\nR code\n\nstart_time_catboost &lt;- Sys.time()\ndevtools::install_url(\"https://github.com/catboost/catboost/releases/download/v1.1.1/catboost-R-Linux-1.1.1.tgz\"[, INSTALL_opts = c(\"--no-multiarch\", \"--no-test-load\")])\nend_time_catboost &lt;- Sys.time()"
  },
  {
    "objectID": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#xgboost",
    "href": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#xgboost",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "XGBoost",
    "text": "XGBoost\n\n\nR code\n\nstart_time_xgboost &lt;- Sys.time()\ninstall.packages(\"xgboost\")\nend_time_xgboost &lt;- Sys.time()"
  },
  {
    "objectID": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#summary",
    "href": "posts/2022-11-13-Install-LightGBM-CatBoost-Ubuntu/index.html#summary",
    "title": "Install LightGBM and CatBoost on Ubuntu 22.04",
    "section": "Summary",
    "text": "Summary\n\n\n\nML Model\nMethod\nInstallation time\n\n\n\n\nLightGBM\nR package\n7.79 min.\n\n\nCatBoost\nR package (w/o devtools)\n2.1 min.\n\n\nXGBoost\nR package\n6.16 min."
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html",
    "title": "Forecasting Unemployment in Greece",
    "section": "",
    "text": "Introduction \n\n\nPrerequisites  ¬† 2.1 Import Libraries  ¬† 2.2 Import Dataset  ¬† 2.3 Preview Datasset  ¬† 2.4 Dataset Structure  ¬† 2.5 Time Series Preprocessing \n\n\nMissing Values \n\n\nDescriptive Statistics \n\n\nExamine Stationarity  ¬† 5.1 Definition of stationarity  ¬† 5.2 Examine Stationarity Graphically  ¬† 5.3 Examine Stationarity with Statistical Tests  ¬† ¬† 5.3.1 ADF test  ¬† ¬† 5.3.2 PP test  ¬† ¬† 5.3.3 KPSS test \n\n\nIdentify Model \n\n\nBuild Time Series Model \n\n\nCompare Models \n\n\nForecast Future Unemployment  ¬† 9.1 ARIMA (0,2,1) forecasts  ¬† 9.2 ARIMA (9,2,1) forecasts \n\nResults"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#background",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#background",
    "title": "Forecasting Unemployment in Greece",
    "section": "Background",
    "text": "Background"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#time-series",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#time-series",
    "title": "Forecasting Unemployment in Greece",
    "section": "Time series",
    "text": "Time series"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#procedure",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#procedure",
    "title": "Forecasting Unemployment in Greece",
    "section": "Procedure",
    "text": "Procedure"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#short-answer",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#short-answer",
    "title": "Forecasting Unemployment in Greece",
    "section": "Short Answer",
    "text": "Short Answer\nIf you are in a hurry, I predicted that unemployment on Greece is expected to further reduce. It will range between 10% - 13% in February, 2023."
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#import-libraries",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#import-libraries",
    "title": "Forecasting Unemployment in Greece",
    "section": "Import Libraries",
    "text": "Import Libraries\nFor this analysis we will need standard libraries for importing and processing my data, such as readr (Wickham, Hester, & Bryan, 2022) and dplyr (Wickham, Fran√ßois, Henry, M√ºller, & Vaughan, 2023). The kableExtra (Zhu, 2021) package was used to print the results in table format, while the flextable (Gohel & Skintzos, 2022) package was used to print the results of the Dickey-Fuller and KPSS tests.\nThen, due to the nature of the data (time series) it was deemed necessary to use relevant libraries such as lubridate(Spinu, Grolemund, & Wickham, 2021), tseries(Trapletti & Hornik, 2022) & forecast(R. Hyndman et al., 2022) packages.\nFinally, the ggplot2 (Wickham et al., 2024) package was used to create some visualizations, as well as an auxiliary package, ggtext (Wilke & Wiernik, 2022), for further formatting those.\n\nShow the code# General purpose R libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(kableExtra)\nlibrary(flextable)\n\n\n# Graphs\nlibrary(ggplot2)\nlibrary(ggtext) # Add support for HTML/CSS on ggplot\n\n# Time Series \n\nlibrary(lubridate)\nlibrary(tseries)\nlibrary(forecast)\n\n# Other settings\noptions(digits=2) # print only 2 decimals"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#import-dataset",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#import-dataset",
    "title": "Forecasting Unemployment in Greece",
    "section": "Import dataset",
    "text": "Import dataset\nAfter loading the libraries I am able to use the commands of the readr package to import my data. My data is in .csv format, so I‚Äôll use the read_csv() command (Wickham et al., 2022) to import them.\nAdditionally, I choose not to include EA-19 values (as I investigate Greece‚Äôs unemployment).\n\nShow the codeunemployment &lt;- read_csv(\"data/unemployment.csv\") %&gt;%\n  select(LOCATION, TIME, Value) %&gt;% filter(LOCATION != \"EA19\")"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#preview-dataset",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#preview-dataset",
    "title": "Forecasting Unemployment in Greece",
    "section": "Preview Dataset",
    "text": "Preview Dataset\n\nShow the code#| label: tbl-preview-dataset\n#| tbl-cap: \"Preview Dataset (first 6 rows)\"\n#| \npreview_dataset = head(unemployment, 10)\nkbl(preview_dataset, \n    align = 'c',\n    booktabs = T,\n    centering = T,\n    valign = T) %&gt;%\n  kable_paper() %&gt;%\n  scroll_box(width = \"600px\", height = \"250px\")\n\n\n\n\nLOCATION\nTIME\nValue\n\n\n\nGRC\n1998-04\n11\n\n\nGRC\n1998-05\n11\n\n\nGRC\n1998-06\n11\n\n\nGRC\n1998-07\n11\n\n\nGRC\n1998-08\n11\n\n\nGRC\n1998-09\n11\n\n\nGRC\n1998-10\n11\n\n\nGRC\n1998-11\n11\n\n\nGRC\n1998-12\n11\n\n\nGRC\n1999-01\n11"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#dataset-structure",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#dataset-structure",
    "title": "Forecasting Unemployment in Greece",
    "section": "Dataset Structure",
    "text": "Dataset Structure\nOur dataset is consisted by 3 variables (columns). More specifically, concerning my variables, are as follows :\n\n\n\n\n\n\n\nVariable\nProperty\nDescription\n\n\n\nLOCATION\n\nqualitative  (nominal)\nSpecific country‚Äôs statistics\n\n\nTIME\n\nqualitative  (ordinal)\nMonth of the reported data\n\n\nValue\n\nquantitative  (continuous)\nUnemployment at the given Time and Country\n\n\n\nThus, my sample has 3 variables, of which 2 are qualitative and 1 is quantitative property."
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#time-series-preprocessing",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#time-series-preprocessing",
    "title": "Forecasting Unemployment in Greece",
    "section": "Time Series Preprocessing",
    "text": "Time Series Preprocessing\nThe TIME variable needs to be a Date variable which is not fulfilled on our case.\n\nShow the codesapply(unemployment, class) %&gt;% kbl() %&gt;% kable_styling(full_width = F, position = \"center\")\n\n\n\n\nx\n\n\n\nLOCATION\ncharacter\n\n\nTIME\ncharacter\n\n\nValue\nnumeric\n\n\n\n\n\nSo, above I see that I have dates in a format ‚ÄúYYYY-MM‚Äù (Year - Month) and they are considered as characters. With the help of lubridate package I will convert my time series on a Date format.\n\nShow the codeunemployment$TIME &lt;- lubridate::ym(unemployment$TIME)\n\n\nAnd let‚Äôs check again :\n\nShow the codesapply(unemployment, class) %&gt;% kbl() %&gt;% kable_styling(full_width = F, position = \"center\")\n\n\n\n\nx\n\n\n\nLOCATION\ncharacter\n\n\nTIME\nDate\n\n\nValue\nnumeric\n\n\n\n\n\nAnd now I got the Date format. I am able to continue my analysis."
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#definition-of-stationarity",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#definition-of-stationarity",
    "title": "Forecasting Unemployment in Greece",
    "section": "Definition of stationarity",
    "text": "Definition of stationarity\nAn important concept in studying time series is stationarity. A time series is called stationary (‚ÄúApplied Time Series Analysis,‚Äù n.d.) if: \n\n\nE(X_t) = \\text{constant} \n\nVar(X_t) = \\text{constant} \nCov(X_t, X_s) = \\text{constant}"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#examine-stationarity-graphically",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#examine-stationarity-graphically",
    "title": "Forecasting Unemployment in Greece",
    "section": "Examine Stationarity Graphically",
    "text": "Examine Stationarity Graphically\n\n\nLevel\nFirst Diff.\nSecond Diff.\n\n\n\nIt is apparent that there is a big variation on the values of unemployment. This time series is not stationary and the differencing is justified.\n\nShow the codeplot(grc_unemployment$Value,type = \"l\")\n\n\n\n\n\n\n\n\n\nHere we can see a big improvement in comparison with original data. I have some concerns about points close to 150 (mildly upwards trend) and 250 (outlier).\n\nShow the codegrc_unemployment_diff1 &lt;- diff(grc_unemployment$Value, differences = 1)\n\nplot(grc_unemployment_diff1,type = \"l\")\n\n\n\n\n\n\n\n\n\nGiven the concerns of above, I made also a second difference plot. It seems to solve the problem on points close to 150.\n\nShow the codegrc_unemployment_diff2&lt;- diff(grc_unemployment$Value, differences = 2)\n\nplot(grc_unemployment_diff2, type = \"l\")"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#examine-stationarity-with-statistical-tests",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#examine-stationarity-with-statistical-tests",
    "title": "Forecasting Unemployment in Greece",
    "section": "Examine Stationarity with Statistical tests",
    "text": "Examine Stationarity with Statistical tests\nThe graphical interpretation of stationarity can be beneficial for a quick assessment on topic of stationarity. However it can be considered a subjective metric, which leads on a non consistent decision (someone may consider the second figure as stationary and some others not.\nThankfully, there are some statistical tests which can help us on our decisions. Some commonly used are :\n\n\nAugmented Dickey-Fuller (ADF) test\n\nPhillips- Perron (PP) test\n\nKwiatkowski-Phillips-Schmidt-Shin (KPSS) test\n\nSummary\n\nShow the codesummary_stationarity_results &lt;- data.frame(\n                             \"Type\" = c(\"levels\", \"Diff(GRC)\", \"Diff2(GRC)\"),\n                             \"ADF test\" = c(\"Non Stationary\", \"Stationary\", \"Stationary\"),\n                              \"PP test\" = c(\"Non Stationary\", \"Stationary\", \"Stationary\"),\n                             \"KPSS test\" =c(\"Non Stationary\", \"Non Stationary\", \"Stationary\")\n)\n\n\nsummary_stationarity_results  %&gt;% kbl() %&gt;% kable_styling()\n\n\n\nType\nADF.test\nPP.test\nKPSS.test\n\n\n\nlevels\nNon Stationary\nNon Stationary\nNon Stationary\n\n\nDiff(GRC)\nStationary\nStationary\nNon Stationary\n\n\nDiff2(GRC)\nStationary\nStationary\nStationary\n\n\n\n\n\nADF test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is not stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is a unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nShow the codeadf.test(grc_unemployment$Value) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-0.9\n0.9485 \n6.0\nAugmented Dickey-Fuller Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nŒ£œÖŒΩŒµœÄœéœÇ, ŒµŒØŒΩŒ±Œπ œÄœÅŒøœÜŒ±ŒΩŒ≠œÇ Œ±œÄœå œÑŒ± Œ±œÄŒøœÑŒµŒªŒ≠œÉŒºŒ±œÑŒ± œÑŒøœÖ œÉœÑŒ±œÑŒπœÉœÑŒπŒ∫Œøœç ŒµŒªŒ≠Œ≥œáŒøœÖ Dickey Fuller œåœÑŒπ Œ∑ œáœÅŒøŒΩŒøœÉŒµŒπœÅŒ¨ ŒºŒøœÖ Œ¥ŒµŒΩ ŒµŒØŒΩŒ±Œπ œÉœÑŒ¨œÉŒπŒºŒ∑. ŒòŒ± œÄœÅŒ≠œÄŒµŒπ ŒΩŒ± ŒµœÜŒ±œÅŒºœåœÉœâ œÑŒøŒΩ Œ≠ŒªŒµŒ≥œáŒø Dickey-Fuller œÉœÑŒπœÇ Œ¥ŒøŒ±œÜŒøœÅŒ≠œÇ.\n\nShow the codeadf.test(grc_unemployment_diff1) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-3.5\n0.0424 *\n6.0\nAugmented Dickey-Fuller Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nAnd finally the results for the second differences are :\n\nShow the codeadf.test(grc_unemployment_diff2) %&gt;% as_flextable()\n\nWarning in adf.test(grc_unemployment_diff2): p-value smaller than printed\np-value\n\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-9.5\n0.0100 **\n6.0\nAugmented Dickey-Fuller Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nPP test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is not stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is a unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nShow the codepp.test(grc_unemployment$Value,) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n0.2\n0.9900 \n5.0\nPhillips-Perron Unit Root Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nShow the codepp.test(grc_unemployment_diff1) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-279.8\n0.0100 **\n5.0\nPhillips-Perron Unit Root Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nShow the codepp.test(grc_unemployment_diff2) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\nalternative\n\n\n-337.1\n0.0100 **\n5.0\nPhillips-Perron Unit Root Test\nstationary\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\nKPSS test\n\n\\begin{array}{l}\nH_0 : \\text{Time series is stationary} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\\equiv\n\\begin{array}{l}\nH_0 : \\text{There is not  unit root} \\\\\nH_1 : \\text{Alternatively}\n\\end{array}\n\n\nShow the codekpss.test(grc_unemployment$Value,) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n2.5\n0.0100 **\n5.0\nKPSS Test for Level Stationarity\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nShow the codekpss.test(grc_unemployment_diff1) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n0.6\n0.0231 *\n5.0\nKPSS Test for Level Stationarity\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05\n\n\n\n\n\n\nShow the codekpss.test(grc_unemployment_diff2) %&gt;% as_flextable()\n\n\n\n\n\nstatistic\np.value\nparameter\nmethod\n\n\n0.0\n0.1000 .\n5.0\nKPSS Test for Level Stationarity\n\n\nSignif. codes: 0 &lt;= '***' &lt; 0.001 &lt; '**' &lt; 0.01 &lt; '*' &lt; 0.05"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#arima-021-forecasts",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#arima-021-forecasts",
    "title": "Forecasting Unemployment in Greece",
    "section": "ARIMA (0,2,1) forecasts",
    "text": "ARIMA (0,2,1) forecasts\n\nShow the codeforecast(auto_model,6) %&gt;% autoplot()\n\n\n\n\n\n\nShow the codeforecast(auto_model,6) %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nPoint Forecast\nLo 80\nHi 80\nLo 95\nHi 95\n\n\n\n294\n12\n11.5\n13\n11.2\n13\n\n\n295\n12\n11.1\n13\n10.7\n13\n\n\n296\n12\n10.7\n13\n10.2\n13\n\n\n297\n12\n10.3\n13\n9.7\n13\n\n\n298\n11\n10.0\n13\n9.2\n13\n\n\n299\n11\n9.6\n13\n8.8\n14"
  },
  {
    "objectID": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#arima-921-forecasts",
    "href": "posts/2022-10-22-Forecasting-Greek-Unemployment/index.html#arima-921-forecasts",
    "title": "Forecasting Unemployment in Greece",
    "section": "ARIMA (9,2,1) forecasts",
    "text": "ARIMA (9,2,1) forecasts\n\nShow the codeforecast(arimaModel_3,6) %&gt;% autoplot()\n\n\n\n\n\n\nShow the codeforecast(arimaModel_3,6) %&gt;% kbl() %&gt;% kable_paper()\n\n\n\n\nPoint Forecast\nLo 80\nHi 80\nLo 95\nHi 95\n\n\n\n294\n12\n11\n12\n11.1\n13\n\n\n295\n12\n11\n13\n10.9\n13\n\n\n296\n12\n11\n13\n10.7\n13\n\n\n297\n12\n11\n13\n10.1\n13\n\n\n298\n12\n10\n13\n9.8\n13\n\n\n299\n12\n10\n13\n9.4\n14"
  },
  {
    "objectID": "web-apps/index.html",
    "href": "web-apps/index.html",
    "title": "Web Projects",
    "section": "",
    "text": "Online\n      \n      A dashboard for an Ageing World (1800 - 2060)\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Online\n      \n      Predict your wage based on your Job Type (onsite, hybrid, remote), employer's country and your job experience.\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Online\n      \n      A Shiny App to calculate parliamentary seats for each party (Greek parliament).\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Soon...\n      \n      A Shiny App to showcase various distributions and their characteristics.\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Soon...\n      \n      A web app to make predictions about next week's passenger traffic (bus/metro/tram)"
  },
  {
    "objectID": "web-apps/index.html#shiny-apps",
    "href": "web-apps/index.html#shiny-apps",
    "title": "Web Projects",
    "section": "",
    "text": "Online\n      \n      A dashboard for an Ageing World (1800 - 2060)\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Online\n      \n      Predict your wage based on your Job Type (onsite, hybrid, remote), employer's country and your job experience.\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Online\n      \n      A Shiny App to calculate parliamentary seats for each party (Greek parliament).\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Soon...\n      \n      A Shiny App to showcase various distributions and their characteristics.\n    \n    \n      \n        \n      \n        \n    \n  \n\n  \n    \n      \n      \n        Soon...\n      \n      A web app to make predictions about next week's passenger traffic (bus/metro/tram)"
  },
  {
    "objectID": "web-apps/index.html#apis-with",
    "href": "web-apps/index.html#apis-with",
    "title": "Web Projects",
    "section": "APIs with ",
    "text": "APIs with \n\n\n    \n      Developers' Wages API\n      Predict your wage based on your dev role (frontend, backend, analytics) and your job experience.\n    \n    \n     \n    \n\n\n    \n      Glass API\n      Determine the type of glass (window/non-window) based on its components"
  }
]