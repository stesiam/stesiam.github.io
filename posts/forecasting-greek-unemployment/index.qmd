---
title: "Forecasting Unemployment in Greece"
author: "stesiam"
lang: en
description: |
  Make a prediction about the future value of Greece's unemployment using ARIMA model.
freeze: false
link-external-newwindow: true
categories: [R, Time Series]
image: unemployment.jpg
image-alt: "Illustration of five people standing in line to exit a building, with a visible exit sign, an open door and a large clock showing 5:00."
fig-cap-location: bottom
date: "2022-10-22"
toc: true
toc-title: Table of Contents
toc-location: left
citation: true
title-block-banner: true
nocite: '@*'
csl: apa-6th-edition.csl
bibliography: [packages.bib, references.bib]
format: 
  html:
    freeze: false
    code-link: true
    code-fold: true
    code-summary: "Show the code"
    code-tools: 
      source: https://github.com/stesiam/stesiam.github.io/blob/gh-pages/posts/forecasting-greek-unemployment/index.qmd
execute:
  echo: true
editor_options: 
  markdown: 
    wrap: 80
---

## Introduction

### Background


### Time series


### Methodology


### Short Answer

If you are in a hurry, I predicted that unemployment on Greece is expected to further reduce. It will range between 10\% - 13\% in February, 2023.



## Prerequisites

### Import Libraries

For this analysis we will need standard libraries for importing and processing my data, such as readr [@R-readr] and dplyr [@R-dplyr]. The kableExtra [@R-kableExtra] package was used to print the results in table format, while the flextable [@R-flextable] package was used to print the results of the Dickey-Fuller and KPSS tests.

Then, due to the nature of the data (time series) it was deemed necessary to use relevant libraries such as lubridate[@R-lubridate], tseries[@R-tseries] & forecast[@R-forecast] packages.


Finally, the ggplot2 [@R-ggplot2] package was used to create some visualizations, as well as an auxiliary package, ggtext [@R-ggtext], for further formatting those.

```{r Import R Libraries, message=FALSE, results='hide', echo=TRUE}
# General purpose R libraries
library(dplyr)
library(readr)
library(kableExtra)
library(flextable)

# Graphs
library(highcharter)

# Time Series 

library(lubridate)
library(tseries)
library(forecast)
```

```{r, include=FALSE}
knitr::write_bib(.packages(), file = 'packages.bib')
```


```{r}
acf_plot_function = function(data, min = -1, max = 1){
  ts_data <- data
  N <- length(ts_data)

# Compute confidence limit
conf_limit <- qnorm(0.975) / sqrt(N)

# Use forecast::Acf (biased estimator, recommended for ARIMA)
acf_obj <- Acf(ts_data, plot = FALSE, lag.max = 20)

# Extract lags and values
# Note: Acf() returns acf_obj$acf as a matrix; acf_obj$lag as a matrix
lags_acf <- as.numeric(acf_obj$lag[-1])             # skip lag 0
acf_values <- as.numeric(acf_obj$acf[-1])           # skip lag 0

# Build the highcharter ACF plot
acf_chart <- highchart() %>%
  hc_chart(type = "column") %>%
  hc_title(text = "Autocorrelation Plot") %>%
  hc_xAxis(categories = lags_acf, title = list(text = "Lag")) %>%
  hc_yAxis(min = min, max = max,
    title = list(text = "ACF"),
    plotLines = list(
      list(value = 0, color = "#000000", width = 3),
      list(value = conf_limit, color = "#FF0000", dashStyle = "ShortDash", width = 1),
      list(value = -conf_limit, color = "#FF0000", dashStyle = "ShortDash", width = 1)
    )
  ) %>%
  hc_legend(enabled = FALSE) %>%
  hc_add_series(name = "ACF", data = round(acf_values, digits = 4))

# Show chart
acf_chart
}

pacf_plot_function <- function(data, min = -1, max = 1) {
  ts_data <- data
  N <- length(ts_data)
  
  # Compute confidence limit (same formula as for ACF)
  conf_limit <- qnorm(0.975) / sqrt(N)
  
  # Compute PACF using forecast::Pacf (biased estimator, recommended for ARIMA)
  pacf_obj <- forecast::Pacf(ts_data, plot = FALSE, lag.max = 20)
  
  # Extract lags and PACF values
  lags_pacf <- as.numeric(pacf_obj$lag)  # already excludes lag 0
  pacf_values <- as.numeric(pacf_obj$acf)
  
  # Build the highcharter PACF plot
  pacf_chart <- highcharter::highchart() %>%
    highcharter::hc_chart(type = "column") %>%
    highcharter::hc_title(text = "Partial Autocorrelation Plot") %>%
    highcharter::hc_xAxis(categories = lags_pacf, title = list(text = "Lag")) %>%
    highcharter::hc_yAxis(
      min = min, max = max,
      title = list(text = "PACF"),
      plotLines = list(
        list(value = 0, color = "#000000", width = 3),
        list(value = conf_limit, color = "#FF0000", dashStyle = "ShortDash", width = 1),
        list(value = -conf_limit, color = "#FF0000", dashStyle = "ShortDash", width = 1)
      )
    ) %>%
    highcharter::hc_legend(enabled = FALSE) %>%
    highcharter::hc_add_series(name = "PACF", data = round(pacf_values, digits = 4))
  
  # Show chart
  pacf_chart
}
```

### Import dataset

After loading the libraries I am able to use the commands of the readr package to import my data. My data is in .csv format, so I'll use the `read_csv()` command [@R-readr] to import them.

Additionally, I choose not to include EA-19 values (as I investigate Greece's unemployment).

```{r Import dataset, cache=TRUE, message=FALSE,results='hide',echo=TRUE, warning=FALSE}
unemployment <- read_csv("data/unemployment.csv") %>%
  select(LOCATION, TIME, Value) %>% filter(LOCATION != "EA19")
```

### Preview Dataset

```{r Preview Data}
#| label: tbl-preview-dataset
#| tbl-cap: "Preview Dataset (first 6 rows)"
head(unemployment, 10) %>%
  kbl(., 
    align = 'c',
    booktabs = T,
    centering = T,
    valign = T) %>%
  kable_styling()
```

### Dataset Structure

Our dataset is consisted by `r ncol(unemployment)` variables (columns). More specifically, concerning my variables, are as follows
:

|  Variable  |             Property             |                Description                 |
|:---------------:|:-------------------------:|:----------------------------------:|
| `LOCATION` |   *qualitative* <br> (nominal)   |       Specific country's statistics        |
|   `TIME`   |   *qualitative* <br> (ordinal)   | Month of the reported data |
|  `Value`   | *quantitative* <br> (continuous) | Unemployment at the given Time and Country |

Thus, my sample has `r ncol(unemployment)` variables, of which 2 are qualitative
and 1 is quantitative property.

## Time Series Preprocessing

The `TIME` variable needs to be a Date variable which is not fulfilled on our
case.

```{r}
sapply(unemployment, class) %>% 
  kbl() %>% kable_styling(full_width = F, position = "center")
```

So, above I see that I have dates in a format "YYYY-MM" (Year - Month) and they
are considered as characters. With the help of `lubridate` package I will
convert my time series on a Date format.

```{r}
unemployment$TIME <- lubridate::ym(unemployment$TIME)
```

And let's check again :

```{r}
sapply(unemployment, class) %>% kbl() %>% kable_styling(full_width = F, position = "center")
``` 

And now I got the Date format. I am able to continue my analysis.

## Missing Values

```{r, results='hide'}
sum(is.na(unemployment))
```

Good news! On this dataset there are `r sum(is.na(unemployment))` missing values, in total. 

In case the dataset had missing values, I would first look at which variables those were.In a second phase, it might be necessary to replace the missing values.

## Descriptive Statistics

The unemployment data for Greece refer to the period from April 1998 το August 2022. Regarding Europe we have data from January 2000 to August 2022.

The last 20 years have seen particularly large changes mainly in Greece, due to the domestic economic crisis. There is a noticeable change between September 2010 (10.1\%) and September 2013 (28.1 \%), in terms of unemployment in Greece. For the record, below you can find a table with the months that presented the highest unemployment in Greece.  As you will notice the five highest values were observed in 2013.


```{r}
unemployment %>% dplyr::filter(LOCATION == "GRC") %>% select(TIME, Value) %>% as.data.frame() %>%
  arrange(Value) %>% tail(5) %>% kbl() %>% kable_styling(full_width = F, position = "center")
```

Accordingly, the highest unemployment rates observed at the European level are the following:

```{r}
unemployment %>% dplyr::filter(LOCATION == "EU27_2020") %>% select(TIME, Value)  %>%
  as.data.frame() %>% arrange(Value) %>% tail(5) %>% kbl() %>% kable_styling(full_width = F, position = "center")
```


The lowest unemployment ever recorded in Greece was in the period of 2008:

```{r}
unemployment %>% dplyr::filter(LOCATION == "GRC") %>% select(TIME, Value) %>% as.data.frame() %>%
  arrange(Value) %>% head(5) %>% kbl() %>% kable_styling(full_width = F, position = "center")
```

On the other hand, at the moment in Europe we are at the lowest levels of the last 20 years, with unemployment hovering around 6\%.

```{r}
unemployment %>% dplyr::filter(LOCATION == "EU27_2020") %>% select(TIME, Value) %>%
  as.data.frame() %>% arrange(Value) %>% head(5) %>% kbl() %>% kable_styling(full_width = F, position = "center")
```

Finally, it is evident that in the case of Greece the changes are more intense than in Europe.

All of the above can be summarized by the following graph:

```{r}
g = unemployment %>%
  mutate(Year = year(TIME)) %>%
  group_by(LOCATION, Year) %>%
  summarise(mean_unemployment = mean(Value))

highchart() %>%
    hc_chart(type = "line") %>%
    hc_title(text = "Unemployment Rates") %>%
    hc_xAxis(title = list(text = "Year")) %>%
    hc_yAxis(title = list(text = "Value")) %>%
    hc_tooltip(shared = TRUE, valueDecimals = 2, valueSuffix = " %") %>%
    hc_add_series(
        data = g,
        type = "line",
        hcaes(x = Year, y = mean_unemployment, group = LOCATION)
    ) %>%
  hc_plotOptions(
  series = list(
    dataLabels = list(
      enabled = TRUE,
      formatter = JS("function() {
        if (this.point.index === this.series.data.length - 1) {
          return this.y.toFixed(2) + ' %';
        }
        return null;
      }")
    )
  )
)
```

## Examine trend and seasonality

In time series analysis, it's important to distinguish where the variability in the final form of the series originates from. Time series consist of three main components: trend, seasonality, and randomness. The trend refers to whether the series shows a specific direction (upward/downward). Seasonality refers to recurring patterns at regular intervals.

$$
y_t = S_t + T_t + E_t
$$
Όπου:

- $y_t$ δηλώνουν τα δεδομένα που έχουμε διαθέσιμα, 
- $S_t$
- $T_t$
- $E_t$

Similarly, the multiplicative model is defined:

$$
y_t = S_t \cdot T_t \cdot E_t
$$

where the components that make up the time series are multiplied instead of added.


## Examine stationarity

### Definition of stationarity


An important concept in studying time series is stationarity. A time series is called stationary [@appliedtimeseriespenn] if: \br

1.  $E(X_t):\text{constant}$ \br
2.  $Var(X_t): \text{constant}$ \br
3.  $Cov(X_t, X_s): \text{constant}$

### Examine Stationarity Graphically

::: {.panel-tabset}

#### Level

It is apparent that there is a big variation on the values of unemployment. This time series is not stationary and the differencing is justified.


```{r}
highchart() %>%
    hc_chart(type = "line") %>%
    hc_title(text = "Unemployment Rates") %>%
    hc_xAxis(title = list(text = "Year")) %>%
    hc_yAxis(title = list(text = "Value")) %>%
    hc_tooltip(shared = TRUE, valueDecimals = 2, valueSuffix = " %") %>%
    hc_add_series(
        data = g,
        type = "line",
        hcaes(x = Year, y = mean_unemployment, group = LOCATION)
    ) %>%
  hc_plotOptions(
  series = list(
    dataLabels = list(
      enabled = TRUE,
      formatter = JS("function() {
        if (this.point.index === this.series.data.length - 1) {
          return this.y.toFixed(2) + ' %';
        }
        return null;
      }")
    )
  )
)
```


#### First Diff.

Here we can see a big improvement in comparison with original data. I have some concerns about points close to 150 (mildly upwards trend) and 250 (outlier). 

```{r}
grc_unemployment = unemployment %>% dplyr::filter(LOCATION == "GRC")
grc_unemployment_diff1 <- diff(grc_unemployment$Value, differences = 1)

highchart() %>%
    hc_chart(type = "line") %>%
    hc_title(text = "Unemployment Rates") %>%
    hc_xAxis(title = list(text = "Year")) %>%
    hc_yAxis(title = list(text = "Value")) %>%
    hc_tooltip(shared = TRUE, valueDecimals = 2, valueSuffix = " %") %>%
    hc_add_series(
        data = grc_unemployment_diff1
    )
```


#### Second Diff.


Given the concerns of above, I made also a second difference plot. It seems to solve the problem on points close to 150.

```{r}

grc_unemployment_diff2<- diff(grc_unemployment$Value, differences = 2)

highchart() %>%
    hc_chart(type = "line") %>%
    hc_title(text = "Unemployment Rates") %>%
    hc_xAxis(title = list(text = "Year")) %>%
    hc_yAxis(title = list(text = "Value")) %>%
    hc_tooltip(shared = TRUE, valueDecimals = 2, valueSuffix = " %") %>%
    hc_add_series(
        data = grc_unemployment_diff2
    )

```


:::


### Examine Stationarity with Statistical tests


The graphical interpretation of stationarity can be beneficial for a quick assessment on topic of stationarity. However it can be considered a subjective metric, which leads on a non consistent decision (someone may consider the second figure as stationary and some others not. 


Thankfully, there are some statistical tests which can help us on our decisions. Some commonly used are :

- **Augmented Dickey-Fuller** (ADF) test
- **Phillips- Perron** (PP) test
- **Kwiatkowski-Phillips-Schmidt-Shin** (KPSS) test
- **Zivot-Andrews** (ZA) test 

But an other problem arises. We are not in a fancy IDE with menus and checkboxes. We use R and its packages. There are many packages that have already write functions to study stationarity with the aforementioned tests. Some of them are:

- tseries
- urca
- CADFtest

We should carefully evaluate our choices, as these packages advertise similar functionality but differ significantly in the scope of their functions and, more importantly, in the level of flexibility they offer for handling time series characteristics. In short, the `tseries` package is the one I'm most familiar with, but it is also the most limited in terms of configurable parameters. Although many tutorials use this package, I found that I couldn’t set the number of lags for tests or specify characteristics like trends when applicable. On the other hand, the `urca` package addresses these limitations by allowing users to specify both the trend component and the number of lags in the respective tests. One minor drawback of urca, however, is that it only provides critical values, not p-values.


#### Summary


```{r}
summary_stationarity_results <- data.frame(
                             "Type" = c("levels", "Diff(GRC)", "Diff2(GRC)"),
                             "ADF test" = c("Non Stationary", "Stationary", "Stationary"),
                              "PP test" = c("Non Stationary", "Stationary", "Stationary"),
                             "KPSS test" =c("Non Stationary", "Non Stationary", "Stationary")
)


summary_stationarity_results  %>% kbl() %>% kable_styling() 
```


#### ADF test

One of the most


$$
H_0 : \text{The time series has a unit root} \\
H_1 : \text{The time series has not a unit root} 
$$
Selecting the lags

```{r}
library(vars)
G = VARselect(grc_unemployment$Value, lag.max = 20, type = "const")


```



```{r}
get_adf_results = function(variable){

    # Ensure variable is numeric (e.g., a time series or numeric vector)
    if (!is.numeric(variable)) {
        stop("Input variable must be numeric.")
    }
    
    # Perform ADF tests
    adf_orig = adf.test(variable)
    adf_diff1 = adf.test(diff(variable, differences = 1))
    adf_diff2 = adf.test(diff(variable, differences = 2))
    
    # Extract results
    adf_table = data.frame(
        "Transformation" = c("Level", "1st Difference", "2nd Difference"),
        "Dickey-Fuller" = c(
            adf_orig$statistic[["Dickey-Fuller"]],
            adf_diff1$statistic[["Dickey-Fuller"]],
            adf_diff2$statistic[["Dickey-Fuller"]]
        ),
        "Lag Order" = c(
            adf_orig$parameter[["Lag order"]],
            adf_diff1$parameter[["Lag order"]],
            adf_diff2$parameter[["Lag order"]]
        ),
        "p-value" = c(
            adf_orig$p.value,
            adf_diff1$p.value,
            adf_diff2$p.value
        )
    ) %>%
        kbl(digits = 5) %>%
        kable_styling(full_width = FALSE)
    
    return(adf_table)
}
```

```{r, warning = FALSE}
#| tbl-cap: "Augmented Dickey-Fuller test results"
get_adf_results(grc_unemployment$Value)
```

Συνεπώς, είναι προφανές από τα αποτελέσματα του
στατιστικού ελέγχου Dickey Fuller ότι η χρονοσειρά μου δεν είναι στάσιμη. Θα πρέπει να εφαρμόσω τον έλεγχο Dickey-Fuller στις δοαφορές.


#### PP  test

$$
H_0 : \text{The time series has a unit root} \\
H_1 : \text{The time series has not a unit root} 
$$

```{r}
get_pp_results = function(variable){

    # Ensure variable is numeric (e.g., a time series or numeric vector)
    if (!is.numeric(variable)) {
        stop("Input variable must be numeric.")
    }
    
    # Perform ADF tests
    pp_orig = pp.test(variable)
    pp_diff1 = pp.test(diff(variable, differences = 1))
    pp_diff2 = pp.test(diff(variable, differences = 2))
    
    # Extract results
    pp_table = data.frame(
        "Transformation" = c("Level", "1st Difference", "2nd Difference"),
        "Phillips-Perron" = c(
            pp_orig$statistic[["Dickey-Fuller Z(alpha)"]],
            pp_diff1$statistic[["Dickey-Fuller Z(alpha)"]],
            pp_diff2$statistic[["Dickey-Fuller Z(alpha)"]]
        ),
        "Lag Order" = c(
            pp_orig[["parameter"]][["Truncation lag parameter"]],
            pp_diff1[["parameter"]][["Truncation lag parameter"]],
            pp_diff2[["parameter"]][["Truncation lag parameter"]]
        ),
        "p-value" = c(
            pp_orig$p.value,
            pp_diff1$p.value,
            pp_diff2$p.value
        )
    ) %>%
        kbl(digits = 5) %>%
        kable_styling(full_width = FALSE)
    
    return(pp_table)
}
```

```{r, warning = FALSE}
#| tbl-cap: "Phillips-Perron test results"
#| warning: false
get_pp_results(grc_unemployment$Value)
```


#### KPSS test

$$
H_0 : \text{The time series has not a unit root} \\
H_1 : \text{Alternatively} 
$$


```{r}
get_kpss_results = function(variable){

    # Ensure variable is numeric (e.g., a time series or numeric vector)
    if (!is.numeric(variable)) {
        stop("Input variable must be numeric.")
    }
    
    # Perform ADF tests
    kpss_orig = kpss.test(variable)
    kpss_diff1 = kpss.test(diff(variable, differences = 1))
    kpss_diff2 = kpss.test(diff(variable, differences = 2))
    
    # Extract results
    pp_table = data.frame(
        "Transformation" = c("Level", "1st Difference", "2nd Difference"),
        "KPSS" = c(
            kpss_orig[["statistic"]][["KPSS Level"]],
            kpss_diff1[["statistic"]][["KPSS Level"]],
            kpss_diff2[["statistic"]][["KPSS Level"]]
        ),
        "Lag Order" = c(
            kpss_orig[["parameter"]][["Truncation lag parameter"]],
            kpss_diff1[["parameter"]][["Truncation lag parameter"]],
            kpss_diff2[["parameter"]][["Truncation lag parameter"]]
        ),
        "p-value" = c(
            kpss_orig$p.value,
            kpss_diff1$p.value,
            kpss_diff2$p.value
        )
    ) %>%
        kbl(digits = 5) %>%
        kable_styling(full_width = FALSE)
    
    return(pp_table)
}
```

```{r, warning = FALSE}
#| tbl-cap: "KPSS test results"
get_kpss_results(grc_unemployment$Value)
```


## Identify Model

::: {.panel-tabset}



### Levels

::: grid
::: {.g-col-12 .g-col-md-6}
```{r, fig.height=4}
acf_plot_function(unemployment$Value, min=-0.2, max=1)
```
:::
::: {.g-col-12 .g-col-md-6}
```{r, fig.height=4}
pacf_plot_function(unemployment$Value, min=-0.2, max=1)
```
:::
:::

### First Diff.

::: grid
::: {.g-col-12 .g-col-md-6}
```{r, fig.height=4}
acf_plot_function(grc_unemployment_diff1, min=-0.1, max = 0.6)
```
:::
::: {.g-col-12 .g-col-md-6}
```{r, fig.height=4}
pacf_plot_function(grc_unemployment_diff1, min=-0.2, max=0.5)
```
:::
:::

### Second Diff.

::: grid
::: {.g-col-12 .g-col-md-6}
```{r, fig.height=4}
acf_plot_function(grc_unemployment_diff2, min=-0.5, max = 0.5)
```
:::
::: {.g-col-12 .g-col-md-6}
```{r, fig.height=4}
pacf_plot_function(grc_unemployment_diff2, min=-0.5, max = 0.5)
```
:::
:::

:::

## Build Time Series Model

::: {.panel-tabset}

### Automated model

```{r}
auto_model <- auto.arima(grc_unemployment$Value, trace = T,seasonal = TRUE)
auto_model 
```


### ARIMA candidate 1

```{r}
arimaModel_1=arima(grc_unemployment$Value, order=c(0,1,2))
arimaModel_1
```


### ARIMA candidate 2

```{r}
arimaModel_2=arima(grc_unemployment$Value, order=c(1,1,2))
arimaModel_2
```


### ARIMA candidate 3

```{r}
arimaModel_3=arima(grc_unemployment$Value, order=c(9,2,1))
arimaModel_3
```

:::

## Compare Models

After building some ARIMA models, I should
decide which is the best one to make my estimations. One metric to evaluate those models is **AIC** (Akaike Information Criterion). The lower the value of AIC, the better my model.



```{r}
accuracy_table <- data.frame(
                             "Name of Model" = c("Auto Model", "ARIMA Candidate #1", "ARIMA Candidate #2", "ARIMA Candidate #3"),
                             Model = c("ARIMA(0,2,1)", "ARIMA(0,1,2)", "ARIMA(1,1,2)", "ARIMA(9,2,1)"),
                             AIC =c(auto_model$aic, arimaModel_1$aic, arimaModel_2$aic, arimaModel_3$aic)
)


accuracy_table %>% kbl() %>% kable_styling()
```

So, the best model is the Auto Model (ARIMA(9,2,1)), which has the lowest AIC value. 


## Checking best models




## Forecast Future Unemployment

Previously, I identify which is the best model. Now, I will use this model in order to predict unemployment for the next 6 months. It should be recalled that the last available value was from August of 2022 (12.2\%). Therefore, I will make a prediction for unemployment in Greece until February 2023.

### ARIMA (0,2,1) forecasts

```{r}
s = forecast(auto_model,20)

month = seq(max(grc_unemployment$TIME) %m+% months(1),  # start at next month
              by = "1 month",
              length.out = 20)

highchart() %>%
    hc_title(text = "Prediction of Unemployment with ARIMA(0,2,1)") %>%
    hc_xAxis(type = "datetime")  %>%
    hc_yAxis(title = list(text="Unemployment (%)")) %>%
  hc_add_series(name="Historic Data",
    data = list_parse2(data.frame(x = datetime_to_timestamp(grc_unemployment$TIME), y = grc_unemployment$Value)),
    type = "line"
  )  %>%
  hc_add_series(name = "Forecast",
                  data = list_parse2(data.frame(
                      x = datetime_to_timestamp(month),
                      y = round(s$mean, digits=2)
                  )),
                  type = "line",
                  color = "#d62728") %>%
    hc_add_series(name = "Confidence Interval",
                data = list_parse2(data.frame(
                  x = datetime_to_timestamp(month),
                  low = round(s$lower[, "80%"], digits=2),
                  high = round(s$upper[, "80%"], digits=2)
                )),
                type = "arearange",
                color = hex_to_rgba("#d62728", 0.2),
                linkedTo = ":previous")


```

### ARIMA (9,2,1) forecasts

```{r}
s1 = forecast(arimaModel_3,20)

month = seq(max(grc_unemployment$TIME) %m+% months(1),  # start at next month
              by = "1 month",
              length.out = 20)

highchart() %>%
    hc_title(text = "Prediction of Unemployment with ARIMA(0,2,1)") %>%
    hc_xAxis(type = "datetime")  %>%
    hc_yAxis(title = list(text="Unemployment (%)")) %>%
  hc_add_series(name="Historic Data",
    data = list_parse2(data.frame(x = datetime_to_timestamp(grc_unemployment$TIME), y = grc_unemployment$Value)),
    type = "line"
  )  %>%
  hc_add_series(name = "Forecast",
                  data = list_parse2(data.frame(
                      x = datetime_to_timestamp(month),
                      y = round(s1$mean, digits=2)
                  )),
                  type = "line",
                  color = "#d62728") %>%
    hc_add_series(name = "Confidence Interval",
                data = list_parse2(data.frame(
                  x = datetime_to_timestamp(month),
                  low = round(s1$lower[, "80%"], digits=2),
                  high = round(s1$upper[, "80%"], digits=2)
                )),
                type = "arearange",
                color = hex_to_rgba("#d62728", 0.2),
                linkedTo = ":previous")
```

## Results

Given the diagram as well as the forecast table (of the best performing model, candidate #3), I conclude that a reduction in unemployment in Greece is expected in the next period of time (in the next six months). More specifically, **Greece's unemployment** in **February 2023** will range between **10\%** (9.4\%) and **13\%** (14\%) with an **80\%** (95\%) probability (based on **ARIMA(9,2,1)** model).

## Acknowledgements {.appendix .unlisted}

Image by <a href="https://pixabay.com/users/roszie-6000120/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=7386581">Rosy / Bad Homburg / Germany</a> from <a href="https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=7386581">Pixabay</a>

